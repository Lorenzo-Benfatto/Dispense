\documentclass[twoside]{article}
\usepackage[utf8]{inputenc}

\title{\textbf{Metodi Matematici per la Fisica 2}}
\author{Filippo Antola, Lorenzo Benfatto}
\date{Novembre 2020}

\usepackage{tikz}
\tikzstyle{mybox} = [draw=black, very thick, rectangle, rounded corners, inner ysep=5pt, inner xsep=5pt]
\usepackage[italian]{babel}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{amsmath,amssymb,mathrsfs}
\usepackage{dsfont}
\usepackage{float}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{geometry}
\geometry{a4paper, top=2.5cm, bottom=2.75cm, left=2.5cm, right=2.5cm, heightrounded, bindingoffset=5mm}
\usepackage[unicode]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    }
\usepackage{chngcntr}
\usepackage{epigraph}
\usepackage{fancyhdr}
\usepackage{marginnote}
\usepackage{titlesec}
\usepackage{wrapfig}
\usepackage{xcolor}
\definecolor{mygray}{gray}{0.6}
\definecolor{gold(metallic)}{rgb}{0.83, 0.69, 0.22}
\definecolor{slategray}{rgb}{0.44, 0.5, 0.56}


\newtheorem{definition}{Definizione}[section]
\newtheorem{proposition}{Proposizione}[section]
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\renewcommand\qedsymbol{$\blacksquare$}

\pagestyle{fancy}
\fancyhf{}
%\fancyhead[LE,RO]{\textcolor{gold(metallic)}{LB}}
%\fancyhead[RE,LO]{\textcolor{slategray}{FA}}
\fancyhead[CE,CO]{\includegraphics*[scale=0.09]{Logo.jpg}}
%\fancyfoot[CE,CO]{\textcolor{mygray}{Respice post te. Hominem te memento.}}
\fancyfoot[LE,RO]{\thepage}

\setlength{\headheight}{30pt}% ...at least 51.60004pt

\counterwithin{equation}{section}
\counterwithin{equation}{subsection}
\setlength\parindent{0pt}

\renewcommand{\vec}[1]{\textbf{#1}}


\begin{document}


\maketitle

\titleformat{\section}[display]
{\sffamily\bfseries\filleft}
{\color{mygray}\fontsize{26}{32}\selectfont\thesection}
{0pt}
{\huge\raggedleft}
[{\titlerule[0.7pt]}]


\noindent\rule{\textwidth}{0.7pt}

\vspace{2cm}

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{Complex_gamma_function_abs.png}
\label{fig:polo}
\end{figure}

\vfill

%\begin{figure}[b]
%\centering
%includegraphics[scale=0.4]{Logo(good).jpg}
%\end{figure}
\epigraph{La strada più breve fra due verità del dominio reale passa per il dominio complesso.}{\textit{Jacques Hadamard}}

%\epigraph{Gli uomini muoiono, ma i loro atti restano.}{\textit{Augustin-Louis Cauchy \\ ultime parole}}
\thispagestyle{empty}
\newpage

\section*{Introduzione}
Quanto riportato è una riscrittura in \LaTeX \ delle note fornite dal professor Meggiolaro per il corso di \textit{Metodi Matematici per la fisica 2} tenutosi nell'a.a. 2020-21 (interamente in versione telematica).
\\
Tutti gli errori presenti sono imputabili unicamente agli autori e si pregano i lettori di segnalarli ai seguenti indirizzi per la realizzazione di future versioni corrette:
\begin{itemize}
    \item benfatto.lorenzo@gmail.com
    \item filippoantola312@gmail.com
\end{itemize}
Alcune lezioni sono state riscritte solo parzialmente (specialmente le ultime) e le esercitazioni non sono state contemplate.
\vfill

\begin{comment}
\epigraph{La tristezza durerà per sempre}{\textit{Vincent Van Gogh, \\
biglietto lasciato prima di suicidarsi.}}
\end{comment}
\newpage

\setcounter{definition}{-1}
%\newpage
\setcounter{section}{0}

\tableofcontents


\newpage

\section{Richiami sui numeri complessi}
Si definisce un numero complesso $z$ come una coppia ordinata ($a,b$) con $a,b \in \mathds{R}$. Si indica come:
\begin{equation}
    z=a+ib \ \ \ \text{con} \ \ \ a=Re(z) \ , \ b=Im(z)
\end{equation}
Anche nota come \textit{Rappresentazione algebrica}. \\
I numeri complessi formano un campo con le operazioni di:
\begin{itemize}
    \item \textbf{Somma:} 
    \begin{equation}
        z_1=(a_1,b_1) \ , \ z_2=(a_2,b_2) \ \ \rightarrow \ \ z_1+z_2\equiv(a_1+a_2,b_1+b_2)
    \end{equation}
    Si definiscono:
    \begin{equation}
        1=(1,0) \ \ \ , \ \ \ i=(0,1)
    \end{equation}
    \item \textbf{Prodotto:}
    \begin{equation}
        z_1z_2 \equiv(a_1 a_2 - b_1 b_2, a_1 b_2 + a_2 b_1)
    \end{equation}
\end{itemize}
\'E possibile introdurre anche una \textit{Rappresentazione Geometrica}:
\begin{equation}
    \rho=|z|=\sqrt{a^2 + b^2} \ \Rightarrow \
    \begin{array}{c}
        x=\rho cos(\varphi)  \\
        y=\rho sin(\varphi)
    \end{array} \ \ \varphi = atan\biggl(\frac{b}{a}\biggr)
\end{equation}
$\varphi\equiv Arg(z)$ con $-\infty < \varphi < \infty$ è detto \textit{argomento di z} e, dato che è definito a meno di multipli di $2\pi$, si può anche definire $arg(z)$ con $\varphi_0 \leq arg(z) \leq 2\pi+\varphi_0$ e $\varphi_0$ è un numero arbitrario (che decide la posizione del taglio nella determinazione scelta).
\\
\\
Usando la \textit{Formula di Eulero}:
\begin{equation}
    e^{i\varphi}=cos(\varphi)+isin(\varphi)
\end{equation}
si può scrivere 
\begin{equation} \label{1.0.7}
    z=\rho(cos(\varphi)+isin(\varphi))=\rho e^{i\varphi}
\end{equation}
La (\ref{1.0.7}) è nota come \textit{Rappresentazione esponenziale}.
\\
In tale rappresentazione la regola di prodotto si riduce a:
\begin{equation}
    z_1z_2=\rho_1 \rho_2 e^{i(\varphi_1 + \varphi_2)} \ \ \ ; \ \ \ \frac{z_1}{z_2}=\frac{\rho_1}{\rho_2}e^{i(\varphi_1 - \varphi_2)}
\end{equation}

\subsection{Radici \texorpdfstring{$n$}{Lg}-esime}
Dato l'elevamento a potenza $n$-esima di un numero complesso $z$ si ha:
\begin{equation}
    z=z_0 ^n=\rho_0 ^n e^{in\varphi_0}
\end{equation}

$z_0$ si dice \textit{radice n-esima di z}. \\
Quando si deve fare la radice di un numero complesso risulta allora chiaro qual è il modulo della radice, ma non è banale per la fase.
\begin{equation}
    z=\rho e^{i\varphi} \ \ \Rightarrow \ \ z_0=\sqrt[n]{z}=\rho_0 e^{i\varphi_0} \ \ \ \ \rho_0=\sqrt[n]{\rho} \ \ \ \varphi_0 \ne \frac{\varphi}{n}
\end{equation}
Dato che la fase è definita a meno di multipli di $2\pi$ ci sono $n$ radici $n$-esime, che si indicano:
\begin{equation}
    z_k=\sqrt[n]{\rho}e^{i\varphi_k} \ \ \ \ \ \ \varphi_k=\frac{arg(z)}{n}+\frac{2\pi k}{n} \qquad k=0,1,n-1
\end{equation}

\subsection{Proprietà}
Si ricorda al lettore che il quadrato di un numero complesso è definito come:
\begin{equation}
    |z|^2\equiv z \cdot z^* \ \ \ \Rightarrow \ \ \ |z_1 z_2|=|z_1||z_2|
\end{equation}
Si dimostrano allora le seguenti disuguaglianze (entrambe chiamate triangolari):
\begin{equation}
    |z_1 +z_2| \leq |z_1| + |z_2| \ \ \ \ \ \ \ |z_1 - z_2| \geq ||z_1|-|z_2||
\end{equation}
E in generale risultano utili le relazioni:
\begin{equation}
    \begin{split}
       ||z_1|-|z_2|| \leq |z_1 +z_2| \leq |z_1|+|z_2| \\
       ||z_1|-|z_2|| \leq |z_1 - z_2| \leq |z_1|+|z_2|
    \end{split}
\end{equation}

\subsection{Funzioni di variabile complessa}
Si definisce così una legge $f$ che associa a un $z\in \mathds{C}$ un $\omega=f(z) \in \mathds{C}$:
\begin{equation}
    z\rightarrow\omega=f(z) \ \ \ , \ \ \ \omega=u+iv
\end{equation}
con $u,v=u(x,y),v(x,y)$ funzioni reali.
\begin{equation*}
    u=Re(\omega) \ \ \ \ \ \ \ v=Im(\omega)
\end{equation*}
\\ \\ 
\begin{definition} $\omega_0$ si dice \textbf{limite di $f(z)$ in $z_0$} se
\begin{equation}
    \forall \epsilon >0 \ \exists \delta >0 \ : \ |f(z)-\omega_0|<\epsilon \Rightarrow |z-z_0|<\delta
\end{equation}
E si scrive allora:
\begin{equation}
    \lim_{z \to z_0}f(z)=\omega_0
\end{equation}
\end{definition}

\begin{definition} $f(z)$ si dice \textbf{continua} in $z_0$ se:
\begin{equation}
    \exists \lim_{z \to z_0}f(z)=f(z_0)
\end{equation}
\end{definition}
\subsection{La funzione \texorpdfstring{$\sqrt{z}$}{Lg}}

La funzione $\sqrt[n]{z}$ è una funzione \textit{multivoca} a $n$-rami.
\\
Ossia, fissato $arg(z) \ \text{t.c.} \ 0\leq arg(z) \leq 2\pi$, i valori della funzione sono dati da:
\begin{equation}
    \omega_k(z)\equiv (\sqrt[n]{z})_k = \overline{\sqrt[n]{|z|}} e^{i(\frac{arg(z)}{n}+\frac{2\pi k}{n})}
\end{equation}

Risulta che il piano complesso è "tagliato" e i limiti per la funzione sono diversi a seconda della direzione da cui si approccia il "taglio".
\begin{equation}
    \begin{split}
        \lim_{arg(z) \to 0^+} \omega_k(z)=\overline{\sqrt[n]{|\rho|}}e^{i\frac{2\pi k}{n}} \\
        \lim_{arg(z) \to 2\pi^-} \omega_k(z)=\overline{\sqrt[n]{|\rho|}}e^{i\frac{2\pi (k+1)}{n}}
    \end{split}
\end{equation}

\vspace{3cm}

\subsection{Il punto all'infinito}

Ogni punto al di sopra di una sfera tangente nell'origine a un piano complesso può essere mappato \textit{stereograficamente} in un punto sul piano, come in Figura (\ref{fig:proiezione}).
\\ \\
\begin{figure}[ht]
\centering
\includegraphics[scale=0.2]{proiezione.png}
\label{fig:proiezione}
\caption{Proiezione Stereografica}
\end{figure}

Il polo della sfera opposto lungo il diametro a quello tangente al piano viene mappato "all'infinito".
\\
In maniera più rigorosa:
\begin{equation}
    \exists \lim_{z \to \infty}f(z)=\omega_0 \ \iff \ \forall \epsilon >0 \ \exists R>0 \ : \ |f(z)-\omega_0|<\epsilon \Rightarrow |z|>R
\end{equation}
Ossia $\{z \ : \ |z|>R \}$ è un intorno del punto all'infinito.












\newpage
\section{Derivabilità in senso complesso}
\begin{comment}
\begin{wrapfigure}[7]{L}{0.05\textwidth}
  \begin{center}
    \includegraphics[width=0.2\textwidth]{Eulero.jpg}
  \end{center}
\end{wrapfigure}\leavevmode

\vspace{1.5cm}

\epigraph{Ora avrò minore occasione di distrazione.}{\textit{Leonhard Euler,\\dopo aver perso la vista dall'occhio destro}}

\vspace{1.5cm}
\end{comment}

Sia $f(z)$ definita in un dominio $D$ aperto e connesso del piano complesso $\mathds{C}$.\\
Si dice che $f(z)$ è \textbf{derivabile/differenziabile in senso complesso} in $z_0$ se 
\begin{equation}
	\exists \lim\limits_{z\to z_zo}\frac{f(z)-f(z_0)}{z-z_0}=\lim\limits_{\Delta z\to 0}\frac{f(z_0+\Delta z)-f(z_0)}{\Delta z}
\end{equation}
In tal caso il limite coincide con la \textbf{derivata complessa di $f(z)$ in $z_0$}, indicata come $f'(z_0)$.\\
Il rapporto $\frac{f(z_0+\Delta z)-f(z_0)}{\Delta z}$ viene detto \textbf{rapporto incrementale}.\\
La derivata in senso complesso è una condizione più forte rispetto alla derivabilità in senso reale.\\
\subsection{Le condizioni di Cauchy Riemann}
\begin{theorem}f è derivabile in senso complesso in $z_0=x_0+iy_0$ $\Longrightarrow$ f è derivabile anche in senso reale, ovvero nel punto$(x_0,y_0)$ esistono:\end{theorem}
\begin{equation}
	 f_x\equiv\frac{\partial f}{\partial x} \quad f_y\equiv\frac{\partial f}{\partial y}
\end{equation}	
\textit{E valgono le condizioni di Cauchy Riemann:}
\begin{equation} \label{CR}
	f_x+if_y=0\end{equation}	\begin{proof}
    f è derivabile in senso complesso in $z_0$ esiste il limite del rapporto incrementale $\exists \lim\limits_{\Delta z\to 0}\frac{\Delta f}{\Delta z}\biggl|_{z_0}$ indipendentemente da come $\Delta z$ tenda a 0. Si prende dapprima $\Delta z=\Delta x+i\Delta y=\Delta x$:
    \begin{equation}
        \lim_{\Delta x\to 0 }\frac{f(x_0+\Delta x,y_0)-f(x_0,y_0)}{\Delta x}\equiv \frac{\partial f}{\partial x}\biggl|_{(x_0,y_0)}=f'(z_0)
    \end{equation}
    Viceversa prendendo $\Delta z=i\Delta y$:
    \begin{equation}
        \lim_{\Delta y\to 0 }\frac{f(x_0,y_0+\Delta y)-f(x_0,y_0)}{i\Delta y}\equiv \frac{1}{i}\frac{\partial f}{\partial y}\biggl|_{(x_0,y_0)}=f'(z_0)
    \end{equation}
    Si è dunque trovato che:
    \begin{equation}
        f'(z_0)=f_x(x_0,y_0)=-if_y(y_0)\Longrightarrow f_x(x_0,y_0)+if_y(x_0,y_0)=0
    \end{equation}
\end{proof}

\begin{theorem}
f differenziabile in senso reale $\forall\ (x_0,y_0) \in D$ dominio di definizione e valgono le condizioni di Cauchy-Riemann $\Longrightarrow$ f(z) è derivabile in senso complesso in $z_0=x_0+iy_0$ e vale 
\end{theorem}
\begin{equation}
	f'(z_0)=f_x(x_0,y_0)=-if_y(x_0,y_0)
\end{equation}
\begin{proof} Si usa la differenziabilità in senso reale:
    \begin{equation}
        \Delta f\equiv f(x_0+\Delta x, y_0+\Delta y)-f(x_0,y_0)=f_x(x_0,y_0)\Delta x+ f_y(x_0,y_0)\Delta y+ \sigma (|\Delta z|)
    \end{equation}
    Usando le condizioni di Cauchy-Riemann:
    \begin{equation}
        \Delta f=f_x(x_0,y_0)(\Delta x+i\Delta y)+\sigma(\Delta z)=f_x(x_0,y_0)\Delta z+\sigma(\Delta z)
    \end{equation}
    Da cui:
    \begin{equation}
        \exists \lim_{\Delta z\to 0}\frac{\Delta f}{\Delta z}=f_x(x_0,y_0)=-if_y(x_0,y_0)
    \end{equation}
\end{proof}

\subsection{Funzioni Analitiche}
	Si dice che $f(z)$ è \textbf{analitica o olomorfa} in un dominio $D\subset \mathbb{C}$ se è derivabile in senso complesso $\forall z \in D$, con derivata prima continua.\\
	Se $f(z)$ è analitica su tutto il piano complesso, allora è detta \textbf{intera}.\\
	Dai teoremi precedenti segue che $f(z)$ è analitica in $D$ \textit{se e solo se} $f(x,y)$ è differenziabile in senso reale in $D$ con derivate prime continue e tali da soddisfare le condizioni di Cauchy-Riemann (\ref{CR}).\\
	\\
	Spesso si scrive $f(z)$ in base alle componenti reale ed immaginaria $f=u+iv$.\\
	Affinche la funzione soddisfi le condizioni di Cauchy-Riemann è necessario che
	\begin{equation}
		f_x+if_y=u_x+iv_x+i(u_y+iv_y)=u_x-v_y+i(v_x+u_y)=0 \Longrightarrow \begin{cases}
		u_x=v_y\\u_y=-v_x
		\end{cases}
	\end{equation}
	Inoltre per $f(z)$ non necessariamente analitica, ma derivabile in senso reale si definiscono gli operatori differenziali complessi:
	\begin{equation}
	\frac{\partial f}{\partial z}\equiv \frac{1}{2}(f_x-if_y) \qquad	\frac{\partial f}{\partial z^*}\equiv \frac{1}{2}(f_x+if_y)
	\end{equation}
	Ad esempio se $t=x+iy$ allora $\frac{\partial t}{\partial z}=1,\ \frac{\partial t}{\partial z^*}=0$, mentre per $g=f^*=x-iy$ $\frac{\partial g}{\partial z}=0,\ \frac{\partial g}{\partial z^*}=1$.\\
	In particolare se $f(z)$ è analitica:
	\begin{equation}
	\exists\ f'(z)=f_x=-if_y \Longrightarrow \frac{\partial f}{\partial z^*}=0, \frac{\partial f}{\partial z}= f'(z)
	\end{equation}
	Allo stesso modo se $f(z)$ è derivabile in senso reale come da ipotesi è facile osservare come valga anche l'affermazione inversa.\\
	Questo significa che $t$ è analitica, mentre $g$ non lo è.Allo stesso modo $f(z)=x$ oppure $f(z)=iy$, pur essendo derivabili in senso reale, non sono analitiche perchè non soddisfano le condizioni di Cauchy-Riemann (\ref{CR}).\\
	Esempi semplici di funzioni analitiche sono $f(z)=az+b$ con $a,b \in \mathds{C}$:
	\begin{equation}
		\lim\limits_{\Delta z\to 0}\frac{\Delta f}{\Delta z}=\lim\limits_{\Delta z\to 0}\frac{a(z+\Delta z)+b-(az+b)}{\Delta z}=a \Longrightarrow \exists\ f'(z)=a
	\end{equation}
	Oppure $f(z)=z^n$:
	\begin{equation}
	\lim\limits_{\Delta z\to 0}\frac{(z+\Delta z)^n-z^n}{\Delta z}=\lim\limits_{\Delta z\to 0}\frac{z^n+n\Delta zz^{n-1})-z^n}{\Delta z}=nz^{n-1} \Longrightarrow \exists\ f'(z)=nz^{n-1}
	\end{equation}
	\subsubsection{Proprietà delle funzioni analitiche}
    \begin{theorem}[analiticità implica continuità]
	Se f(z) è analitica in $z_0$ $\in$ D $\Longrightarrow$ f(z) è continua in $z_0$.
	\end{theorem}
	\begin{proof} 
	\begin{equation}
	    \exists f'(z_0)=\lim_{\Delta z \to 0} \frac{\Delta f}{\Delta z} \ \Rightarrow \ \exists \lim_{\Delta z \to 0}\Delta f =0 \ \ \Rightarrow \ \ \lim_{\Delta z \to 0}f(z_0+\Delta z)=f(z_0)
	\end{equation}
	\end{proof}
	\begin{theorem}[operazioni con funzioni analitiche]:
	f(z) e g(z) analitiche  in D$\Longrightarrow$ f(z)+g(z) e f(z)g(z) sono funzioni analitiche in D, $\frac{f(z)}{g(z)}$ è analitica $\forall$ z $\in$ D tale che g(z)$\ne$ 0, e viceversa.\\
	Inoltre (f(z)+g(z))'=f'(z)+g'(z), (f(z)g(z))'=f'(z)g(z)+f(z)g'(z) e $\left(\frac{f(z)}{g(z)}\right)$'=$\frac{f'(z)g(z)+f(z)g'(z)}{f(z)^2}$\\
	\end{theorem} 
	\begin{theorem}[derivata della funzione composta]
	$\omega$=f(z) analitica in D, $\eta$=g($\omega$) analitica in G=f(D) $\Longrightarrow$ $\eta$=g(f(z))$\equiv$F(z) è analitica in D e F'($z_0$)=g'($f(z_0)$)f'($z_0)$ \end{theorem}
	\begin{theorem}[derivata della funzione inversa]
	$\omega$=f(z) analitica in D, $|f'(z)|\ne 0$ nell'intorno di un punto $z_0$ $\Longrightarrow$ nell'intorno di $\omega_0=f(z_0)$ $\in$ G=f(D) è definita la funzione inversa $\eta=f^{-1}(\omega)$ ed è analitica con $\eta'=(f^{-1})'=\frac{1}{f'(z_0)}$\end{theorem}
	
	\subsection{Coordinate polari}
	Spesso è conveniente esprimere una funzione complessa in coordinate polari.\\
	Se si suppone $f(z)$ sia derivabile in senso reale rispetto a $\rho$ e $\phi$, si ottengono le relazioni:
	\begin{equation}
		\frac{\partial f}{\partial\rho}=\frac{\partial f}{\partial x}\frac{\partial x}{\partial\rho}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial\rho}=f_xcos\phi+f_ysin\phi
	\end{equation}
	\begin{equation}
		\frac{1}{\rho}\frac{\partial f}{\partial\phi}=\frac{1}{\rho}\left(\frac{\partial f}{\partial x}\frac{\partial x}{\partial\phi}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial\phi}\right)=-f_xsin\phi+f_ycos\phi
	\end{equation}
	Combinando queste equazioni e sfruttando la relazione di Eulero si ottiene:
	\begin{equation}
	\frac{\partial f}{\partial\rho}+i\frac{1}{\rho}\frac{\partial f}{\partial\phi}=(f_x+if_y)e^{-i\phi} \qquad \frac{\partial f}{\partial\rho}-i\frac{1}{\rho}\frac{\partial f}{\partial\phi}=(f_x-if_y)e^{i\phi}
	\end{equation}
	Per cui se $f(z)$ soddisfa la condizione di Cauchy-Riemann (\ref{CR}) è necessario che:
	\begin{equation}
	f_x+if_y=0\Longleftrightarrow \frac{\partial f}{\partial\rho}+i\frac{1}{\rho}\frac{\partial f}{\partial\phi}=0
	\end{equation}
	Se si pone $f(z)=u+iv$:
	\begin{equation}
		\frac{\partial u}{\partial\rho}-\frac{1}{\rho}\frac{\partial v}{\partial \rho}+i\left(\frac{1}{\rho}\frac{\partial u}{\partial \phi}+\frac{\partial v}{\partial\rho}\right)=0 \Longleftrightarrow \begin{cases} \frac{\partial u}{\partial\rho}=\frac{1}{\rho}\frac{\partial v}{\partial \rho}\\
		\frac{1}{\rho}\frac{\partial u}{\partial \phi}=-\frac{\partial v}{\partial\rho}\end{cases}
	\end{equation}
	Inoltre se $f(z)$ è analitica, quindi valgono le condizioni di Cauchy-Riemann (\ref{CR}), la sua derivata risulta uguale a:
	\begin{equation}
	f'(z)=f_x=-if_y=\frac{1}{2}(f_x-if_y)=\frac{1}{2}\biggl(\frac{\partial f}{\partial\rho}-i\frac{1}{\rho}\frac{\partial f}{\partial\phi}\biggr)e^{-i\phi}=\frac{\partial f}{\partial\rho}e^{-i\phi}=-i\frac{1}{\rho}\frac{\partial f}{\partial\phi}e^{-i\phi}
	\end{equation}
	
	\begin{comment}
	
	\subsubsection{Esempi dell'uso delle coordinate polari}
	\begin{itemize}
		\item $f(z)=\frac{1}{z}$ è un rapporto di funzioni analitiche, per cui è analitica $\forall z \ne$0. Si verificano facilmente le condizioni di Cauchy-Riemann e la sua derivata prima...
		\item $f(z)=z^n$...\\
		Mega contoni per dimostrare cose banali con le coordinate polari, per ora salto.\\
	\end{itemize}
	
	\end{comment}
	
	\subsection{Funzione esponenziale complessa}
	Si definisce come:
	\begin{equation}
		e^z\equiv e^xe^{iy}=e^x(cosy+iseny)
	\end{equation}
	Per $y=0$ si riduce alla funzione esponenziale reale.\\
	Gode delle usuali proprietà della funzione esponenziale reale:
	\begin{equation}
	e^{z_1}e^{z_2}=e^{z_1+z_2}
	\end{equation}
	Difatti si può dimostrare avendo già dimostrato la tesi sull'asse reale ed immaginario:
	\begin{equation}
		e^{z_1}e^{z_2}=e^{x_1}e^{iy_1}e^{x_2}e^{iy_2}=e^{x_1+x_2}e^{iy_1+iy_2}=e^{z_1+z_2}
	\end{equation}
	Inoltre è una funzione analitica intera e
	\begin{equation*}
		(e^z)'=e^z
	\end{equation*}
	Difatti esistono le derivate in campo reale e vale la condizione di Cauchy-Riemann.\\
	In generale si ha che $F(z)=e^{\alpha z}$ è analitica intera con:
	\begin{equation}\label{2.4.4}
		F'(z)=(e^{\alpha z})'=\alpha e^{\alpha z} \qquad \alpha \in \mathds{C}
	\end{equation}
		\subsection{Le funzioni trigonometriche complesse}
	Si definiscono:
	\begin{equation}
		cos(z)\equiv\frac{e^{iz}+e^{-iz}}{2} \quad sen(z)\equiv\frac{e^{iz}-e^{-iz}}{2i}
	\end{equation}
	Sono funzioni analitiche intere e sull'asse reale coincidono con le funzioni trigonometriche reali. Rappresentano quindi un estensione analitica.\\
	Per calcolare le loro derivate si fa uso della (\ref{2.4.4})  e si trova
	\begin{equation}
		(cosz)'=-senz \quad (senz)'=cosz
	\end{equation}
	Inoltre si generalizza anche la formula di Eulero:
	\begin{equation}
		e^{iz}=cosz+isenz
	\end{equation}
	Inoltre contiuano a valere le relazioni $\forall z,w \in \mathds{C}$:
	\begin{itemize}
		\item $cos^2z+sen^2z=1 $
		\item $cos(z+\omega)=cosz \ cos\omega-senz \ sen\omega$
		\item $sin(z+\omega)=sinz \ cos\omega+cosz \ sen\omega$
	\end{itemize}
	Si possono dimostrare a partire dalla definizione.
    \subsection{Funzioni iperboliche complesse}
    Si definiscono:
    \begin{equation}
        coshz\equiv\frac{e^z+e^{-z}}{2} \qquad senh\equiv\frac{e^z-e^{-z}}{2}
    \end{equation}
    Sono funzioni analitiche intere, rappresentano l'estensione analitica delle rispettive funzioni reali.\\
    Inoltre vale:
    \begin{equation}
        (coshz)'=senhz  \qquad (senhz)'=coshz
    \end{equation}
    E:
    \begin{equation}
        cosh^2z-senh^2z=1
    \end{equation}
    Nonchè le seguenti relazioni con le funzioni trigonometriche complesse:
    \begin{equation}
        coshz=cos(iz) \qquad senhz=-isen(iz)
    \end{equation}
    \subsection{Funzione logaritmo complessa}
    Si definisce come la funzione inversa della funzione esponenziale complessa:
    \begin{equation}
        e^{logz}=z
    \end{equation}
    Scrivendo z in coordinate polari:
    \begin{equation}
       log(z)=log(\rho)+i\phi=log|z|+iArg(z) \quad e^{log(\rho)+i\phi log(e)}=e^{log(\rho)}e^{i\phi}=\rho e^{i\phi}=z
    \end{equation}
    Non è una funzione univoca, si tratta di una funzione multivoca o polidroma a infiniti valori.\\
    Se si fissa $arg(z)$ come una funzione univoca discontinua, ad esempio con immagine da 0 a 2$\pi$, gli infiniti valori o rami della funzione logaritmo sono:
    \begin{equation}
        (logz)_k\equiv log|z|+iarg(z)+i2\pi k \qquad k\in\mathds{Z}
    \end{equation}
    Con la definizione dell'$arg(z)$ come $0\le arg(z)<2\pi$, sono funzioni univoche nel piano complesso tagliato $\mathds{C}/\{z:x\ge0,y=0\}$, con le relazioni:
    \begin{equation}
    \lim_{argz\to0^+}(logz)_k=log\rho + i2\pi k \qquad \lim\limits_{argz\to 2\pi^-}(logz)_k=log\rho + i2\pi (k+1)= \lim_{argz\to0^+}(logz)_{k+1}
    \end{equation}
    La determinazione con $k=0$, sul bordo superiore del taglio coincide con la funzione logaritmo reale e viene detta determinazione principale.\\
    Ciascuna determinazione è una funzione analitica nel suo dominio di definizione, difatti:
    \begin{equation}
        f(z)=log(z)=log(\rho)+i\phi \longrightarrow \frac{\partial f}{\partial \rho}+\frac{i}{\rho}\frac{\partial f}{\partial \phi}=0
    \end{equation}
    Ed inoltre
    \begin{equation}
        (logz)'=\left(\frac{\partial log(z)}{\partial \rho}\right) e^{-i\phi}=\frac{1}{\rho}e^{-i\phi}=\frac{1}{z}
    \end{equation}
    \subsection{Funzione elevamento a potenza complessa}
    Si definisce a partire dall funzione logaritmo complessa:
    \begin{equation}
        z^\alpha\equiv e^{\alpha log(z)}=e^{\alpha(log|z|+iarg(z)+i2\pi k)}=e^{\alpha log|z|}e^{\alpha iarg(z)}e^{\alpha i2\pi k}=|z|^\alpha e^{\alpha iarg(z)}e^{\alpha i2\pi k}
    \end{equation}
    Si osservi che:
    \begin{itemize}
        \item $\alpha \in \mathds{N}$ la funzione è univoca ed analitica intera;
        \item $\alpha=\frac{m}{n}$ con $m,n \in \mathds{N}$ primi fra loro, la funzione è ad $n$ valori;
        \item $\alpha\in \mathds{I}\ o\ \alpha\in \mathds{C}$ ha infiniti valori
    \end{itemize}
    Per quanto riguarda la derivata complessa:
    \begin{equation}
        (z^\alpha)'=\frac{\alpha}{z}e^{\alpha log(z)}=\frac{\alpha}{e^{log(z)}}e^{\alpha log(z)}=\alpha e^{(\alpha-1) log(z)}=\alpha z^{\alpha-1}
    \end{equation}
\newpage

\setcounter{section}{3}

\section{Integrale di una funzione rispetto ad una variabile complessa}

Si considera una curva regolare a tratti di lunghezza $L$:
\begin{equation}
    z(t)=x(t)+iy(t) \ \ \ ; \ \ \ t \in [\aleph,\beth] \ \ \ ; \ \ z(\aleph)=z_{in} \ \ z(\beth)=z_{fin}
\end{equation}

$x(t)$ e $y(t)$ sono funzioni continue e derivabili q.o. con la condizione:
\begin{equation}
    [x'(t)]^2 + [y'(t)]^2 \ne 0
\end{equation}
Si partiziona la curva con
\begin{equation}
    \Delta z_i \equiv z_i - z_{i-1}
\end{equation}

e si definisce l'integrale sulla curva come:
\begin{equation}
    \int_C f(z) \ dz \equiv \lim_{max|\Delta z_i| \to 0} \sum_{i=1} ^n f(z_i) \ \Delta z_i
\end{equation}
se il limite esiste finito per ogni punto e per ogni partizione. \\ \\
Scrivo:\begin{equation}
    z_i=x_i+iy_i \ \rightarrow \ \Delta z_i=\Delta x_i +i\Delta y_i \ \ ; \ \ f(z_i)=u(x_i,y_i)+iv(x_i,y_i)
\end{equation}

Scrivo in questi termini la sommatoria per passare all'integrale
\begin{equation}
    \begin{split}
        \sum_{i=1}^n f(z_i)\Delta z_i=\sum_{i=1}^n \{ u(x_i,y_i)\Delta x_i - v(x_i,y_i)\Delta y_i \} +i \sum_{i=1}^n \{ u(x_i,y_i)\Delta y_i + v(x_i,y_i)\Delta x_i\} \\
        \rightarrow \ max|\Delta z_i| \to 0 \ \rightarrow \ \int_C \{ u(x,y)dx - v(x,y)dy  \} +i \int_C \{ v(x,y)dx+u(x,y)dy \}
    \end{split}
\end{equation}
Trovando come risultato generale 
\begin{equation}
    \int_C f(z) \ dz = \int_C \{ u(x,y)dx - v(x,y)dy  \} +i \int_C \{ v(x,y)dx+u(x,y)dy \}
\end{equation}


\subsection{Proprietà dell'integrale in una variabile complessa}
Si elenca una serie di risultati:
\begin{itemize}
    \item \begin{equation}
        \int_{-C}f(z) \ dz= - \int_C f(z) \ dz
    \end{equation}
    \item \begin{equation}
        \int_{C=C_1 \circ C_2} f(z) \ dz= \int_{C_1} f(z) \ dz + \int_{C_2} f(z) \ dz
    \end{equation}
    \item \begin{equation}
        \int_C \{ \alpha f_1(z) +\beta f_2(z) \} \ dz= \alpha \int_C f_1 (z) \ dz + \beta \int_C f_2(z) \ dz \ \ , \ \ \forall \alpha, \beta \in \mathds{C}
    \end{equation}
    \item \begin{equation} \label{3.1.4}
        \left|\int_C f(z) \ dz\right| \leq \int_C |f(z)| \ ds
    \end{equation}
    con $ds\equiv |dz|$ elemento differenziale di lunghezza della curva $C$. $ds$ è il limite di 
    \begin{equation}
        \Delta s_i \equiv |\Delta z_i|=\sqrt{(\Delta x_i)^2 + (\Delta y_i)^2}.
    \end{equation}
\end{itemize}

Dalla (\ref{3.1.4}) discende il:
\begin{lemma}[\textbf{Lemma di Darboux}]\label{4 Darboux}
\label{Darboux}
Se $\max_{z \in \mathds{C}}|f(z)|=M$ e $L=\int_C ds$ è la lunghezza della curva $C$, allora:
\begin{equation}
    \left|\int_C f(z) \ dz \right|\leq ML
\end{equation}
\end{lemma}

\begin{proof}
\begin{equation}
    \left|\int_C f(z) \ dz\right| \leq \int_C |f(z)| \ ds \leq M \int_C ds = ML
\end{equation}
\end{proof}

\begin{itemize}
    \item Detta $z(t)$ una \textit{rappresentazione parametrica} della curva $C$, con $t\in [\aleph,\beth]$, $z(\aleph)=z_{in}$ e $z(\beth)=z_{fin}$, regolare a tratti, si ha:
    \begin{equation}
        \int_C f(z) \ dz=\int_{\aleph} ^{\beth} f[z(t)]\frac{dz}{dt} dt
    \end{equation}
\end{itemize}

\begin{definition} Una curva chiusa regolare a tratti e priva di autointersezioni si dice \textbf{Contorno Chiuso}.
\end{definition}
L'integrale lungo un contorno chiuso si indica:
\begin{equation}
    \oint_C f(z) \ dz
\end{equation}

\begin{definition} Per convenzione si assume come \textbf{verso positivo di percorrenza} di un contorno chiuso quello per cui il dominio interno rimane a sinistra della direzione di percorrenza (ossia è il verso antiorario).
\end{definition}

\textbf{Esempio:}
\\
Si calcoli
\begin{equation} \label{3.1.10}
    I=\oint_{C_R}\frac{dz}{z-z_0}
\end{equation}

Dove $C_R$ è la circonferenza di raggio $R$ e centro in $z_0$ percorsa in senso antiorario.

\begin{center}
\begin{tikzpicture}
\draw (2,2) -- (3.5,2);
\draw[->] (2,2) -- (3.05,3.05);
\draw (2,2) circle (1.5cm);
\draw (3.5,1)  node[anchor=west] {$C_R$};
\draw (2.7,2) arc (0:72:0.4cm) node[anchor=west] {$\ \ \theta$};
\draw[thick,->] (0,0) -- (4.5,0) node[anchor=north west] {Re(z)};
\draw[thick,->] (0,0) -- (0,4.5) node[anchor=south east] {Im(z)};
\foreach \x in {0,1,2,3,4}
   \draw (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\x$};
\foreach \y in {0,1,2,3,4}
    \draw (1pt,\y cm) -- (-1pt,\y cm) node[anchor=east] {$\y$};
    
\filldraw[black] (2,2) circle (2pt);
\draw (2,1.75) node[anchor=west] {$z_0$};
\filldraw[black] (3.05,3.05) circle (1pt)node[anchor=west] {$z=z_0 +Re^{i\theta}$};
\draw[->] (2,0.5) -- (2.01,0.5);
\draw[->] (2.01,3.5) -- (2,3.5);
\end{tikzpicture}
\end{center}

Si utilizza la seguente parametrizzazione della curva $C_R$:
\begin{equation}
    C_R: \ \ z(\theta)=z_0 + R e^{i\theta} \ \ , \ \ \theta \in [0,2\pi]
\end{equation}
Da cui il differenziale diventa:
\begin{equation}
    z-z_0=Re^{i\theta} \ \ \Rightarrow \ \ dz=iRe^{i\theta}d\theta
\end{equation}
L'integrale in (\ref{3.1.10}) diventa:
\begin{equation}
    I=\int_0 ^{2\pi} \frac{iRe^{i\theta} \ d\theta}{Re^{i\theta}}=i\int_0 ^{2\pi} d\theta =2\pi i
\end{equation}
\\ \\
Si può estendere poi un risultato dall'analisi reale in più variabili:

\begin{theorem}[\textbf{Formula di Green}] \label{Green}
Date due funzioni $A(x,y)$ e $B(x,y)$ continue in un dominio chiuso $\Bar{G}$ limitato da un contorno regolare a tratti $C$ e con derivate parziali del primo ordine continue in $G$ vale:
\begin{equation}
    \int_C Adx+Bdy=\iint_G \biggl\{ \frac{\partial B}{\partial x} - \frac{\partial A}{\partial y} \biggr\} \ dx \ dy
\end{equation}
\end{theorem}

\begin{definition} Un dominio $\Omega$ si dice \textbf{Semplicemente Connesso} quando ogni curva semplice e chiusa $\Gamma$ contenuta in $\Omega$ è frontiera di un dominio $D$ contenuto in $\Omega$.
\end{definition}
\subsection{Teoremi di Cauchy}
Si enunciano e dimostrano ora tre versione di un teorema importante in analisi complessa:
\begin{theorem}[\textbf{Th. di Cauchy v.1}] \label{Cauchy}
Sia $f(z)$ analitica in un dominio $G$ semplicemente connesso. Allora
\begin{equation}
    \oint_{\Gamma} f(z) \ dz=0
\end{equation}
$\forall$ contorno chiuso $\Gamma$ completamente contenuto in $G$.
\end{theorem}

\begin{proof}
Essendo $G$ semplicemente connesso il contorno chiuso $\Gamma$ è la frontiera di un dominio $D$ ($\Gamma=\partial D$) contenuto in $G$ in cui $f(z)$ è analitica.
\\
Applico la formula (\ref{Green}) e trovo:
\begin{equation} \begin{split}
    \oint_{\Gamma} f(z) \ dz = \int_{\Gamma} \{u dx - v dy \} + i\oint_{\Gamma} \{v dx + u dy \} = \\
    =\iint_D \biggl\{ - \frac{\partial v}{\partial x} - \frac{\partial u}{\partial y} \biggr\} \ dx \ dy + i \iint_D \biggl\{ \frac{\partial u}{\partial x} - \frac{\partial v}{\partial y} \biggr\} \ dx \ dy =0
\end{split}\end{equation}

Difatti per le condizioni di C.R. (\ref{CR}) risulta
\begin{equation}
    \frac{\partial u}{\partial x}=\frac{\partial v}{\partial y} \ \ \ \ \ \ \ \ \frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}
\end{equation}
Oppure più concisamente:
\begin{equation}
    \oint_{\Gamma}f(z) \ dz = \oint_{\Gamma} \{ f \ dx + if \ dy \}= \iint_D \{if_x -f_y\}\ dx \ dy=0
\end{equation}
\end{proof}

\begin{theorem}[\textbf{Th. di Cauchy v.2}] \label{Cauchy 2}
Sia $f(z)$ analitica in un dominio $G$ semplicemente connesso limitato da un contorno regolare a tratti $C$ e continua nel chiuso $\Bar{G}$. Allora:
\begin{equation}
    \oint_{C=\partial G}f(z) \ dz=0
\end{equation}
\end{theorem}

\begin{theorem}[\textbf{Th. di Cauchy v.3}]
Sia $f(z)$ analitica in un dominio $G$ a connessione multipla, limitato esternamente dal contorno $C_0$ e internamente dai contorni $C_1,...,C_n$ e sia $f(z)$ continua nel chiuso $\Bar{G}$.
\\
Allora, detta $C$ la frontiera totale del dominio $G$ formata dai contorni:
\begin{itemize}
    \item $C_0$ percorso nel verso positivo.
    \item $C_1,...,C_n$ percorsi nel verso negativo.
\end{itemize}
si ha:
\begin{equation}
    \oint_{C=\partial G}f(z) \ dz= \oint_{C_0 ^+}f(z) \ dz + \oint_{C_1 ^-}f(z) \ dz + ... + \oint_{C_n ^-}f(z) \ dz=0
\end{equation}
\end{theorem}

\begin{proof}
Unendo il contorno $C_0$ ai contorni $C_1,...,C_n$ con curve regolari $\gamma_1,...,\gamma_n$ si individua un contorno chiuso $\Tilde{C}$, in cui ogni curva $\gamma_i$ è percorsa due volte (in sensi opposti), che racchiude un dominio $\Tilde{G}$ semplicemente connesso. 
 \begin{center}
    \includegraphics[width=0.5\textwidth]{cauchi v.3.JPG}
  \end{center}

Si applica allora (\ref{Cauchy 2}):
\begin{equation}
    \oint_{\Tilde{C}=\partial \Tilde{G}}f(z) \ dz= \oint_{C_0 ^+}f(z) \ dz + \int_{\gamma_1}f(z) \ dz + \oint_{C_1 ^-}f(z) \ dz + \int_{-\gamma_1}f(z) \ dz + \int_{\gamma_2}f(z) \ dz + ... =0
\end{equation}

Che, semplificando gli integrali sulle $\gamma_i$, diventa:
\begin{equation}
    \oint_{C=\partial G}f(z) \ dz= \oint_{C_0 ^+}f(z) \ dz + \oint_{C_1 ^-}f(z) \ dz+\oint_{C_2 ^-}f(z) \ dz + ...=0
\end{equation}

\end{proof}

\subsection{L'integrale indefinito (primitiva) di una funzione analitica}

Se $f(z)$ è una funzione analitica in un dominio $G$ semplicemente connesso, presi due punti $z_0,z \in G$ e due cammini qualsiasi $\Gamma_1, \ \Gamma_2$ che li connettono, in virtù di (\ref{Cauchy}) si ha:
\begin{equation}
    \int_{\Gamma_1}f(\eta) \ d\eta=\int_{\Gamma_2}f(\eta) \ d\eta
\end{equation}
In questo caso si scrive sono:
\begin{equation}
   \int_{\Gamma_1}f(\eta) \ d\eta=\int_{\Gamma_2}f(\eta) \ d\eta\equiv\int_{z_0}^{z}f(\eta) \ d\eta\equiv F(z) 
\end{equation}
dal momento che l'integrale non dipende dalla scelta del cammino, ma solo dagli estremi.
\\
\begin{theorem} \label{F(z)}
Sia $f(z)$ definita e continua in un dominio semplicemente connesso $G$ e tale che $\forall \ \Gamma$ contorno chiuso valga
\begin{equation}
    \oint_{\Gamma}f(\eta) \ d\eta=0
\end{equation}
Allora la funzione $F(z)\equiv \int_{z_0}^{z} f(\eta) \ d\eta$ è una funzione analitica in $G$ e inoltre:
\begin{equation}
    F'(z)=f(z)
\end{equation}
\end{theorem}

\begin{proof}
Si considerino le $\Gamma_i$ che connettono i punti $z_0$ e $z$:
\begin{equation}
    \oint_{\Gamma}f(\eta) \ d\eta=0 \ \ \Rightarrow \ \  \int_{\Gamma_1}f(\eta) \ d\eta=\int_{\Gamma_2}f(\eta) \ d\eta\equiv\int_{z_0}^{z}f(\eta) \ d\eta\equiv F(z) \ \ \forall \ \Gamma_1,\Gamma_2
\end{equation}
Scrivo allora il rapporto incrementale di $F(z)$:
\begin{equation} \label{3.3.6} \begin{split}
    \frac{\Delta F}{\Delta z}=\frac{F(z+\Delta z) - F(z)}{\Delta z}=\frac{1}{\Delta z} \biggl \{ \int_{z_0}^{z+\Delta z} f(\eta) \ d\eta - \int_{z_0}^{z} f(\eta) \ d\eta \biggr\}= \\ \frac{1}{\Delta z} \biggl \{ \int_{z_0}^{z} f(\eta) \ d\eta + \int_{z}^{z+\Delta z} f(\eta) \ d\eta  - \int_{z_0}^{z} f(\eta) \ d\eta \biggr\}=  \frac{1}{\Delta z} \int_{z}^{z+\Delta z} f(\eta) \ d\eta
\end{split}\end{equation}

Scegliendo nell'ultimo integrale il cammino rettilineo tra $z$ e $z+\Delta z$ parametrizzato:
\begin{equation}
    \eta(t)=z+t\Delta z \ \ , \ \ t \in [0,1]
\end{equation}

La (\ref{3.3.6}) diventa:
\begin{equation}
    \frac{\Delta F}{\Delta z}=\frac{1}{\Delta z}\int_0 ^1 f(\eta(t))\frac{d\eta}{dt}dt=\frac{1}{\Delta z}\int_0 ^1 f(z+t\Delta z) \Delta z \ dt = \int_0 ^1 f(z+t\Delta z) dt \ \xrightarrow{\Delta z \to 0}f(z) \int_0 ^1 dt=f(z)
\end{equation}
Dato che
\begin{equation}
    \exists \lim_{\Delta z \to 0} \frac{\Delta F}{\Delta z}\equiv F'(z)=f(z)
\end{equation}
con $F'(z)$ continua, allora $F(z)$ è analitica in $G$.

\end{proof}

\begin{definition} La funzione $F(z)$ tale che $F'(z)=f(z)$ si dice \textbf{Integrale indefinito} o \textbf{Primitiva} di $f(z)$.
\end{definition}


\newpage
\section{L'integrale di Cauchy}
\subsection{Formula di Cauchy}
\begin{theorem}[\textbf{II Teorema di Cauchy, I versione}] \label{II Cauchy 1v}
f(z) analitica in un dominio G semplicemente connesso e limitato dal contorno C.\\
Sia $z_0$ $\in$ G e $\Gamma$ contorno chiuso completamente contenuto in G $\Longrightarrow$ vale la \textbf{formula di Cauchy:}
\begin{equation}\label{4.1.1}
    f(z_0)=\frac{1}{2\pi i}\oint_{\Gamma^+}\frac{f(z)}{z-z_0}dz
\end{equation}

\end{theorem}

\begin{proof} 
Si introduce la funzione 
\begin{equation}
    \phi(z)\equiv \frac{f(z)}{z-z_0}
\end{equation}
che è analitica in tutto $G$ tranne che in $z_0$.
\begin{center}
    \includegraphics[width=0.5\textwidth]{2cauchyv1.JPG}
\end{center}
Considerando il dominio $D$ in figura si trova, applicando il (\ref{Cauchy}):
\begin{equation}
    \oint_{\Gamma^+}\frac{f(z)}{z-z_0}dz+\oint_{\gamma^-}\frac{f(z)}{z-z_0}dz=0 \ \ \ \Rightarrow \ \ \ \oint_{\Gamma^+}\frac{f(z)}{z-z_0}dz=\oint_{\gamma^+}\frac{f(z)}{z-z_0}dz
\end{equation}
Considerando in particolare una curva $\gamma_{\rho}$ parametrizzata come:
\begin{equation}
    \gamma_{\rho}: \ \ z(\theta)=z_0+\rho e^{i\theta} \ \ \ \ \ \theta \in [0,2\pi]
\end{equation}
Si ha
\begin{equation}
    \oint_{\Gamma^+}\frac{f(z)}{z-z_0}dz=\oint_{\gamma_{\rho^+}}\frac{f(z)}{z-z_0}dz=i\int_{0}^{2\pi}f(z_0+\rho e^{i\theta})d\theta
\end{equation}
Ma dato che il primo membro di quest'uguaglianza non dipende da $\rho$, non vi può dipendere nemmeno il secondo, per cui lo si calcola per $\rho \to 0$
\begin{equation}
    \oint_{\Gamma^+}\frac{f(z)}{z-z_0}dz=\lim_{\rho \to 0}i\int_{0}^{2\pi}f(z_0+\rho e^{i\theta})d\theta=if(z_0)\int_0^{2\pi}d\theta=2\pi i f(z_0)
\end{equation}
E dividendo per $2\pi i$ si trova la tesi.


\end{proof}

\begin{theorem}[\textbf{II teorema di Cauchy, II e III versione}]\label{II Cauchy 2.3v}
f(z) analitica in un dominio G semplicemente connesso e limitato dal contorno C, continua nel dominio chiuso $\Bar{G}$ e $z_0$ $\in$ G.
\begin{equation}
    f(z_0)=\frac{1}{2\pi i}\oint_{C=\partial G^+}\frac{f(z)}{z-z_0}dz
\end{equation}
La formula vale anche nel caso in cui G sia un dominio a connessione multipla, considerando come $C=\partial G$ la frontiera totale del dominio G.\\
\end{theorem}

Se il punto $z_0$ si trovasse invece all'esterno di $\Gamma$, la funzione sarebbe analitica nel dominio da essa contenuto per cui l'integrale farebbe 0.\\
Rimane da discutere il caso limite in cui $z_0$ $\in$ $\Gamma$, in questo caso l'integrale non risulta, in generale, ben definito.
\subsubsection{Valore principale di Cauchy}
Facendo riferimento alla formula di Cauchy, si consideri il caso $z_0$ $\in$ $\Gamma$.
\\
Se $\Gamma$ è derivabile in $z_0$ (geometricamente esiste la tangente alla curva in tal punto) allora l'integrale esiste nel senso di valore principale di Cauchy
\begin{equation}
   \frac{1}{2\pi i}\mathscr{P}\oint_{\Gamma}\frac{f(z)}{z-z_0}dz=\lim_{\epsilon\to 0}\frac{1}{2\pi i}\oint_{\Gamma_\epsilon}\frac{f(z)}{z-z_0}dz
\end{equation}
Con $\Gamma_\epsilon$ parte del contorno $\Gamma$ al di fuori del cerchio $|z-z_0|<\epsilon$, da cui
\begin{equation}
    \frac{1}{2\pi i}\mathscr{P}\oint_{\Gamma}\frac{f(z)}{z-z_0}dz=\frac{1}{2}f(z_0)
\end{equation}
\\
Se invece $f(z)$ soddisfacesse:
\begin{equation}
    |f(z_1)-f(z_2)|\le k|z_1-z_2|^\gamma \qquad 0<\gamma\le 1 \quad \forall z_1,z_2\in G
\end{equation}
detta condizione di Holder ($\gamma<1$) o Lipschitz ($\gamma=1$), allora l'integrale esisterebbe come valore principale secondo Cauchy, ma in generale non corrisponderebbe a $\frac{1}{2}f(z_0)$.\\
Si noti come tale condizione implichi continuità, senza che sia vero in generale l'affermazione inversa.
\subsection{Formula del valor medio}
Si consideri nella formula di Cauchy (\ref{4.1.1}) una circonferenza $C_R$ di raggio R e centro $z_0$, contenuta completamente nel dominio $G$ della funzione $f(z)$ al posto di $\Gamma$:
\begin{equation}
    f(z_0)=\frac{1}{2\pi i}\oint_{C_r}\frac{f(z)}{z-z_0}dz=\frac{1}{2\pi i}\oint_{C_r}\frac{f(z_0+Re^{i\theta})}{Re^{i\theta}}iRe^{i\theta}d\theta=\frac{1}{2\pi}\oint_{C_r}f(z_0+Re^{i\theta})d\theta
\end{equation}
Riassumendo:
\begin{equation}
    f(z_0)=\frac{1}{2\pi}\oint_{C_r}f(z_0+Re^{i\theta})dz
\end{equation}
\begin{center}
\begin{tikzpicture}
\draw (2,2) -- (3.5,2);
\draw[->] (2,2) -- (3.05,3.05);
\draw (2,2) circle (1.5cm);
\draw (3.5,1)  node[anchor=west] {$C_R$};
\draw (2.7,2) arc (0:72:0.4cm) node[anchor=west] {$\ \ \theta$};
\draw[thick,->] (0,0) -- (4.5,0) node[anchor=north west] {Re(z)};
\draw[thick,->] (0,0) -- (0,4.5) node[anchor=south east] {Im(z)};
\foreach \x in {0,1,2,3,4}
   \draw (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\x$};
\foreach \y in {0,1,2,3,4}
    \draw (1pt,\y cm) -- (-1pt,\y cm) node[anchor=east] {$\y$};
    
\filldraw[black] (2,2) circle (2pt);
\draw (2,1.75) node[anchor=west] {$z_0$};
\filldraw[black] (3.05,3.05) circle (1pt)node[anchor=west] {$z=z_0 +Re^{i\theta}$};
\draw[->] (2,0.5) -- (2.01,0.5);
\draw[->] (2.01,3.5) -- (2,3.5);
\end{tikzpicture}
\end{center}
\subsection{Principio del massimo modulo di una funzione analitica}\label{massimo modulo}
\begin{theorem}
Sia f(z) analitica nel dominio G connesso e limitato e continua sul dominio chiuso $\partial \Bar{G}$, allora:
\begin{itemize}
    \item il massimo modulo $\max_{z\in G}|f(z)|$ è assunto sulla frontiera $\partial \Bar{G}$ o
    \item $|f(z)|$ costante
\end{itemize}
\end{theorem}
\begin{proof}
Si scrive $f(z)=u+iv$, se ne calcola il modulo:
\begin{equation}
    |f(z)|=\sqrt{u^2(x,y)+v^2(x,y)}
\end{equation}
Per ipotesi è una funzione reale di 2 variabili, continua nel dominio chiuso e limitato $\Bar{G}$: per il teorema di Weierstrass assume il valore massimo in un punto del dominio:
\begin{equation}
    M=max_{z \in \Bar{G}}|f(z)|=|f(z_0)| \qquad z_0\in \Bar{G}
\end{equation}
Suppongo $z_0\in G$, sia allora $\Bar{z}$ altro punto interno a G e $\gamma$ una curva completamente contenuta in G che li contenga. Si definisce:
\begin{equation}
    d\equiv dist(\gamma,\partial G)\equiv min|z_2-z_1| \qquad \text{con } z_1\in\gamma, z_2\in\partial G
\end{equation}
Si consideri la circonferenza $k_0$ centrata in $z_0$ e di raggio $R=\frac{d}{2}$, in modo che siano contenute in G. Si trova:
\begin{equation}
    M=\frac{1}{2\pi}\left|\int_0^{2\pi}f(z_0+Re^{i\theta})d\theta\right|\le\frac{1}{2\pi}\int_0^{2\pi}\left|f(z_0+Re^{i\theta})\right|d\theta\le \frac{M}{2\pi}\int_0^{2\pi}d\theta=M
\end{equation}
Di conseguenza:
\begin{equation}
    \int_0^{2\pi}\left|f(z_0+Re^{i\theta})\right|d\theta=2\pi M
\end{equation}
Per cui dato che $|f(z)|\le M\ \forall z \in \Bar{G}$ si deduce che:
\begin{equation}
    |f(z)|=M \quad \forall z\in k_0
\end{equation}
lo stesso vale per ogni circonferenza di centro $z_0$ e raggio minore di $\frac{d}{2}$.\\
Se $z_1$ è l'ultimo punto di intersezione fra $k_0$ e $\gamma$ si ripete il procedimento considerando la circonferenza $k_1$ di centro $z_1$ e raggio $R$. Si può quindi iterare il procedimento sino $\Bar{z}$.\\
Di conseguenza $|f(z)|=M\  \forall z \in G$ e, per continuità:
\begin{equation}
    |f(z)|=M \qquad \forall z \in \partial G
\end{equation}
Per cui se la funzione non è costante il punto di massimo deve appartenere alla frontiera del dominio.\\
\end{proof} 
Analogamente se risultano verificate tali ipotesi vale anche il \textbf{principio del minimo modulo}, secondo cui o il modulo funzione è costante oppure il minimo valore della funzione viene assunto sulla frontiera.\\
\begin{theorem}
f(z) è analitica in un dominio G
\begin{equation}
|f(z)|=\text{costante}\ \forall z \in G \Longleftrightarrow f(z)=costante \ \forall z\in G  
\end{equation}
\end{theorem}
\begin{proof}
se $|f(z)|=\sqrt{u^2+v^2}=k$ costante allora $|f(z)|^2=u^2+v^2=k^2$.\\
Se $k=0$, si tratta del caso banale di $f(z)=0$.\\
Se $k\ne0$ si derivi il modulo quadro rispetto a $x$ e $y$, dopodichè sfruttando le condizioni di C.R.:
\begin{equation}
    \begin{cases}
    2uu_x+2vv_x=0\\
    2uu_y+2vv_y=0
    \end{cases} \qquad
    \begin{cases}
    uu_x-vu_y=0\\
    vu_x+uu_y=0
    \end{cases}
\end{equation}
Si ricava che $u_x=u_y=0$ e per cui $v_x=v_y=0$ dalle condizioni di C.R..
\end{proof}

\subsection{Integrali dipendenti da un parametro}
\begin{theorem}\label{int par}
g(z,$\eta$) funzione di due variabili complesse, z $\in$ G (aperto e connesso) e $\eta\in C$ curva regolare a tratti.
\begin{itemize}
    \item g(z,$\eta$) sia analitica rispetto a z $\forall z \in G, \forall \eta \in C$.
    \item g(z,$\eta$) e $\frac{\partial g(z,\eta)}{\partial \eta}$, continue nelle variabili z ed $\eta$ $\forall z \in G, \forall \eta \in C$.
\end{itemize}
$\Longrightarrow$
\begin{equation}
    F(z)\equiv \int_Cg(z,\eta)d\eta
\end{equation}
Risulta analitica rispetto a z nel dominio G e la sua derivata può essere calcolata tramite derivazione sotto il segno di integrale.\\
\end{theorem}
\begin{proof}
Per le ipotesi fatte su $g$, $F(z)$ risulta derivabile rispetto ad $x$ ed $y$. Tali derivate parziali, per i teoremi dell'analisi reale, si possono calcolare derivando sotto il segno di integrale:
\begin{equation}
    F_x=\int_cg_x(z,\eta)d\eta \qquad F_y=\int_C g_y (z,\eta)d\eta
\end{equation}
Essendo $g$ analitica valgono le condizioni di C.R., ma di conseguenza tali condizioni valgono anche per $F$, $F_x+iF_y=0$, per cui $F(z)$ analitica.\\
La derivata di $F(z)$ risulta:
\begin{equation}
    F'(z)=F_x(z)=-iF_y(z)=\int_Cg_x(z,\eta)d\eta=\int_c-ig_y(z,\eta)d\eta=\int_C\frac{\partial g}{\partial z}(z,\eta)d\eta
\end{equation}
\end{proof}
\subsection{Derivata di ordine qualsiasi di una funzione analitica}
\begin{theorem}\label{5.derivate}
f(z) funzione analitica in G e continua in $\Bar{G}$.\\
$\Longrightarrow$ $\forall z \in G$ esiste la derivata di ordine qualsiasi di f(z), data da:
\begin{equation}
    f^{(n)}(z)=\frac{n!}{2\pi i}\oint_{\partial \Bar{G}}\frac{f(\eta)}{(\eta-z)^{n+1}}d\eta
\end{equation}
\end{theorem}
\begin{proof}
Si scriva la formula di Cauchy:
\begin{equation}\label{4.5.2}
    f(z)=\frac{1}{2\pi i}\oint_{\Bar{G}}\frac{f(\eta)}{\eta-z}d\eta
\end{equation}
La funzione integranda $g(z,\eta)=\frac{f(\eta)}{\eta-z}$ soddisfa le ipotesi del teorema \ref{int par}, per cui si può calcolare la derivata sotto il segno di integrale:
\begin{equation}
    f'(z)=\frac{1}{2\pi i}\oint_{\Bar{G}}\frac{f(\eta)}{(\eta-z)^2}d\eta
\end{equation}
Analogamente a prima la funzione integranda soddisfa le ipotesi del teorema citato, per cui:
\begin{equation}
    f''(z)=\frac{2}{2\pi i}\oint_{\Bar{G}}\frac{f(\eta)}{(\eta-z)^3}d\eta
\end{equation}
Procedendo in tal modo si trovano gli ordini successivi.
\end{proof}
Da questo teorema si ricava che un funzione analitica in un dominio $G$ ha derivate continue di ordine qualsiasi al suo interno.

\subsection{Teorema di Morera}
\begin{theorem}
f(z) funzione continua in G dominio semplicemente connesso, tale che, $\forall \Gamma$ contorno chiuso:
\begin{equation}
    \oint_{\Gamma} f(\eta)d\eta=0
\end{equation}
$\Longrightarrow$ f(z) è analitica in G
\end{theorem}
\begin{proof}
Si considera:
\begin{equation}
    F(z)=\int_z^{z_0} f(\eta)d\eta \qquad z,z_0 \in G
\end{equation}
Il cui integrale sia fatto rispetto ad un qualsiasi cammino congiungenti i 2 punti. Dal teorema \ref{F(z)} tale funzione è analitica e $F'(z)=f(z)$. Tuttavia anche questa funzione è analitica per il teorema \ref{5.derivate}.\\
Di conseguenza $f(z)$ analitica con derivata $f'(z)=F''(z)$.
\end{proof}

\subsection{Teorema di Liouville}
\begin{theorem}
f(z) analitica intera, $|f(z)|$ uniformemente limitato
\begin{equation}
    \exists \ M>0 \ \text{tale che\ } |f(z)|\le M, \forall z\in \mathds{C}
\end{equation}
$\Longrightarrow$ f(z) è identicamente uguale ad una costante.\\
\end{theorem}
\begin{proof}
Si considera:
\begin{equation}
    f'(z)=\frac{1}{2\pi i}\oint_{C_R}\frac{f(\eta)}{(\eta-z)^2}d\eta
\end{equation}
Con $C_R:\eta(\theta)=z+Re^{i\theta}$ con $\theta\in[0,2\pi]$ circonferenza di raggio $R$ e centro $z$, ossia
\begin{equation}
    \eta(\theta)=z+Re^{i\theta}
\end{equation}
Considerando il modulo dell'espressione integrale della derivata si trova
\begin{equation*}
    |f'(z)|=\frac{1}{2\pi i}\left|\oint_{C_R}\frac{f(\eta)}{(\eta - z)^2}d\eta\right|\le \frac{1}{2\pi i} \oint_{C_R}\frac{|f(\eta)|}{|\eta - z|^2}|d\eta|=\frac{1}{2\pi}\int_0^{2\pi}\frac{|f(\eta(\theta))|}{R^2}Rd\theta \le \frac{M}{2\pi R}\int_0^{2\pi}d\theta=\frac{M}{R}
\end{equation*}
La disuguaglianza deve valere per ogni valore arbitrario di $R$, per cui prendendo il limite $R\to \infty$ si ha
\begin{equation}
    |f'(z)|=0 \ \Rightarrow \ f'(z)=0
\end{equation}
Per cui $f(z)$ è una costante.

\end{proof}
Un utile applicazione del teorema di Liouville può essere la dimostrazione del:
\begin{theorem}[\textbf{Th fondamentale dell'algebra}]
Dato un polinomio di grado n$\ge 1$
\begin{equation}
    P(z)=\sum_{k=0}^na_kz^k \quad a_n\ne0
\end{equation}
ha almeno una radice in $\mathds{C}$
\end{theorem}
\begin{proof}
Se $a_0=0$ allora $P(0)=0$, caso banale.\\
Se $a_0\ne0$, si supponga per assurdo che $P(z)\ne 0 \ \forall z \in \mathds{C}$.\\
In tal caso la funzione $g(z)\equiv\frac{1}{P(z)}$ risulta essere analitica su tutto $\mathds{C}$, intera.\\
Inoltre sarà anche limitata inferiormente in modulo:
\begin{equation}
    \lim_{z\to\infty}P(z)=\infty \Longrightarrow \lim_{z\to\infty}g(z)=0
\end{equation}
Per cui esiste $R$ tale che $|g(z)|<1$ per $|z|>R$. All'interno del cerchio di raggio $R$, $g(z)$ è continua, per cui limitata in modulo $|g(z)|<M_R, \forall z : |z|\le R$.\\
Mettendo insieme le condizioni si deduce che $|g(z)|$ è uniformemente limitato in $\mathds{C}$, per cui applicando il teorema di Liouville dovrebbe essere uguale ad una costante.\\
Tuttavia questo è assurdo poichè tende a 0 all'infinito e $g(0)=a_0\ne 0$.
\end{proof}



\newpage
\setcounter{section}{6}
\section{Serie uniformemente convergenti di funzioni di variabile complessa}
\begin{comment}
\begin{wrapfigure}[7]{L}{0.2\textwidth}
  \begin{center}
    \includegraphics[width=0.2\textwidth]{abel.jpg}
  \end{center}
\end{wrapfigure}\leavevmode

\epigraph{\'E come la volpe, che confonde con la coda le sue tracce nella sabbia.}{\textit{Niels Abel, parlando di Gauss}}

\epigraph{Cauchy è matto e non c'è modo di essere in buoni rapporti con lui.}{\textit{Niels Abel, parlando di Cauchy}}
\end{comment}

Data una successione infinita di funzioni univoche di una variabile complessa $\{u_n(z) ; \ n=0,1,2,...\}$ nel dominio $G$, si chiama \textit{Serie di funzioni} l'espressione:
\begin{equation} \label{5.0.1}
    \sum_{n=0}^{\infty}u_n(z)
\end{equation}
\begin{definition} si dice che la (\ref{5.0.1}) è \textbf{convergente} nel dominio $G$ alla funzione univoca $f(z)$ se
\begin{equation}
    \forall z \in G, \ \ \exists \lim_{n \to \infty} S_n(z)=f(z)
\end{equation}
\end{definition}
con
\begin{equation}
    S_n(z)\equiv \sum_{c=0}^{n}u_c(z)
\end{equation}
\textit{Somma parziale n-esima} della serie.
\\
Cioè se
\begin{equation}
    \forall z \in G \ \forall \varepsilon >0 \ \ \exists N(\varepsilon,z) \ : \ \left|f(z)-\sum_{c=0}^n u_c(z)\right|<\varepsilon \ \ \forall n\geq N(\varepsilon,z)
\end{equation}
In questo caso $f(z)$ si dice \textit{Somma della serie (\ref{5.0.1})} nel dominio $G$.
\\
Per una serie convergente, la serie 
\begin{equation}
    \sum_{c=n+1}^{\infty} u_c(z)=f(z)-S_n(z)
\end{equation}
è detta \textit{resto n-esimo} della serie e si indica con $r_n(z)$.
\begin{equation}
    r_n(z)=f(z)-S_n(z) \ \ \ \ \ \ \ \ \lim_{n \to \infty} r_n(z)=0
\end{equation}
\begin{definition} Si dice che (\ref{5.0.1}) è \textbf{uniformemente convergente} nel dominio $G$ alla funzione univoca $f(z)$ se
\begin{equation}
    \forall \varepsilon >0 \ \exists N(\varepsilon) \ : \ \left|f(z)-\sum_{c=0}^n u_c(z)\right|< \varepsilon \quad \forall n \geq N(\varepsilon), \ \forall z \in G
\end{equation}
\end{definition}
\begin{theorem}[\textbf{Criterio di Weierstrass}] \label{Weierstrass}
Se 
\begin{equation}
  |u_n(z)|\leq |a_n| \ \ \forall z \in G  
\end{equation}
 e la serie 
 \begin{equation} \label{5.0.9}
   \sum_{n=0}^{\infty} |a_n|  
 \end{equation}
  è convergente, allora la serie (\ref{5.0.1}) converge uniformemente nel dominio $G$.
\end{theorem}

\begin{proof}
Essendo (\ref{5.0.9}) convergente,
\begin{equation}
    \forall \varepsilon>0 \ \exists N(\varepsilon) \ : \ \sum_{c=n+1}^{\infty} |a_c|<\varepsilon \ \ \forall n \geq N(\varepsilon)
\end{equation}
Da cui si ha anche
\begin{equation}
    |r_n(z)|=\left|\sum_{c=n+1} ^{\infty}u_c(z)\right|\leq \sum_{c=n+1}^{\infty} |u_c(z)| \leq \sum_{c=n+1}^{\infty} |a_n|<\varepsilon \ \ \forall n\geq N(\varepsilon) \ \forall z \in G
\end{equation}
\end{proof}
\textbf{NB:} Il criterio (\ref{Weierstrass}) è una condizione sufficiente ma non necessaria per la convergenza uniforme.

\subsection{Proprietà delle serie uniformemente convergenti}
\begin{theorem}
Se le funzioni $u_n(z)$ sono continue in un dominio $G$ e la serie
\begin{equation}
    \sum_{n=0}^{\infty}u_n(z)
\end{equation}
converge uniformemente in $G$ alla funzione $f(z)$, allora anche $f(z)$ è continua
\end{theorem}

\begin{theorem}
Se la serie
\begin{equation}
    \sum_{n=0}^{\infty} u_n(z)
\end{equation}
di funzioni continue $u_n(z)$ converge uniformemente in un dominio $G$ alla funzione $f(z)$, allora
\begin{equation}
    \int_C f(z) \ dz=\sum_{n=0}^{\infty}\int_C u_n(z) \ dz
\end{equation}
$\forall \ C$ curva regolare a tratti in $G$.
\end{theorem}

\begin{theorem}[\textbf{Th. di Weierstrass}] \label{th weierstrass}
Se le funzioni $u_n(z)$ sono analitiche in un dominio $G$ e la serie
\begin{equation}
    \sum_{n=0}^{\infty} u_n(z)
\end{equation}
converge uniformemente alla funzione $f(z)$ in ogni sottodominio chiuso $\bar{G'}\subset G$, allora:
\begin{itemize}
    \item $f(z)$ è analitica in $G$.
    \item La derivata c-esima vale: \begin{equation} 
        f^{(c)}(z)=\sum_{n=0}^{\infty} u_n ^{(c)}(z)
    \end{equation}
    \item La serie
    \begin{equation}
        \sum_{n=0}^{\infty} u_n ^{(c)} (z)
    \end{equation}
    converge uniformemente in ogni sottodominio chiuso $\bar{G'}\subset G$
    \end{itemize}
\end{theorem}

\textbf{Esempio:}\\
Si considera la serie:
\begin{equation}
    \sum_1^\infty u_n(z)=\sum_1^\infty\frac{z^n}{n^2}
\end{equation}
Le funzioni $u_n(z)$ sono analitiche intere e vale $|u_n(z)|\le\frac{1}{n^2}$ $\forall |z|\le 1$. Per il criterio di Weierstrass (\ref{Weierstrass}) la serie converge uniformemente nel cerchio unitario, dominio chiuso $\bar{G}$.\\
La serie delle derivate $\sum_1^\infty\frac{z^{n-1}}{n}$ non converge uniformemente nel cerchio di raggio unitario, in quanto diverge per $z=1$, ma per il teorema di Weierstrass (\ref{th weierstrass}) converge uniformemente in ogni sottodominio chiuso.\\
\subsection{Serie di potenze di una variabile complessa}
Si consideri il caso in cui $u_n(z)=c_n (z-z_0)^n$ con $c_n \in \mathds{C}$ e $z_0$ punto fisso del piano complesso. \\
La serie
\begin{equation}
    \sum_{n=0} ^{\infty} u_n(z)=\sum_{n=0}^{\infty} c_n (z-z_0)^n
\end{equation}
viene detta \textit{Serie di Potenze}.
\\
Le funzioni $u_n=c_n(z-z_0)^n$ sono intere.
\\
Il dominio di convergenza di una serie di potenze dipende dalla forma dei coefficienti $c_n$.
\\ \\
\textbf{Esempio:}
\begin{itemize}
    \item La serie di potenze 
\begin{equation}
    \sum_{n=0}^{\infty} n!(z-z_0)^n
\end{equation}
converge solo nel punto $z=z_0$.
\\
Infatti
\begin{equation}
    \frac{|u_{n+1}(z)|}{|u_n(z)|}=(n+1)|z-z_0| \xrightarrow[n \rightarrow \infty] \ +\infty \ \ \forall \ z \ne z_0
\end{equation}
perciò la serie risulta divergente $\forall \ z \ne z_0$ dal momento che non è soddisfatta la condizione necessaria di convergenza:
\begin{equation}
    \lim_{n \to \infty}u_n(z)=0
\end{equation}
\item La serie di potenze 
\begin{equation}
    \sum_{n=0}^{\infty} \frac{1}{n!}(z-z_0)^n
\end{equation}
converge assolutamente $\forall z\in \mathds{C}$.\\
Infatti
\begin{equation}
    \frac{|u_{n+1}(z)|}{|u_n(z)|}=\frac{|z-z_0|}{n+1} \xrightarrow[n \rightarrow \infty] \ 0 \ \ \forall \ z
\end{equation}
La serie dei moduli è convergente, per cui per il criterio di D'Alembert la serie è assolutamente convergente
\end{itemize}
\begin{theorem}[\textbf{Th. di Abel}] \label{Abel}
Se la serie di potenze
\begin{equation}
    \sum_{n=0}^{\infty} c_n(z-z_0)^n
\end{equation}
converge in un punto $z_1\ne z_0$, allora essa converge assolutamente $\forall \ z \ : \ |z-z_0|<|z_1 - z_0|$ e, inoltre, converge uniformemente in ogni cerchio $|z-z_0|\leq \rho < |z_1 - z_0|$.
\end{theorem}

\begin{proof}
Si prenda $z$ tale che  $|z-z_0|<|z_1 - z_0|$ e si pone
\begin{equation}
    q\equiv \frac{|z-z_0|}{|z_1 - z_0|}<1
\end{equation}
La serie
\begin{equation}
    \sum_{n=0}^{\infty} c_n(z_1 -z_0)^n
\end{equation}
è convergente per ipotesi e quindi per il criterio necessario di convergenza:
\begin{equation*}
    \lim_{n \to \infty}c_n(z_1-z_0)^n=0 \ \Rightarrow \ \exists M \ : \ |c_n||z_1 - z_0|^n \leq M \ \forall n \in \mathds{N} \ \iff \ \exists M>0 \ : \ |c_n|\leq \frac{M}{|z_1 - z_0|^n}
\end{equation*}
Ne segue che
\begin{equation}
    \left|\sum_{n=0}^{\infty} c_n (z-z_0)^n\right|\leq \sum_{n=0}^{\infty} |c_n||z-z_0|^n \leq M\sum_{n=0}^{\infty} \frac{|z-z_0|^n}{|z_1-z_0|^n}=M\sum_{n=0}^{\infty}q^n=\frac{M}{1-q}
\end{equation}
che dimostra la convergenza della serie $\forall \ z \ : \ |z-z_0|<|z_1-z_0| \ (\iff q<1)$.
\\
Prendendo $z$ tale che $|z-z_0|\leq \rho <|z_1-z_0|$, risulta
\begin{equation}
    |c_n(z-z_0)^n|\leq |c_n||z-z_0|^n\leq M\frac{\rho^n}{|z_1 -z_0|^n}
\end{equation}
Ed essendo questa una serie geometrica convergente di ragione $\frac{\rho}{|z_1 - z_0|}<1$ per il criterio (\ref{Weierstrass}) la serie
\begin{equation}
    \sum_{n=0}^{\infty}c_n(z-z_0)^n
\end{equation}
risulta essere uniformemente convergente in ogni cerchio $|z-z_0|\leq \rho$ di raggio $\rho \leq |z_1-z_0|$.
\end{proof}

Si elencano di seguito una serie di conseguenze di (\ref{Abel}):
\begin{itemize}
    \item Se la serie di potenze diverge in un punto $z=z_1$ allora diverge $\forall \ z \ : \ |z-z_0|>|z_1-z_0|$.
    \item Per ogni serie di potenze esiste un $R\geq 0$ tale che all'interno del cerchio $|z-z_0|<R$ la serie è convergente, mentre al di fuori è divergente.
    \begin{proof}
    Si prende come $R$ il $sup\{|z-z_0|\}$ sugli $z$ tali che a serie di potenze sia convergente.
    \\
    Se $R=0$, allora la serie converge solo in $z=z_0$.
    \\
    Se $R=\infty$, allora la serie converge in tutto il piano complesso.
    \\
    Se $0<R<\infty$, la serie diverge per $|z-z_0|>R$, mentre converge per $|z-z_0|<R$.
    \\
    Tutto in base al Th. di Abel.
    \end{proof}
    $R$ viene chiamato \textit{Raggio di convergenza} e il dominio $|z-z_0|<R$ \textit{Cerchio di convergenza}.\\
    Si dimostra che è dato dalla \textbf{formula di Cauchy-Hadamard}:
    \begin{equation}
        R=\frac{1}{l}\quad l\equiv \lim_{n\to\infty}\sup\{\sqrt[k]{|c_k|},k\ge n\}
    \end{equation}
    
    
    \item Dato che le funzioni $u_n(z)=c_n(z-z_0)^n$ sono intere e siccome
    \begin{equation}
        \sum_{n=0}^{\infty}c_n(z-z_0)^n
    \end{equation}
    converge uniformemente in ogni cerchio $|z-z_0|\leq \rho$ con $\rho < R$ , allora converge anche in ogni sottodominio chiuso del cerchio di convergenza.
    \\
    Per il (\ref{th weierstrass}) allora la somma $f(z)$ della serie è analitica e, dal momento che la si può integrare o derivare termine a termine un numero qualsiasi di volte nel cerchio di convergenza, il raggio di convergenza della serie derivata è lo stesso della serie di partenza.
    \item Detta $f(z)$ la somma della serie
    \begin{equation}
        \sum_{n=0}^{\infty} c_n(z-z_0)^n
    \end{equation}
    vale la formula:
    \begin{equation}
        c_n=\frac{1}{n!}f^{(n)}(z_0)
    \end{equation}
    \begin{proof}
    Sia 
    \begin{equation}
        f(z)=\sum_{n=0}^{\infty}c_n(z-z_0)^n
    \end{equation}
    si nota che $f(z_0)=c_0$.
    \\
    Inoltre, derivando termine a termine:
    \begin{equation} \label{5.2.15} \begin{split}
        f'(z)=\sum_{n=1}^{\infty}c_n n (z-z_0)^{n-1} \ \ , \ \ f''(z)=\sum_{n=2}^{\infty}c_n n (n-1) (z-z_0)^{n-2} \ \ , \\ \ \ ... \ \ , \ \ f^{(c)}(z)=\sum_{n=c}^{\infty}c_n n(n-1)...(n-c+1)(z-z_0)^{n-c}
   \end{split} \end{equation}
   Ponendo nella (\ref{5.2.15}) $z=z_0$ si trova:
   \begin{equation}
       f'(z_0)=c_1 \ , \ f''(z_0)=c_2 \ 2! \ , \ ... \ , \ f^{(c)}(z_0)=c_c \ c!
   \end{equation}
   Che non è altro che
   \begin{equation}
       c_c=\frac{1}{c!}f^{(c)}(z_0) \ \ \forall \ c \in \mathds{N}
   \end{equation}
    \end{proof}
\end{itemize}

\textbf{Esempio:}
\\
La serie di potenze con $c_n=1 \ \ \forall \ n \in \mathds{N}$ ossia
\begin{equation}
    \sum_{n=0}^{\infty} (z-z_0)^n
\end{equation}
è una \textit{Serie geometrica complessa}, ovvero una serie del tipo:
\begin{equation} \label{geom}
    \sum_{n=0}^{\infty} \eta^n \ \ \ \ \eta \in \mathds{C}
\end{equation}
La (\ref{geom}) ha raggio di convergenza $R=1$, per cui diverge se $|z-z_0|\geq 1$ mentre converge assolutamente se $|z-z_0|<1$.
\\
La somma della serie è:
\begin{equation}
    f(z)=\lim_{n \to \infty} S_n(z)=\lim_{n \to \infty} \frac{1-(z-z_0)^{n+1}}{1-(z-z_0)}=\frac{1}{1-(z-z_0)}
\end{equation}
\newpage











\section{Sviluppo in serie di Taylor}
\begin{comment}
\begin{wrapfigure}[7]{L}{0.1\textwidth}
  \begin{center}
    \includegraphics[width=0.25\textwidth]{Hadamard.jpg}
  \end{center}
\end{wrapfigure}\leavevmode

\vspace{1.5 cm}
\epigraph{La strada più breve fra due verità del dominio reale passa per il dominio complesso.}{Jacques Hadamard}
\vspace{1.5 cm}
\end{comment}

\subsection{Il teorema di Taylor}
\begin{theorem}\label{8 T}
f(z) funzione analitica all'interno del cerchio $|z-z_0|<R$\\
$\Longrightarrow$ all'interno del cerchio la funzione può essere rappresentata in modo univoco da una serie di potenze:
\begin{equation}
    f(z)=\sum_{n=0}^\infty c_n(z-z_0)^n \qquad c_n=\frac{1}{n!}f^{(n)}(z_0)
\end{equation}
\end{theorem}
\begin{proof}
Sia $z$ tale che $|z-z_0|<R$, si consideri la circonferenza di raggio $\rho$ tale che $|z-z_0|<\rho<R$.
$f(z)$ è analitica nel cerchio di raggio $R$, per cui dal teorema di Cauchy:
\begin{equation}\label{ttay}
    f(z)=\frac{1}{2\pi i}\oint_{C_\rho}\frac{f(\eta)}{\eta-z}d\eta
\end{equation}
Siccome $\eta\in C_\rho$ $\Longrightarrow$ $|z-z_0|<|\eta-z_0|<\rho$ per cui $\frac{|z-z_0|}{|\eta-z_0|}<1$.\\
Allora
\begin{equation}\begin{split}
    \frac{1}{\eta - z}=\frac{1}{(\eta-z_0)-(z-z_0)}=\frac{1}{\eta-z_0}\frac{1}{1-\frac{z-z_0}{\eta-z_0}}=\\
    =\frac{1}{\eta - z_0}\sum_{n=0}^{\infty}\left(\frac{z-z_0}{\eta-z_0} \right)^n=\sum_{n=0}^{\infty}\frac{(z-z_0)^n}{(\eta-z_0)^{n+1}}
\end{split}\end{equation}
Si sostituisce questa espressione nella (\ref{ttay}) e si integra termine a termine. Si può fare per via della convergenza uniforme della serie $\sum \frac{f(\eta)}{(\eta - z_0)^{n+1}}(z-z_0)^n$, maggiorata in modulo dalla serie convergente
\begin{equation*}
    M\sum \frac{|z-z_0|^n}{\rho^{n+1}}=\frac{M}{\rho}\sum \left( \frac{|z-z_0|}{\rho} \right)^n=\frac{M}{\rho - |z-z_0|}
\end{equation*}
Dato che $M\equiv max|f(\eta)|$ si trova
\begin{equation}
    f(z)=\sum_{n=0}^{\infty}\left( \frac{1}{2\pi i}\oint_{C_{\rho}}\frac{f(\eta)}{(\eta -z_0)^{n+1}}d\eta \right)(z-z_0)^n
\end{equation}
Ma per il Th. di Cauchy (\ref{II Cauchy 1v}) si può passare dall'integrale su $C_{\rho}$ a un integrale su un contorno chiuso $C$ qualunque contenuto nel cerchio $\Delta R$ e contenente all'interno $z_0$.
\\
Perciò si trova che $\forall z \in \Delta_R$:
\begin{equation}
    f(z)=\sum_{n=0}^{\infty}c_n(z-z_0)^n
\end{equation}
con
\begin{equation}
    c_n=\frac{1}{2\pi i}\oint_C \frac{f(\eta)}{(\eta -z_0)^{n+1}}d\eta=\frac{1}{n!}f^{(n)}(z_0)
\end{equation}

\end{proof}

Si osservi che nell'analisi reale dal fatto che $f(x)$ $\in C^\infty[a,b]$ non segue necessariamente che la funzione sia sviluppabile in una serie $\sum_0^\infty c_n(x-x_0)^n$ con $x_0\in[a,b]$ e convergente $\forall x \in[a,b]$.\\
Ad esempio la funzione $f(x)=\frac{1}{1+x^2} \in C^\infty(\mathds{R})$, ma posto $x_0=0$ la serie $\sum_0^\infty(-1)^nx^{2n}$ converge a $f(x)$ solo se $x \in [-1,1]$.\\


\subsection{Esempi}
\subsubsection{Funzione logaritmo}
Si consideri della funzione $log(z)$ la determinazione principale ($k=0$) con $arg(z) \ \in[-\pi,\pi]$. In questo modo si ha il taglio sulla semiretta reale negativa.
\begin{equation}
    log(z)=log(|z|)+iarg(z) \qquad arg(z) \in[-\pi,\pi]
\end{equation}
Si tratta di una funzione analitica in $\mathds{C}/\{z:Re(z)\le 0, Im(z)=0\}$, per cui lo sarà nel cerchio $|z-1|<1$.\\
Si determina lo sviluppo di Taylor attorno a 1, con raggio di convergenza $R=1$.\\
Sapendo che:
\begin{equation}
    (log(z))^{(n)}=(-1)^{n-1}\frac{(n-1)!}{z^n}
\end{equation}
Si ottiene:
\begin{equation}
    log(z)=\sum_0^\infty (-1)^{n-1}\frac{(z-1)^n}{n} \qquad \forall z:|z-1|<1
\end{equation}
\subsubsection{Funzione esponenziale}
E' una funzione intera con:
\begin{equation}
    (e^z)^{(n)}=e^z \qquad \forall n\in \mathds{N}
\end{equation}
Si ottiene di conseguenza che lo sviluppo di Taylor attorno a $z=0$:
\begin{equation}
    e^z=\sum_0^\infty \frac{z^n}{n!}
\end{equation}
Con raggio di convergenza $R=\infty$.
\subsubsection{Funzioni trigonometriche}
Sono funzioni intere con:
\begin{equation}
    (cos(z))'=-sen(z) \quad (sen(z))'=cos(z)
\end{equation}
Si ricavano gli sviluppi attorno a $z=0$:
\begin{equation}
    cos(z)=\sum_0^\infty(-1)^n\frac{z^{2n}}{(2n!)}  \qquad
    sen(z)=\sum_0^\infty(-1)^n\frac{z^{2n+1}}{(2n+1)!}
\end{equation}
Con raggio di convergenza $R=\infty$.
\subsubsection{Funzioni iperboliche}
Sono intere con derivate:
\begin{equation}
    (cosh(z))'=senh(z) \quad (senh(z))'=cosh(z)
\end{equation}
Per cui attorno a 0 si ricavano gli sviluppi:
\begin{equation}
    cosh(z)=\sum_0^\infty\frac{z^{2n}}{(2n!)}  \qquad
    sen(z)=\sum_0^\infty\frac{z^{2n+1}}{(2n+1)!}
\end{equation}
Con raggio di convergenza $R=\infty$.
\subsubsection{La funzione \texorpdfstring{$f(z)=\frac{1}{z-a}$}{Lg}}
Si tratta di una funzione analitica $\forall z \in\mathds{C}$ tale che $z\ne a$.\\
Di conseguenza il raggio di convergenza della serie sarà $R=|z_0-a|$.\\
Si può riscrivere come:
\begin{equation}
    \frac{1}{z-a}=\frac{1}{(z-z_0)-(a-z_0)}=-\frac{1}{z-a}\frac{1}{1-\frac{z-z_0}{a-z_0}}=\sum_0^\infty\frac{(-1)^n}{(z_0-a)^{n-1}}(z-z_0)^n
\end{equation}

\subsection{Proprieta degli zeri di una funzione analitica}
\subsubsection{Teorema di unicità}
\begin{theorem}\label{8 uni}
$f(z)$ analitica in un dominio connesso $G$ tale che $f^{(n)}(z_0)=0 \ \ \forall n\in \mathds{N}\Longrightarrow$
\begin{equation}
    f(z)\equiv 0 \quad \forall z \in G
\end{equation}
\end{theorem}
\begin{proof}
Simile al principio del massimo modulo di una funzione analitica, si consideri un punto $t$ interno a $G$ e sia $\gamma$ curva completamente contenuta in $G$ che colleghi $z_0$ e $\bar{z}$.\\
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{unicità.PNG}
    \label{unicità}
\end{figure}
Si definisce:
\begin{equation}
    d\equiv dist(\gamma,\partial G)\equiv min |z_1-z_2| \quad z_1\in \gamma,\ z_2 \in \partial G
\end{equation}
Si prenda il cerchio $\Omega$ centrato in $z_0$ e di raggio $R=\frac{d}{2}$, in questo modo $\Omega\subset G$, al suo interno $f(z)$ è analitica.\\
Sfruttando le ipotesi ed il teorema di Taylor, si ottiene:
\begin{equation}
    f(z)=\sum_0^\infty\frac{1}{n!}f^{(n)}(z_0)(z-z_0)^n\equiv0 \quad\forall z\in \Omega
\end{equation}
Da cui si ottiene la tesi $\forall \ z\in \Omega$
Se $z_1$ è l'ultimo punto di intersezione fra il cerchio e $\gamma$ si trova per continuità che lo stesso vale anche in questo punto.\\
Si ripete il procedimento prendendo il cerchio di raggio $R$ e centro $z_1$,  e cosi via sino ad un punto qualunque.

\end{proof}

\subsubsection{Zeri di una funzione analitica}
Sia $f(z)$ funzione analitica non identicamente nulla, in un dominio connesso $G$.\\
Se $f(z_0)=0 \ \to \ z_0$ è uno \textit{zero} di $f(z)$ e:
\begin{itemize}
    \item se $f(z_0)=0$, ma $f'(z_0)\ne 0$ si dice \textit{zero di ordine 1}
    \item se $f(z_0)=...=f^{(n)}(z_0)=0$ ma $f^{(n+1)}(z_0)\ne 0$ si dice \textit{zero di ordine n}
\end{itemize}
Per il teorema di unicità (\ref{8 uni}) non può essere $f^{(n)}(z_0)=0 \ \forall n\in\mathds{N}$.\\
\\
\begin{definition}
Uno zero è \textit{punto isolato} se esiste un intorno in cui non ci sono altri zeri.
\end{definition}
\begin{theorem}\label{8 zeri}
Gli zeri di una funzione analitica non nulla in un dominio connesso $G$ sono punti isolati.\\
Detto $\Omega$ l'insieme degli zeri di $f(z)$ in $G$, gli eventuali punti di accumulazione di $\Omega$ non appartengono a $G$.
\end{theorem}
\begin{proof}
Se $z_0\in G$ è uno zero di ordine n di $f(z)$, risulta che, in un $\delta$-intorno di $z_0$ vale lo sviluppo in serie di Taylor:
\begin{equation}
    f(z)=\sum_{l=n}^{\infty}c_l(z-z_0)^l=(z-z_0)^n[c_n+c_{n+1}(z-z_0)+...]=(z-z_0)^n\sum_{k=0}^{\infty}c_{n+k}(z-z_0)^k\equiv (z-z_0)^n g(z)
\end{equation}
dove $g(z)$ è una funzione analitica nell'intorno di $z_0$. Allora, per continuità, esiste un $\delta$-intorno di $z_0$ in cui $f(z)\ne 0$ tranne che in $z_0$.\\
Di conseguenza $z_0$ è un punto isolato, dal momento che esiste un $\delta$-intorno in cui non ci sono altri zeri.
Si supponga ora che l'insieme $\Omega$ degli zeri di $f(z)$ abbia un punto di accumulazione $\bar{z}$, ovvero esista una successione di zeri $z_k$ di $f(z)$ che converga a $\bar{z}$. Se, per assurdo, $\bar{z}\in G$ si avrebbe, essendo $f(z)$ continua in $G$:
\begin{equation}
    \lim_{z_n\to \bar{z}}f(z_k)=f(\bar{z})=0
\end{equation}
Per cui $\bar{z}$ sarebbe uno zero non isolato di $f(z)$, in contrasto con quanto già dimostrato.
\end{proof}

Ad esempio $f(z)=sen\left(\frac{1}{z}\right)$ si annulla in $z_n=\frac{1}{n\pi}$ con $n=\pm 1,\pm 2,...$. L'insieme degli zeri ha un punto di accumulazione in $\bar{z}=0$, tuttavia non è un punto di analiticità della funzione.
\begin{theorem}
$f(z)$ non nulla, analitica in un dominio connesso, può avere solo un numero finito di zeri in ogni sottodominio chiuso e limitato $\Bar{D}\subset G$.
\end{theorem}
\begin{proof}
Se ci fossero infiniti zeri in un insieme chiuso e limitato si potrebbe formare una successione convergente a uno zero nel dominio.
\end{proof}
\subsection{Teorema di unicità}
\begin{theorem}
$f(z)$ e $g(z)$ funzioni analitiche in un dominio connesso $G$. Sia $\Omega$ insieme dei punti tali che $f(z)=g(z)$.\\
$\Longrightarrow$ se in $\Omega$ esiste almeno un punto di accumulazione $\bar{z}\in G$ (una successione $\{z_n\}\in\Omega$ tali che $f(z_n)=g(z_n)$ con $\lim_{n\to\infty}z_n=\bar{z}\in G$):
\begin{equation}
    f(z)\equiv g(z)
\end{equation}
\end{theorem}
\begin{proof}
Si considera la funzione:
\begin{equation}
    F(z)\equiv f(z)-g(z)
\end{equation}
Per ogni $z\in\Omega$ $F(z)=0$, suppongo esista un punto di accumulazione $\bar{z}$ in $\Omega$.\\
Se per assurdo fosse $F(z)$ diverso dalla funzione nulla in $G$ per il teorema \ref{8 zeri} $\bar{z}$ non potrebbe appartenere a $G$.
\end{proof}
Il teorema presenta un facile corollario: se $f(z)$ e $g(z)$ sono funzioni analitiche in un connesso $G$ e coincidono su una curva $\gamma$ appartenente a $G$, allora $f(z)\equiv g(z)$.
\subsubsection{Esempi}
Di conseguenza le funzioni analitiche intere sono estensioni analitiche al piano complesso delle funzioni definite sull'asse reale.\\
La funzione complessa $log(z)=log(|z|)+iarg(z)$ con $arg(z)\in[-\pi,\pi]$ è l'unica estensione analitica al dominio connesso $G=\mathds{C}/\{z:Re(z)\le 0,Im(z)=0\}$ della funzione definita sul semiasse reale $log(x)$.\\
Le funzioni analitiche intere $f(z)=cos^2(z)+sen^2(z)$ e $g(z)=1$ coincidono sull'asse reale e per cui coincidono su tutto il piano complesso.\\
\subsection{Il teorema di de l'Hopital-Bernoulli}
$f(z)$ e $g(z)$ funzioni analitiche in dominio $G$, $z_0\in G$ zero di ordine $n$ per entrambe.\\
$\Longrightarrow$
\begin{equation}
    \lim_{z\to z_0}\frac{f(z)}{g(z)}=\lim_{z\to z_0}\frac{f^{(n)}(z)}{g^{(n)}(z)}=\frac{f^{(n)}(z_0)}{g^{(n)}(z_0)}
\end{equation}
\begin{proof}
Le funzioni si possono sviluppare in serie di Taylor nell'intorno di $z_0$
\begin{equation}
    f(z)=(z-z_0)^n\sum_{l=0}^\infty c_{n+l}(z-z_0)^l \qquad g(z)=(z-z_0)^n\sum_{l=0}^\infty d_{n+l}(z-z_0)^l
\end{equation}
Con $c_n=\frac{1}{n!}f^{(n)}(z_0)$ e $d_n=\frac{1}{n!}f^{(n)}(z_0)$.\\
Per cui:
\begin{equation}
    \lim_{z\to z_0}\frac{f(z)}{g(z)}=\lim_{z\to z_0}\frac{c_n+c_{n+1}(z-z_0)+...}{d_n+d_{n+1}(z-z_0)+...}=\frac{f^{(n)}(z_0)}{g^{(n)}(z_0)}=\lim_{z\to z_0}\frac{f^{(n)}(z)}{g^{(n)}(z)}
\end{equation}
\end{proof}

\newpage
\section{Lo sviluppo in serie di Taylor-Laurent}
\begin{comment}
\begin{wrapfigure}[7]{L}{0.1\textwidth}
  \begin{center}
    \includegraphics[width=0.2\textwidth]{taylor.jpg}
  \end{center}
\end{wrapfigure}\leavevmode

\vspace{1.5 cm}
\epigraph{Non è improbabile che la sua vita sia stata accorciata dalle sue abitudini sedentarie.}{\textit{John Mason Good, parlando di Brook Taylor}}
\vspace{1.5 cm}
\end{comment}

Una serie della forma
\begin{equation} \label{7.0.1}
    \sum_{n=-\infty}^{\infty}c_n(z-z_0)^n
\end{equation}
con $z_0$ un punto fissato del piano e $c_n \in \mathds{C}$ si dice \textit{Serie di Taylor-Laurent}.
\\ \\
Per determinare il dominio di convergenza della (\ref{7.0.1}) la si riscrive:
\begin{equation}
    \sum_{n=0}^{\infty} c_n(z-z_0)^n + \sum_{n=1}^{\infty} \frac{c_{-n}}{(z-z_0)^n}
\end{equation}

I due termini della somma sono detti rispettivamente \textit{parte di Taylor} e \textit{parte di Laurent}.
\\
A seguito di quanto visto in (\ref{8 T}) la parte di Taylor converge in un certo raggio di convergenza $|z-z_0|<R$ ad una certa funzione analitica $f_T(z)$.
\\
La parte di Laurent invece è possibile riscriverla tramite un cambio di variabile come una serie geometrica complessa:
\begin{equation}
    \sum_{n=1}^{\infty}c_{-n}(z-z_0)^{-n} \ \to \ \eta \equiv \frac{1}{z-z_0} \ \to \ \sum_{n=1}^{\infty}c_{-n}\eta^n
\end{equation}
che converge all'interno di un certo cerchio di convergenza $|\eta|<R'$ ad una funzione analitica $g(\eta)$.
\begin{equation}
    \sum_{n=1}^{\infty}\frac{c_{-n}}{(z-z_0)^n}=g(\eta(z))\equiv f_L(z) \ \ \forall z \ : \ |z-z_0|>\frac{1}{R'}\equiv r
\end{equation}
Da cui, se $r<R$, la parte di Taylor e quella di Laurent convergono nel dominio comune $r<|z-z_0|<R$ :
\begin{equation} \label{7.0.5}
    \sum_{n=-\infty}^{n=\infty}c_n(z-z_0)^n=f_T(z)+f_L(z) \equiv f(z) \ \ \ \forall z \ : \ r<|z-z_0|<R
\end{equation}

\begin{center}
    \begin{tikzpicture}
    \draw (2,2) circle (2cm);
    \draw (2,2) circle (1cm);
    \draw[->] (2,2) -- (2.7,2.7);
    \filldraw[black] (2.7,2.7) circle (0pt)node[anchor=west] {$r$};
    \filldraw[black] (2,0.2) circle (0pt)node[anchor=west] {$R$};
    \draw[->](2,2)--(2,0);
    \filldraw[black] (2,2) circle (1pt)node[anchor=west] {$z=z_0$};
    \end{tikzpicture}
\end{center}
La somma della serie (\ref{7.0.5}) $f(z)=f_T(z)+f_L(z)$ è una funzione analitica nella corona circolare $r<|z-z_0|<R$.

\begin{theorem} \label{7.1}
Se $f(z)$ è una funzione analitica in una corona circolare $r<|z-z_0|<R$, allora in tale dominio la funzione può essere rappresentata in modo univoco con una \textit{Serie di Taylor-Laurent} convergente:
\begin{equation}
    \sum_{n=-\infty}^{\infty} c_n(z-z_0)^n \ \ \text{con} \ \ c_n=\frac{1}{2\pi i}\oint_C \frac{f(\eta)}{(\eta-z_0)^{n+1}} \ d\eta
\end{equation}
dove $C$ è una curva chiusa arbitraria nella corona $r<|z-z_0|<R$ che racchiude $z_0$.
\end{theorem}

\begin{proof}
Si prende in esame un punto qualunque $z$ nella corona $r<|z-z_0|<R$. \\
Si considerano due circonferenze $C_{\rho_1}$ e $C_{\rho_2}$ centrate in $z_0$ di raggi $\rho_1$ e $\rho_2$, \\ tali che $r<\rho_1<|z-z_0|<\rho_2<R$.

\begin{center}
    \begin{tikzpicture}
    \draw (2,2) circle (2cm);
    \draw[dashed] (2,2) circle (1.9 cm);
    \draw[->] (0.1,2.1)--(0.1,1.9);
    \draw[->] (3.9,1.9)--(3.9,2.1);
    \draw[dashed] (2,2) circle (1.1 cm);
    \draw[->] (0.9,1.9)--(0.9,2.1);
    \draw[->] (3.1,2.1)--(3.1,1.9);
    \draw (2,2) circle (1cm);
    \filldraw[black] (0.1,2) circle (0pt)node[anchor=west] {$C_{\rho_2}$};
    \filldraw[black] (3.2,2) circle (0pt)node[anchor=west] {$C_{\rho_1}^-$};
    \draw[->] (2,2) -- (2.7,2.7);
    \filldraw[black] (2.7,2.7) circle (0pt)node[anchor=west] {$r$};
    \filldraw[black] (2,-0.2) circle (0pt)node[anchor=west] {$R$};
    \draw[->](2,2)--(2,0);
    \filldraw[black] (2,2) circle (1pt)node[anchor=west] {$z_0$};
    \end{tikzpicture}
\end{center}

In base al secondo teorema di Cauchy (\ref{II Cauchy 2.3v}) per il dominio compreso tra $C_{\rho_1}$ e $C^- _{\rho_2}$ si può scrivere:
\begin{equation}
    f(z)=\frac{1}{2\pi i}\oint_{C_{\rho_2}} \frac{f(\eta)}{\eta - z}d\eta + \frac{1}{2\pi i}\oint_{C_{\rho_1}^-}\frac{f(\eta)}{\eta-z}d\eta
\end{equation}
Nel primo integrale la variabile $\eta \in C_{\rho_2}$ soddisfa la disuguaglianza
\begin{equation} \begin{split}
    \left|\frac{z-z_0}{\eta-z_0}\right|=\frac{|z-z_0|}{\rho_2}<1 \ \Rightarrow \ \frac{1}{\eta - z}=\frac{1}{(\eta-z_0)-(z-z_0)}= \\ =\frac{1}{\eta - z_0}\frac{1}{1-\frac{z-z_0}{\eta - z_0}}=\frac{1}{\eta - z_0}\sum_{n=0}^{\infty}\biggl( \frac{z-z_0}{\eta-z_0} \biggr) ^n=\sum_{n=0}^{\infty}\frac{(z-z_0)^n}{(\eta-z_0)^{n+1}}
\end{split}\end{equation}
Si può sostituire quanto trovato e integrare termine a termine (per via della convergenza uniforme) trovando:
\begin{equation}
    f_T(z)\equiv \frac{1}{2\pi i}\oint_{C_{\rho_2}} \frac{f(\eta)}{\eta - z}d\eta=\sum_{n=0}^{\infty}c_n(z-z_0)^n \ \ \text{con} \ \ c_n=\frac{1}{2\pi i}\oint_{C_{\rho_2}}\frac{f(\eta)}{(\eta-z_0)^{n+1}}d\eta \ , \ \forall n\geq 0
\end{equation}
Nell'integrale a secondo termine invece la variabile $\eta$ soddisfa:
\begin{equation}
    \begin{split}
        \left|\frac{\eta-z_0}{z-z_0}\right|=\frac{\rho_1}{|z-z_0|}<1 \ \Rightarrow \ \frac{1}{\eta-z}=\frac{1}{(\eta-z_0)-(z-z_0)}=\\
        =-\frac{1}{z-z_0}\frac{1}{1-\frac{\eta-z_0}{z-z_0}}=-\frac{1}{z-z_0}\sum_{n=0}^{\infty} \biggl( \frac{\eta-z_0}{z-z_0} \biggr)^n=-\sum_{n=0}^{\infty}\frac{(\eta-z_0)^n}{(z-z_0)^{n+1}}
    \end{split}
\end{equation}
Operando come sopra si trova:
\begin{equation}
    f_L(z)\equiv \frac{1}{2\pi i}\oint_{C_{\rho_1}^-}\frac{f(\eta)}{\eta-z}d\eta=\sum_{n=0}^{\infty}\biggl(-\frac{1}{2\pi i}\oint_{C_{\rho_1}^-}f(\eta)(\eta-z_0)^n d\eta \biggr) \frac{1}{(z-z_0)^{n+1}}\xrightarrow[n \to n+1]\ \sum_{n=1}^{\infty}\frac{c_{-n}}{(z-z_0)^n}
\end{equation}
con
\begin{equation}
  c_{-n}=-\frac{1}{2\pi i}\oint_{C_{\rho_1}^-} f(\eta)(\eta -z_0)^{n-1}d\eta=\frac{1}{2\pi i}\oint_{C{\rho_1}}\frac{f(\eta)}{(\eta-z_0)^{-n+1}}d\eta \ \ \forall n>1
\end{equation}

Dato che le funzioni integrande presenti nell'espressione trovata per i coefficienti $c_{\pm n}$ sono analitiche nella corona $r<|z-z_0|<R$ si può sostituire l'integrale sulle $C_{\rho}$ con uno su una curva arbitraria nel dominio.
\\
Da cui in ultima istanza si trova:
\begin{equation} \begin{split}
    f(z)=f_T(z)+f_L(z)=\sum_{n=0}^{\infty}c_n(z-z_0)^n+\sum_{n=1}^{\infty} \frac{c_{-n}}{(z-z_0)^n}=\sum_{n=-\infty}^{\infty}c_n(z-z_0)^n \\ \text{con} \ \ \ \ \ \ \ \ \ c_n=\frac{1}{2\pi i} \oint_{C}\frac{f(\eta)}{(\eta-z_0)^{n+1}}d\eta \ \ \forall \eta \in \mathds{Z}
\end{split}\end{equation}
\end{proof}

\textbf{Nota Bene:} Nel caso in cui $f(z)$ sia analitica $\forall z \ : \ |z-z_0|<R$ si vede che $c_n=0 \ \forall n <0$, perciò $f_L(z)=0$ e la serie si riduce alla serie di Taylor della funzione:
\begin{equation}
    f(z)=\sum_{n=0}^{\infty}c_n(z-z_0)^n
\end{equation}

\subsection{I punti singolari isolati di una funzione analitica}

\begin{definition}
Si dice che $z_0$ è un \textbf{punto singolare isolato} di una funzione $f(z)$ se $f(z)$ è analitica in una corona circolare $0<|z-z_0|<R$ dove $z_0$ è un punto singolare della funzione.
\end{definition}

\begin{center}
    \begin{tikzpicture}
    \draw (2,2) circle (2cm);
    \draw[->] (2,2) -- (3.4,3.4);
    \filldraw[black] (2.7,2.7) circle (0pt)node[anchor=west] {$R$};
    \filldraw[black] (2,2) circle (1pt)node[anchor=west] {$z_0$};
    \end{tikzpicture}
\end{center}

In virtù di (\ref{7.1}), la funzione $f(z)$ ammette uno sviluppo in serie di Taylor-Laurent:
\begin{equation} \label{7.1.1}
    f(z)=\sum_{n=-\infty}^{\infty}c_n(z-z_o)^n \ \ \ \ \ \ \ \text{per} \ \   0<|z-z_0|<R
\end{equation}
Ci sono 3 casi possibili:
\begin{enumerate}
    \item
    \rule{\textwidth}{0.7pt}
    Se in (\ref{7.1.1}) si ha $c_n=0 \ \forall n<0$ lo sviluppo si riduce a uno sviluppo in serie di Taylor e 
    \begin{equation}
        \exists \lim_{z \to z_0} f(z)=c_0
    \end{equation}
    Si dice allora che $f(z)$ ha una \textit{singolarità eliminabile} in $z=z_0$ dal momento che si può ridefinire $f(z_0)\equiv c_0=\lim_{z\to z_0}f(z)$.
    \\ \\
    \textbf{Esempio:} la funzione
    \begin{equation}
        f(z)=\frac{sin(z)}{z}
    \end{equation}
    è analitica nella corona circolare $0<|z|<\infty$.
    \\
    Dal momento che 
    \begin{equation}
        \lim_{z\to z=0}\frac{sin(z)}{z}=1
    \end{equation}
    il punto $z=0$ risulta essere un punto singolare eliminabile.
    \\
    \begin{equation}
        \frac{sin(z)}{z}=\frac{1}{z}\sum_{n=0}^{\infty}(-z)^n\frac{z^{2n+1}}{(2n+1)!}=\sum_{n=0}^{\infty}(-z)^n\frac{z^{2n}}{(2n+1)!}=1-\frac{z^2}{3!}+\frac{z^4}{5!}+... \ \ \ \text{per} \ |z|>0
    \end{equation}
    \\ 
    Risulta valere il seguente:
    \begin{theorem}
    Se $f(z)$ analitica nella corona $0<|z-z_0|<R$ è limitata in un $\delta$-intorno del punto $z_0$, ossia
    \begin{equation}
        \exists M>0 \ \text{e} \ 0<\delta<R \ \ : \ \ |f(z)|\leq M \ \forall z \ : \ 0<|z-z_0|<\delta
    \end{equation}
    allora il punto $z_0$ è un punto singolare eliminabile di $f(z)$.
    \end{theorem}
    \begin{proof}
    Si consideri l'espressione integrale per i coefficienti dello sviluppo in serie:
    \begin{equation}
        c_n=\frac{1}{2\pi i}\oint_C \frac{f(\eta)}{(\eta-z_0)^{n+1}}d\eta \ \ \forall n \in \mathds{Z}
    \end{equation}
    Si prende come $C$ una circonferenza $C_{\rho}$ centrata in $z_0$ e contenuta nel $\delta$-intorno ($\rho < \delta$).
    Allora:
    \begin{equation}
        |c_n|=\frac{1}{2\pi}\left|\oint_{C_{\rho}}\frac{f(\eta)}{(\eta-z_0)^{n+1}}d\eta\right|\leq \frac{1}{2\pi} \oint_{C_{\rho}}\frac{|f(\eta)|}{|\eta - z_0|^{n+1}}|d\eta|\leq \frac{M}{2\pi \rho^{n+1}}2\pi \rho=\frac{M}{\rho^n}
    \end{equation}
    Da cui, per $n<0$, il limite per $\rho \to 0$ causa $|c_n|\leq 0$, ossia $c_n=0 \ \ \forall n<0$, da cui il punto $z_0$ è un punto singolare eliminabile.
    \end{proof}
    
    
    \item 
    \rule{\textwidth}{0.7pt}
    Se in (\ref{7.1.1}) si ha
    \begin{equation}
        c_n=0 \ \ \forall n<-m \ \ \text{con} \ c_{-m}\ne 0 \ \ m>0
    \end{equation}
    da cui lo sviluppo in serie di Taylor-Laurent ha la forma:
    \begin{equation}
        f(z)=\sum_{n=-m}^{\infty}c_n(z-z_0)^n=\frac{c_{-m}}{(z-z_0)^m}+...+\frac{c_{-1}}{z-z_0}+\sum_{n=0}^{\infty}c_n(z-z_0)^n
    \end{equation}
    (con un numero finito di termini nella parte di Laurent) si dice allora che $z_0$ è un \textit{polo di ordine m} di $f(z)$.
    \\
    Vale la condizione:
    \begin{equation} \label{7.1.11}
        \exists \ \text{(finito)} \ \lim_{z \to z_0} (z-z_0)^m f(z)=c_m \ne 0
    \end{equation}
    La (\ref{7.1.11}) è una condizione necessaria e sufficiente affinchè $z_0$ sia un polo di ordine $m$.
    \\
    Infatti la funzione $\phi(z)\equiv (z-z_0)^m f(z)$ è analitica per $0<|z-z_0|<R$ e ha una singolarità eliminabile in $z_0$ e quindi ha nella corona circolare uno sviluppo in serie di Taylor, da cui:
    \begin{equation}
        f(z)=\frac{\psi(z)}{(z-z_0)^m}=\sum_{n=0}^{\infty}a_n(z-z_o)^{n-m}=\sum_{n=-m}^{\infty} a_{n+m}(z-z_0)^{n}
    \end{equation}
    Da cui si vede che nel termine di Laurent ci sono $m$ termini $\ne 0$, da cui $z_0$ è un polo di ordine $m$.
    \\ \\
    Quella elencata sopra è la dimostrazione di:
    \begin{theorem}
    $z_0$ è un polo di ordine $m$ di $f(z)$ se e solo se
    \begin{equation}
        \exists \ \text{(finito)} \ \lim_{z \to z_0}(z-z_0)^m f(z)=c\ne 0 \ \ \text{per qualche} \ m \ne 0
    \end{equation}
    \end{theorem}
    \textbf{Nota Bene:} $z_0$ è un polo di ordine $m$ di $f(z)$ $\iff$ $z_0$ è uno zero di ordine $m$ di $g(z)\equiv 1/f(z)$.
    \\ \\
    In generale vale:
     \begin{theorem}
     $z_0$ è un polo di ordine $m$ di $f(z)$ se e solo se
     \begin{equation}
         \exists \lim_{z \to z_0}f(z)=\infty
     \end{equation}
     \end{theorem}
     \begin{proof}
     Si considera $g(z)=1/f(z)$ che ha uno zero di ordine $m$ in $z_0$.
     \\
     Si usa allora:
     \begin{equation}
         \exists \ \lim_{z\to z_0}f(z)=\infty \ \ \iff \ \ \exists \ \lim_{z\to z_0} g(z)=0
     \end{equation}
     
     \end{proof}
     \textbf{Esempio:} La funzione
     \begin{equation}
         f(z)=\frac{1}{z^2}
     \end{equation}
     analitica in $\mathds{C}/\{0\}$ ha un polo di ordine $2$ in $z=0$, infatti
     \begin{equation}
         \lim_{z \to 0}z^2 f(z)=1
     \end{equation}
     
     \item 
     \rule{\textwidth}{0.7pt}
     Se in (\ref{7.1.1}) c'è un numero infinito di termini non nulli nella parte di Laurent si dice che $z_0$ è un \textit{punto singolare essenziale} di $f(z)$.
     \\
     In questo caso non esiste il limite (finito o infinito) di $f(z)$ per $z \to z_0$, ma vale:
     \begin{theorem}[\textbf{Th. di Casorati-Sochotskij-Weierstrass}]
     $\forall \varepsilon>0$ e $\forall \beta \in \mathds{C}$ esiste, in un qualsiasi $\delta$-intorno di un punto singolare essenziale $z_0$ della funzione $f(z)$ almeno un punto $z_1$ tale che $|f(z_1)-\beta|<\varepsilon$.
     \end{theorem}
     E vale anche il più forte:
     \begin{theorem}[\textbf{Th. di Picard}]
     $\forall \beta \in \mathds{C}$ esistono, in un qualsiasi $\delta$-intorno di un punto singolare essenziale $z_0$ di $f(z)$, infiniti punti in cui $f(z)=\beta$.
     \end{theorem}
     \textbf{Esempio:} La funzione $f(z)=e^{1/z}$ è analitica $\forall z \in \mathds{C}/\{0\}$ e ha un punto singolare essenziale in $z=0$.
     \\
     Si verifica che $\nexists \lim\limits_{z \to 0}f(z)$: basta restringersi sull'asse reale 
     \begin{equation}
         \lim_{x\to 0^-}e^{1/x}=0 \ \ne \ \lim_{x\to 0^+}e^{1/x}=+\infty
     \end{equation}
     Si può anche determinare lo sviluppo in serie di Taylor-Laurent nella corona $|z|>0$.
     \begin{equation}
         e^{1/z}=\sum_{n=0}^{\infty}\frac{1}{n!}\biggl( \frac{1}{z} \biggr)^n=...+\frac{1}{2!}\frac{1}{z^2}+\frac{1}{z}+1 \ \ \ \forall z \ : \ |z|>0
     \end{equation}
     che è uno sviluppo con infiniti termini non nulli nella parte di Laurent.
\end{enumerate}

\subsection{Il punto all'infinito come punto singolare isolato}

\begin{definition}
Il punto all'infinito ($z=\infty$) è un punto singolare isolato della funzione analitica $f(z)$ se si può trovare un $r$-intorno del punto $z=\infty$ in cui la funzione è analitica.
\end{definition}
Ossia per $|z|>r$ non ci sono singolarità di $f(z)$ a distanza finita da z=0.
\\
La funzione $f(z)$ ammette allora uno sviluppo in serie di Taylor-Laurent nella corona $r<|z|<\infty$:
\begin{equation}
    f(z)=\sum_{n=-\infty}^{\infty}c_n z^n
\end{equation}
Anche qua si distinguono 3 casi:
\begin{enumerate}
    \item 
    \rule{\textwidth}{0.7pt}
    Se $c_n=0 \ \ \forall n>0$ allora si dice che $z=\infty$ è un punto singolare eliminabile, con condizione necessaria e sufficiente:
    \begin{equation}
        \exists \ \text{(finito)} \ \lim_{z\to \infty}f(z)=c_0
    \end{equation}
    Per cui la funzionare si può sviluppare come:
    \begin{equation}
        f(z)=\sum_{n=-\infty}^0 c_n z^n
    \end{equation}
    \textbf{Esempio:} La funzione $f(z)=1/z$ è analitica in $0<|z|<\infty$ e ha in $z=\infty$ una singolarità eliminabile dal momento che
    \begin{equation}
        \lim_{z\to \infty}\frac{1}{z}=0
    \end{equation}
    Se $C_0=0$ allora $z=\infty$ è uno zero della funzione $f(z)$, o, generalizzando, se $c_0=c_{-1}=...=c_{-m-1}=0, c_m\ne 0$ allora si tratta di uno zero di ordine $m$.\\
    \item
    \rule{\textwidth}{0.7pt}
    Se nello sviluppo $c_n=0 \ \ \forall n>m$ e $c_m\ne 0 \ , \ \ m>0$ allora il punto $z=\infty$ è un polo di ordine $m$ di $f(z)$.
    \\
    Condizione necessaria e sufficiente è:
    \begin{equation}
        \lim_{z\to \infty}f(z)=\infty
    \end{equation}
    \textbf{Esempio:} La funzione $f(z)=z$ è intera e ha un polo di ordine $1$ in $z=\infty$.
    \\
    Infatti
    \begin{equation}
        \lim_{z\to \infty}z=\infty
    \end{equation}
    e si può scrivere come serie
    \begin{equation}
        f(z)=z=\sum_{n=-\infty}^1c_nz^n
    \end{equation}
    con $c_1=1$ e $c_n=0 \ \ \forall \ n \ne 1$.
    
    
    
    \item
    \rule{\textwidth}{0.7pt}
    Se lo sviluppo contiene un numero infinito di termini non nulli con potenze positive di $z$, allora si dice che $z=\infty$ è un punto singolare essenziale.
    \\
    Non esiste il limite per $z$ che va a infinito di $f(z)$, nè finito nè infinito.
    \\ \\
    \textbf{Esempio:} La funzione $f(z)=e^z$ è intera e ha in $z=\infty$ una singolarità essenziale, dal momento che è:
    \begin{equation}
        f(z)=e^z=\sum_{n=0}^{\infty}\frac{1}{n!}z^n
    \end{equation}
    Si verifica facilmente che non esiste il limite. Basta mettersi sull'asse reale per osservare che
    \begin{equation}
        \lim_{x\to -\infty}e^x=0 \ \ne \ \lim_{x\to \infty}e^x=+\infty
    \end{equation}
\end{enumerate}

\textbf{Osservazione:} La trasformazione $z=1/z'$ mappa il punto $z=\infty$ nel punto $z'=0$ e l'$r$-intorno del punto $z=\infty$ nell'$R'$-intorno ($R'=1/r$) di $z'=0$.
\\
Ossia il punto singolare isolato $z=\infty$ per $f(z)$ viene mappato nel punto singolare isolato $z'=0$ della funzione $g(z)\equiv f(1/z')$ e il carattere del punto isolato non cambia. Infatti:
\begin{equation*}
    g(z')=f\left(\frac{1}{z'}\right)=\sum_{n=-\infty}^{\infty}c_n\left(\frac{1}{z'}\right)^n   \xrightarrow[n \rightarrow -n] \  \sum_{n=-\infty}^{\infty} c_{-n}z'^n=\sum_{n=-\infty}^{\infty}a_n z'^n \ \ \ \text{per} \ \ 0<|z'|<R'=\frac{1}{r'} \ \ a_n=c_{-n} \ \forall n
\end{equation*}

\newpage
\setcounter{section}{10}
\section{Teoria dei residui}
Una funzione analitica nell'intorno di un punto singolare isolato $z_0$, può essere sviluppata in serie di Taylor-Laurent in $0<|z-z_0|<R$:
\begin{equation}
    f(z)=\sum_{n=-\infty}^\infty c_n(z-z_0)^n \qquad c_n=\frac{1}{2\pi i}\oint_C \frac{f(\eta)}{(\eta-z_0)^{n+1}} \ d\eta
\end{equation}
Con $C$ curva chiusa qualsiasi nel dominio di analiticità della funzione $f(z)$, $0<|z-z_0|<R$, e contenente al suo interno il punto $z_0$.\\
\begin{definition}
Il \textit{residuo} della funzione analitica $f(z)$ nel punto $z_0$ è il numero complesso:
\begin{equation}
    Res[f(z),z_0]\equiv C_{-1}=\frac{1}{2\pi i}\oint_C f(\eta)\ d\eta
\end{equation}
\end{definition}
Se $z_0$ è un punto singolare eliminabile di $f(z)$ allora $Res[f(z),z_0]=0$.\\
\subsection{Calcolo del residuo per un polo}
Se $z_0$ è un polo di ordine 1 di $f(z)$ vale la:
\begin{equation}
    Res[f(z),z_0]=\lim_{z\to z_0} (z-z_0)f(z)
\end{equation}
\begin{proof}
In questo caso lo sviluppo in serie di Taylor-Laurent ha la forma:
\begin{equation}
    f(z)=\frac{c_{-1}}{z-z_0}+c_0+c_1(z-z_0)+... \Longrightarrow \lim_{z\to z_0} (z-z_0)f(z)=c_{-1}\equiv Res[f(z),z_0]
\end{equation}
\end{proof}
\begin{theorem}
Se f(z) è della forma:
\begin{equation}
    f(z)=\frac{g(z)}{h(z)}
\end{equation}
con g(z) e h(z) funzioni analitiche in $z_0$, $g(z_0)\ne$0, $h(z_0)=0$ e $h'(z_0)=0$, ovvero zero di ordine 1, allora $z_0$ è un polo di ordine 1 di f(z), con:
\begin{equation}
    Res[f(z),z_0]=\frac{g(z)}{h'(z)}
\end{equation}
\end{theorem}
\begin{proof}
Nell'intorno di $z_0$, valgono gli sviluppi di Taylor:
\begin{equation}
    g(z)=g(z_0)+g'(z_0)(z-z_0)+... \qquad h(z)=h'(z_0)(z-z_0)+\frac{1}{2!}h''(z_0)(z-z_0)^2+...
\end{equation}
Per cui esiste il limite:
\begin{equation}
    \lim_{z\to z_0}(z-z_0)f(z)=\lim_{z\to z_0}(z-z_0)\frac{g(z)}{h(z)}=\frac{g(z_0)}{h'(z_0)}\ne 0
\end{equation}
\end{proof}
Generalizzando:
\begin{theorem}
$z_0$ è un polo di ordine m di f(z):
\begin{equation}
    Res[f(z),z_0]=\frac{1}{(m-1)!}\lim_{z\to z_0}\frac{d^{m-1}}{dz^{m-1}}[(z-z_0)^mf(z)]
\end{equation}
\end{theorem}
\begin{proof}
In un intorno di $z_0$, $f(z)$ uno ammette sviluppo in serie di Taylor-Laurent:
\begin{equation}
    f(z)=\frac{c_{-m}}{(z-z_0)^m}+...+\frac{c_{-1}}{z-z_0}+c_0+c_1(z-z_0)+... \Longrightarrow  f(z)(z-z_0)^m=c_{-m}+...+c_{-1}(z-z_0)^{m-1}+...
\end{equation}
Da cui
\begin{equation*}
    \frac{d^{m-1}}{dz^{m-1}}[(z-z_0)^mf(z)]=(m-1)!c_{-1}+O(z-z_0)\Longrightarrow Res[f(z),z_0]=\frac{1}{(m-1)!}\lim_{z\to z_0}\frac{d^{m-1}}{dz^{m-1}}[(z-z_0)^mf(z)]
\end{equation*}
\end{proof}
\subsection{Teorema fondamentale della teoria dei residui}
\begin{theorem}\label{11 interno}
f(z) analitica all'interno di un contorno chiuso $\Gamma$, tranne che in un numero finito di punti singolari isolati $z_k$, k=1,...;N.\\
$\Longrightarrow$ se f(z) regolare (analitica, o almeno continua) su $\Gamma$, allora:
\begin{equation}
    \oint_\Gamma f(z)dz=2\pi i \sum_1^NRes[f(z),z_k]
\end{equation}
\end{theorem}
\begin{proof}
Viene anche detto teorema interno dei residui.\\
Posso isolare i punti singolari isolati $z_k$ all' interno di $\Gamma$ con delle curve chiuse $C_k$ contenute dentro $\Gamma$, non intersecanti e tali che contengano internamente solo il punto singolare $z_k$.\\
Applicando il teorema di Cauchy (\ref{4.1.1}) al dominio a connessione multipla racchiuso dalla frontiera $\Gamma\cup C_1\cup C_2...\cup C_N$ si ottiene:
\begin{equation}
    \oint_\Gamma f(z)dz=\sum_i^N\oint_{C_k}f(z)dz=2\pi i \sum_1^N Res[f(z),z_k]
\end{equation}
\end{proof}
Il teorema vale anche in una formulazione più generale, in cui $\Gamma$ sia la frontiera totale di un dominio a connessione multipla $G$, in cui $f(z)$ sia ovunque analitica tranne che in un numero N finito di punti singolari isolati e continua su $\Gamma$.


\subsection{Residuo all'infinito}
Se $z=\infty$ è un punto singolare isolato di $f(z)$ allora può essere sviluppata in serie di Taylor-Laurent in un intorno $r<z<\infty$ centrata in $z_0=0$.
\begin{equation}
    f(z)=\sum_{n=-\infty}^\infty c_nz^n \qquad c_n=\frac{1}{2\pi i}\oint_C \frac{f(\eta)}{\eta^{n+1}}d\eta
\end{equation}
Con $C$ curva chiusa nella corona circolare $r<|z|<\infty$ e racchiudente il punto $z=0$ (centro dello sviluppo).
\begin{definition}
Se z=$\infty$ è un punto singolare isolato della funzione f(z), si dice \textit{residuo all'infinito} di f(z) il numero complesso:
\begin{equation}
    Res[f(z),\infty]\equiv-C_{-1}=-\frac{1}{2\pi i}\oint_C f(\eta)\ d\eta=\frac{1}{2\pi i}\oint_{C^-} f(\eta)\ d\eta
\end{equation}
\end{definition}
In questo caso il valore del residuo può essere non nullo anche nel caso in cui $z=\infty$ sia un punto singolare eliminabile. Ad esempio per la funzione $f(z)=\frac{1}{z}$, con $Res[\frac{1}{z},\infty]=-1$, ma $\lim_{z\to\infty}\frac{1}{z}=0$
\subsection{Teorema esterno dei residui}
\begin{theorem}
 f(z) è analitica ovunque all'esterno di un contorno chiuso $\Gamma$, tranne che in un numero finito N$_e$ di punti singolari isolati $z_e$ e f(z) è regolare su $\Gamma$.\\
 $\Longrightarrow$
 \begin{equation}
     \oint_\Gamma f(z)dz=-2\pi i \sum_1^{N_e}Res[f(z),z_e]-2\pi i Res[f(z),\infty]
 \end{equation}
\end{theorem}
\begin{proof}
Si pone $r\equiv Max\{|z_e|\}$, $f(z)$ risulta analitica per $r<f(z)<\infty$, per cui è sviluppabile in serie di Taylor-Laurent.\\
Tutti i punti singolari isolati sono contenuti nel cerchio $\Delta_r=\{ z:|z|<r \}$.
\\
Per cui $z=\infty$ è punto singolare isolato: presa una qualsiasi curva chiusa $C$ nella corona circolare e contenente $z=0$, per costruzione conterrà anche la curva $\Gamma$ e i punti $z_e$
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{ResiduiEsterni.PNG}
\end{figure}
Nel dominio $D$ a connessione multipla, racchiuso fra le curve $C$ e $\Gamma$, $f(z)$ risulta analitica tranne che nei punti $z_e$. Applicando il teorema interno dei residui (\ref{11 interno}) si trova che:
\begin{equation}
    \oint_c f(z)dz+\oint_{\Gamma^-}f(z)dz=2\pi i \sum_{e=1}^{N_{ext}}Res[f(z),z_e]
\end{equation}
Dove $N_{ext}$ è il numero di punti singolari isolati esterni a $\Gamma$.\\
Si isola dunque la parte su $\Gamma$ e si sfrutta la definizione di $Res[f(z),\infty]$:
\begin{equation}
     \oint_\Gamma f(z)dz=-2\pi i \sum_1^{N_e}Res[f(z),z_e]-2\pi i Res[f(z),\infty]
 \end{equation}
\end{proof}
Si ottiene come corollario \begin{theorem}
 f(z) analitica in tutto $\mathds{C}$ tranne che in un numero finito di punti singolari isolati $z_k$.\\
 $\Longrightarrow$
 \begin{equation}
     \sum_{k=1}^N Res[f(z),z_k]+Res[f(z),\infty]=0
 \end{equation}
\end{theorem}
\begin{proof}
Si pone $r\equiv Max\{|z_e|\}$, $f(z)$ risulta analitica per $r<f(z)<\infty$, per cui è sviluppabile in serie di Taylor-Laurent.\\
Per cui $z=\infty$ è punto singolare isolato: presa una qualsiasi curva chiusa $C$ nella corona circolare e contenente $z=0$, per costruzione conterrà tutti punti $z_k$.\\
Applicando il teorema esterno dei residui:
\begin{equation}
    \oint_C f(z)dz=-2\pi i Res[f(z),\infty]
\end{equation}
Applicando, invece, il teorema interno dei residui:
\begin{equation}
    \oint_C f(z)dz=2\pi i\sum_1^N Res[f(z),z_k]
\end{equation}
Uguagliando si ricava la tesi.

\end{proof}

\newpage
\section{Applicazioni dei residui al calcolo di integrali di funzioni di variabili reali}

\subsection{Integrali della forma \texorpdfstring{$\int_{-\infty}^{\infty}f(x)dx$}{Lg}}
\begin{lemma} \label{bruh}
Se $f(z)$ è analitica nel semipiano complesso superiore $Im(z)\ge0$ (oppure in quello inferiore) ovunque tranne che in un numero finito di punti singolari isolati e se vale:
\begin{equation}
    \lim_{R\to \infty}R \cdot \max_{z\in C_R'}|f(z)|=0
\end{equation}
dove $C_R'$ è la semicirconferenza di raggio $R$ e centro in $z=0$ nel semipiano complesso superiore (oppure in quello inferiore), allora:
\begin{equation}
    \lim_{R\to \infty}\int_{C_R'}f(z)dz=0
\end{equation}
\end{lemma}

\begin{proof}
Segue dal \textit{Lemma di Darboux} (\ref{4 Darboux}):
\begin{equation}
    \left|\int_{C_R'}f(z)dz\right|\le \max_{z\in C_R'}|f(z)|\cdot \pi R \xrightarrow[R\to \infty] \ 0
\end{equation}
\end{proof}

\begin{theorem} \label{king}
Si supponga che $f(x)$, definita $\forall x \in \mathds{R}$ e tale che ne esista l'integrale improprio
\begin{equation}
    \int_{-\infty}^{\infty}f(x)dx\equiv \lim_{R\to \infty} \lim_{R' \to \infty}\int_{-R}^{R'}f(x)dx
\end{equation}
possa essere prolungata analiticamente al semipiano complesso superiore $Im(z)\ge 0$ e che il suo prolungamento analitico $f(z)$ soddisfi le ipotesi del Lemma (\ref{bruh}) e non abbia punti singolari sull'asse reale.
\\
Allora si ha:
\begin{equation}
    \int_{-\infty}^{\infty}f(x)dx=2\pi i \sum_{k=1}^N Res[f(z),z_k]
\end{equation}
dove $z_k$ sono i punti singolari della funzione nel semipiano complesso superiore (analogo col semipiano inferiore).
\end{theorem}
\begin{proof}
Prendendo $R>\max_k |z_k|$ e applicando il Th. fondamentale dei residui:
\begin{equation}
    \int_{-R}^R f(x)dx+\int_{C_R'}f(z)dz=2\pi i \sum_{k=1}^N Res[f(z),z_k]
\end{equation}
Perciò prendendo il limite $R\to \infty$ e usando il Lemma (\ref{bruh}) segue la tesi.

\end{proof}

\textbf{Nota Bene:} Se si applica il Th. (\ref{king}) al semipiano complesso inferiore la curva viene percorsa in senso negativo:
\begin{equation}
\int_{-R}^R f(x)dx + \int_{C_{R^-}'}f(z)dz=-2\pi i \sum_{k=1}^N Res[f(z),z_k]
\end{equation}

\subsection{Integrali della forma \texorpdfstring{$\int_0 ^{2\pi}R(cos(\theta),sin(\theta))d\theta$}{Lg}}
Dove $R$ è una funzione razionale dei suoi argomenti.
\\
Si ponga $z\equiv e^{i\theta}=cos(\theta)+isin(\theta)$.
\begin{equation}
    \begin{split}
        cos(\theta)=\frac{1}{2}(e^{i\theta}+e^{-i\theta})=\frac{1}{2}\left(z+\frac{1}{z}\right) \\
        sin(\theta)=\frac{1}{2i}(e^{i\theta}-e^{-i\theta})=\frac{1}{2i}\left( z-\frac{1}{z}\right) \\
        d\theta = \frac{1}{iz}dz \ \ \ \ \ \ dz=ie^{i\theta}d\theta=izd\theta
    \end{split}
\end{equation}
Con queste relazioni l'integrale diviene:
\begin{equation} \label{10.1.2}
    I\equiv \int_0 ^{2\pi} R(cos(\theta),sin(\theta))d\theta=\oint_{|z|=1}R\left[ \frac{1}{2}\left( z+\frac{1}{z} \right),\frac{1}{2i}\left( z-\frac{1}{z} \right) \right]\frac{dz}{iz}\equiv \oint_{|z|=1}\Tilde{R}(z)dz
\end{equation}
dove 
\begin{equation}
    \Tilde{R}(z)\equiv \frac{1}{iz}R\left[ \frac{1}{2}\left( z+\frac{1}{z} \right),\frac{1}{2i}\left( z-\frac{1}{z} \right) \right]
\end{equation}
è una funzione razionale di $z$ (rapporto di due polinomi primi tra loro in $z$).
\\
$\Tilde{R}(z)$ è analitica in tutto $\mathds{C}$ tranne che negli $N_q\le q$ zeri del polinomio di grado $q$ al denominatore.
\\
Applicando il \textit{Th. interno dei residui} (\ref{11 interno}) l'integrale in (\ref{10.1.2}) diviene:
\begin{equation}
    I=\oint_{|z|=1}\Tilde{R}(z)dz=2\pi i \sum_{k=1}^{N_{int}}Res[\Tilde{R}(z),z_k]
\end{equation}
Dove la somma è estesa a tutti i poli interni al dominio circondato dalla curva di integrazione (in questo caso si tratta della circonferenza centrata in 0 con raggio 1).
\subsubsection{Esempio}
Si calcoli l'integrale, con a$\in\mathds{R}$ e $|a|<1$
\begin{equation}
    I=\int_0^{2\pi}\frac{d\theta}{1+acos\theta}
\end{equation}
Si applicano le dovute sostituzioni:
\begin{equation}
     I=\int_0^{2\pi}\frac{d\theta}{1+acos\theta}=\int_{|z|=1}\frac{1}{iz(1+\frac{a}{2}\biggl(z+\frac{1}{z}\biggr)}dz=\frac{2}{i}\int_{|z|=1}\frac{dz}{az^2+2z+a}
\end{equation}
Si trovano dunque i punti singolari della funzione integranda:
\begin{equation}
    z_1,z_2=\frac{-1\pm\sqrt{1-a^2}}{a}\in \mathds{R}\Longrightarrow az^2+2z+a=a(z^2-Sz+P)
\end{equation}
Con S$\equiv z_1+z_2=-\frac{2}{a}$, P$\equiv z_1z_2=1$, da cui un solo punto singolare è all'interno del cerchio di raggio 1:
\begin{equation}
z_1=\frac{-1+\sqrt{1-a^2}}{a}=-\frac{a}{1+\sqrt{1-a^2}} \Longrightarrow |z_1|=\frac{|a|}{1+\sqrt{1-a^2}}<|a|<1
\end{equation}
Per cui per il teorema interno dei residui si trova:
\begin{equation}
    I=\frac{2}{i}2\pi iRes\biggl[\frac{1}{az^2+2z+a},z_1\biggr]=\frac{2\pi}{\sqrt{1-a^2}}
\end{equation}

\subsection{Integrali della forma \texorpdfstring{$\int_{-\infty}^{\infty}e^{i\alpha x}f(x) dx$}{Lg}}

\begin{lemma}[\textbf{Lemma di Jordan}]\label{Air Jordan}
Se la funzione $f(z)$ è analitica nel semipiano complesso superiore (oppure nell'inferiore), tranne che in un numero finito di punti singolari isolati $z_k$ e se tende a zero in modulo uniformemente rispetto ad $arg(z)$, ossia:
\begin{equation}
    \lim_{R\to \infty}\left(\max_{z \in C_R '} |f(z)| \right)=0
\end{equation}
dove $C_R '$ è la semicirconferenza di raggio $R$ e centro z=0 nel semipiano complesso superiore (oppure inferiore), ovvero:
\begin{equation}
    \exists \ \mu(R) \ : \ \ |f(z)|\le \mu(R) \ \ \ \text{per} \ \ |z|=R \ \ \text{con} \ \ \mu(R)\to 0 \ \ \text{per} \ R \to \infty
\end{equation}
allora si ha che, prendendo $a \in \mathds{R}$:
\begin{itemize}
    \item \begin{equation}
        \lim_{R\to \infty}\int_{C_R'}e^{iaz}f(z) dz =0 \ \ \ \text{per} \ \ a>0
    \end{equation}
    nel semipiano complesso superiore.
    \item \begin{equation}
        \lim_{R\to \infty}\int_{C_R'}e^{iaz}f(z)dz=0 \ \ \ \text{per} \ \ a<0
    \end{equation}
    nel semipiano complesso inferiore.
\end{itemize}
\end{lemma}

\begin{proof}
Nel primo caso si parametrizza un semicerchio nel semipiano $Im(z)\ge0$ come 
\begin{equation}
    C_R'=\{ z \ : \ z=Re^{i\theta}, \ \theta \in [0,\pi] \}
\end{equation}
da cui
\begin{align}
    \left| \int_{C_R'}e^{iaz}f(z) dz \right|&=\left| \int_{C_R'}e^{iaRcos\theta-aRsen\theta}f(Re^{i\theta}) iRe^{i\theta}d\theta \right|\le \int_0^\pi e^{-aRsen\theta}|f(z)|Rd\theta\\
    &\le R\mu(R)\int_0^\pi e^{-aRsen\theta}d\theta=R\mu(R)\int_0^\frac{\pi}{2}
    e^{-aRsen\theta}d\theta+\int_{\frac{\pi}{2}}^\pi e^{-aRsen\theta}d\theta=\\
    &= R\mu(R)\int_0^\frac{\pi}{2}e^{-aRsen\theta}d\theta+\int_0^{\frac{\pi}{2}} e^{-aRsen\theta'}d\theta'=2R\mu(R)\int_0^\frac{\pi}{2}e^{-aRsen\theta}d\theta
\end{align}
Si sfrutta ora il fatto che sen$\theta\ge\frac{2}{\pi}\theta$ se $\theta\in[0,\pi/2]$:
\begin{align}
    \left| \int_{C_R'}e^{iaz}f(z) dz \right|&\le2R\mu(R)\int_0^\frac{\pi}{2}e^{-aRsen\theta}d\theta\le2R\mu(R)\int_0^\frac{\pi}{2}e^{-\frac{2aR}{\pi}\theta}d\theta=\\
    &=2 R\mu(R)\frac{e^{-\frac{2aR}{\pi}\theta}}{-\frac{2aR}{\pi}}\biggl|_0^\frac{\pi}{2}=\frac{\pi}{a}\mu(R)[1-e^{-aR}]\xrightarrow{R\to\infty}0
\end{align}
Da cui segue la tesi. Il caso relativo al semipiano inferiore è analogo parametrizzando $\theta\in[-\pi,0]$
\end{proof}

\begin{theorem}
Se la funzione $f(x)$, definita $\forall x \in \mathds{R}$, può essere prolungata analiticamente nel semipiano complesso superiore (oppure in quello inferiore) e il suo prolungamento $f(z)$ soddisfa le ipotesi del Lemma di Jordan (\ref{Air Jordan}) e non ha punti singolari sull'asse reale, allora si ha che (per $a \in \mathds{R})$:
\begin{itemize}
    \item \begin{equation}
        \int_{-\infty}^{\infty}e^{iax}f(x)dx=2\pi i \sum_{k=1}^N Res[e^{iaz}f(z),z_k] \ \ \ \text{per} \ \ a>0
    \end{equation}
    \item \begin{equation}
        \int_{-\infty}^{\infty}e^{iax}f(x)dx=-2\pi i \sum_{k=1}^N Res[e^{iaz}f(z),z_k] \ \ \ \text{per} \ \ a<0
    \end{equation}
\end{itemize}
Dove $z_k$ sono i punti singolari della funzione nel semipiano in esame.
\end{theorem}

\begin{proof}
Basta applicare il \textit{Th. interno dei residui} (\ref{11 interno}) al dominio racchiuso dal contorno $[-R,R] \cup C_R'$ e segue direttamente dal \textit{Lemma di Jordan} (\ref{Air Jordan}).
\end{proof}
\subsubsection{Esempio}
\begin{equation}
    I=\int_\infty^\infty\frac{sen(ax)}{x}dx
\end{equation}
Si osservi come non si possa scrivere I=Im$\int_\infty^\infty\frac{e^{iax}}{x}dx$, poichè tale integrale non esiste a causa della divergenza in 0, a differenza dell'integrale di partenza.\\
Si può bypassare il problema come:
\begin{equation}
    I=\lim_{R\to\infty,r\to0^+}\{\int_{-R}^{-r}+\int_r^R\}\frac{sen(ax)}{x}dx=ImI_1 \qquad I_1=\lim_{R\to\infty,r\to0^+}\{\int_{-R}^{-r}+\int_r^R\}\frac{e^{iax}}{x}dx\equiv P\int_{-\infty}^\infty\frac{e^{iax}}{x}dx
\end{equation}
Inteso come integrale in senso principale di Cauchy.\\
Il prolungamento analitico della funzione f(x) è la funzione f(z)$=\frac{e^{iaz}}{z}$ analitica $\forall z\in\mathds{C}/\{z=0\}$, difatti in z=0 la funzione ha un polo di ordine 1.\\
Per calcolare I$_1$ si utilizza il teorema interno dei residui per l'integrale lungo il cammino chiuso $\Gamma$:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{11.PNG}
    \label{fig:my_label}
\end{figure}
Dove:
\begin{equation}\int_{C'_R}\frac{e^{iaz}}{z}dz
    \oint_\Gamma\frac{e^{iaz}}{z}dz=\biggl\{\int_{-R}^{-r}+\int_r^R\biggr\}\frac{e^{iax}}{x}dx+\int_{C'_{r^-}}\frac{e^{iaz}}{z}dz+\int_{C'_R}\frac{e^{iaz}}{z}dz=0
\end{equation}
Dato che $\biggl|\frac{1}{z}\biggr|=\frac{1}{R}\xrightarrow{R\to\infty}$, quindi la funzione soddisfa le ipotesi del lemma di Jordan si ha:
\begin{equation}
    \lim_{R\to\infty}\int_{C'_R}\frac{e^{iaz}}{z}dz=0
\end{equation}
Per cui passando al limite si ottiene:
\begin{equation}
    I_1=P\int_{-\infty}^\infty\frac{e^{iax}}{x}dx=-\lim_{r\to 0^+}\int_{C'_{r^-}}\frac{e^{iaz}}{z}dz=\lim_{r\to 0^+}\int_{C'_r}\frac{e^{iaz}}{z}dz
\end{equation}
Per il cui calcolo si ricorre:
\begin{theorem}
Se la funzione $F(z)$ ha un polo di ordine 1 in $z=z_0$, allora, detto $\gamma_r$ un arco di circonferenza di centro $z_0$, raggio $r$ e ampiezza $\alpha$, si ha:
\begin{equation}
    \lim_{r\to 0^+}\int_{\gamma_r^+}F(z)dz=i\alpha Res[F(z),z_0]
\end{equation}

\end{theorem}

\begin{proof}
Se $z=z_0$ è un polo di ordine 1 di $F(z)$, esiste un intorno $\Delta_R '$ di $z_0$ in cui $F(z)$ è analitica e sarà della forma:
\begin{equation}
    F(z)=\frac{g(z)}{z-z_0}
\end{equation}
con $g(z)$ analitica in $z_0$.
\\
Allora, prendendo $r<R$ e parametrizzando $\gamma_r$ così:
\begin{equation}
    \gamma_r=\{z=z_0+re^{i\theta} \ , \ \theta \in [\theta_0,\theta_0+\alpha]\}
\end{equation}
si trova:
\begin{equation}
    \int_{\gamma_r ^+}F(z)dz=\int_{\gamma_r^+}\frac{g(z)}{z-z_0}dz=\int_{\theta_0}^{\theta_0+\alpha}\frac{g(z_0+re^{i\theta})}{re^{i\theta}}ire^{i\theta}d\theta
\end{equation}
Perciò, prendendo il limite per $r\to 0^+$ e usando la continuità di $g$ in $z_0$:
\begin{equation}
    \lim_{r\to 0^+}\int_{\gamma_r^+}F(z)dz=i \lim_{r \to 0^+} \int_{\theta_0}^{\theta_0 +\alpha} g(z_0+re^{i\theta})d\theta=ig(z_0)\int_{\theta_0}^{\theta_0 +\alpha}d\theta=i\alpha g(z_0)
\end{equation}
Ma dal momento che 
\begin{equation}
    Res[F(z),z_0]=\lim_{z\to z_0}(z-z_0)F(z)=g(z_0)
\end{equation}
si vede che
\begin{equation}
    \lim_{r \to 0^+}\int_{\gamma_r ^+}F(z) dz=i\alpha Res[F(z),z_0]
\end{equation}
\end{proof}
Per cui nell'integrale:
\begin{equation}
    I_1=\lim_{r\to 0^+}\int_{C'_r}\frac{e^{iaz}}{z}dz=i\pi Res\biggl[\frac{e^{iaz}}{z},z=0]=i\pi \Longrightarrow I=Im(I_1)=\pi
\end{equation}

\subsection{Integrali della forma \texorpdfstring{$\int_0^\infty x^\alpha f(x)dx$}{Lg} o \texorpdfstring{$\int_0^\infty x^{\alpha-1} f(x)dx$}{Lg}}
Per il caso $\int_0^\infty x^\alpha f(x)dx$ si faccia l'ipotesi:
\begin{itemize}
    \item il prolungamento analitico $f(z)$ sia una funzione analitica univoca ovunque tranne che in un numero finito $N$ di punti singolari isolati $z_k$, $k=0,1,...,N$, non giacenti sul semiasse reale positivo.
    \item $z=0$ punto singolare eliminabile.
    \item Valga la condizione:
    \begin{equation}
        \max_{z\in C_R}|f(z)|R^{\alpha+1} \to 0, R\to\infty\qquad \alpha\in\mathds{R}, 0<\alpha<1
    \end{equation}
    Su $C_R$ circonferenza di raggio $R$ e centro $z=0$.
\end{itemize}
Si dimostra allora che:
\begin{equation} \label{13 alpha}
    \int_0^\infty x^\alpha f(x)dx=\frac{2\pi i}{1-e^{i2\pi a}} \sum_{k=1}^{N}Res[f(z)z^\alpha,z_k]
\end{equation}
Nel caso $\int_0^\infty x^{\alpha-1} f(x)dx$, sostituendo alla terza ipotesi:
\begin{equation}
     \max_{z\in C_R}|f(z)|R^{\alpha} \to 0, R\to\infty\qquad \alpha\in\mathds{R}, 0<\alpha<1
\end{equation}
Si dimostra che
\begin{equation} \label{13 alpha-1}
    \int_0^\infty x^{\alpha-1} f(x)dx=\frac{2\pi i}{1-e^{i2\pi a}} \sum_{k=1}^{N}Res[f(z)z^{\alpha-1},z_k]
\end{equation}
\begin{proof}
Si dimostra prima la relazione (\ref{13 alpha}). Si definisce $F(Z)\equiv z^\alpha f(z)$, con $\alpha\in\mathds{R},0<\alpha<1$.\\
Essendo $z^\alpha\equiv e^{\alpha log(z)}$, $log(z)=log(|z|)+iarg(z)+i2\pi l, l\in\mathds{Z}$, $F(z)$ è una funzione multivoca.\\
Prendendo $arg(z)\in[0,2\pi]$ ed il ramo con $l=0$, diventa una funzione analitica univoca nel dominio G=$\mathds{C}/\{z:Re(z)\le0,Im(z)=0\}$, tranne che in un numero finito di punti singolari  isolati $z_k, \ k=1,...,N$. Tale funzione è il prolungamento analitico della funzione integranda $F(x)=x^\alpha f(x)$ ($x>0$), esse coincidono sul bordo superiore del "taglio", $arg(z)\to 0^+$.\\
Si integra $F(z)$ lungo il contorno chiuso $\Gamma$ in Figura (\ref{13 figura}):
\begin{figure}[H]\label{13 figura}
    \centering
    \includegraphics[scale=0.2]{contorno.JPG}
\end{figure}
Si sceglie $r$ sufficientemente piccolo ed $R$ sufficientemente grande, in modi che i punti singolari siano tutti compresi nella corona circolare.\\
Si sfrutta ora il teorema interno dei residui:
\begin{equation}
    \oint F(z)dz=\int_{I^+}F(z)dz +\int_{C_R}F(z)dz+\int_{I^-}F(z)dz+\int_{C_r^-+}F(z)dz=2\pi i\sum_1^{N_e}Res[f(z)z^{\alpha-1},z_k]
\end{equation}
Si valutano ora i 4 integrali:
\begin{itemize}
    \item $\int_{I_+}F(z)dz=\int_r^Rx^\alpha f(x)dx\to\int_0^\infty x^\alpha f(x)dx$ per $R\to\infty, r\to 0$.\\
    Sfruttando che arg(z)$\to0^+$.
    \item $\int_{C_R}F(z)dz$, per le ipotesi su $f(z)$ si ha che:
    \begin{equation}
        \left|\int_{C_R}F(z)dz\right|\le\int_{C_R}|F(z)|dz\le max_{z\in C_R}|f(z)|R^\alpha 2\pi R\to 0 \Longrightarrow \lim_{R\to\infty}\int_{C_R}F(z)dz=0
    \end{equation}
    \item $\int_{I_-}F(z)dz$, in questo caso arg(z)$\to =2\pi^-$, per cui $F(z)=z^\alpha f(z)\to x^\alpha f(z)e^{i2\pi\alpha}$. Per cui:
    \begin{equation}
        \int_{I_-}F(z)dz=\int_R^rx^\alpha f(x)e^{i2\pi\alpha}dx\to -e^{i2\pi\alpha}\int_0^\infty x^\alpha f(x)dx \text{ per } R\to\infty, r\to 0.\\
    \end{equation}
    \item $\int_{C_r^-}F(z)dz$, dato che $z=0$ è un punto singolare eliminabile di $f(z)$ per ipotesi, in un $\delta$-intorno $\Delta_z$ sufficientemente piccolo di $z=0$, $\exists M>0:|f(z)|\le M \forall z\in \Delta_z$.\\
    Per cui prendendo $r<\delta$
    \begin{equation}
        \left|\int_{C_r^-}F(z)dz\right|\le\int_{C_r^-}|F(z)||dz|\le Mr^\alpha 2\pi r\to 0 \Longrightarrow \lim_{r\to0}\int_{C_r^-}F(z)dz=0
    \end{equation}
\end{itemize}
Per cui mettendo assieme i pezzi e passando al limite si ottiene la (\ref{13 alpha}).\\
Per ricavare la (\ref{13 alpha-1}) si ripetono gli stessi passaggi con la sostituzione $\alpha\to\alpha -1$
\end{proof}

\subsection{Integrali della forma \texorpdfstring{$\int_0^\infty f(x)log(x)dx$}{Lg}}
Si faccia l'ipotesi che il prolungamento analitico $f(z)$ sia una funzione analitica univoca ovunque tranne che in un numero finito $N$ di punti singolari isolati $z_k$, $k=0,1,...,N$, non giacenti sul semiasse reale positivo e che $z=0$ sia un punto singolare eliminabile.\\
La funzione$ F(z)\equiv f(z)log(z)$, prendendo il ramo con $k=0$ e con $arg(z)\in[0,2\pi]$:
\begin{equation}
    log(z)\equiv log(|z|)+iarg(z)
\end{equation}
è una funzione analitica univoca nel dominio G=$\mathds{C}/\{z:Re(z)\ge0,Im(z)=0\}$, tranne che in numero finito di punti singolari isolati. Risulta quindi il prolungamento analitico della funzione integranda, le due funzioni coincidono sul bordo superiore del taglio.\\
E' possibile integrare la funzione desiderata, considerando il cammino $\Gamma$ mostrato in figura (\ref{13 figura}) e integrando su essa la funzione $G(Z)=\equiv f(z)log^2(z)$ con la condizione:
\begin{equation}
    \lim_{R\to\infty}\int_{C_R}f(z)(log(z))^2dz=0
\end{equation}
Il fatto che $z=0$ sia un punto singolare eliminabile per $f(z)$, garantisce anche:
\begin{equation}
    \lim_{r\to0}\int_{C_r}f(z)(log(z))^2 dz =0
\end{equation}
Difatti per $r$ sufficentemenente piccolo si trova che $\exists M>0, |f(z)|\le M,\forall z\in C_r$, da cui:
\begin{equation}
    \left|\int_{C_r^-}G(z)dz \right|=\left| \int_{C_r^-}f(z)(log(z))^2 dz\right|\le \int_{C_r^-}|f(z)||log(z)|^2|dz|\le 2\pi r M [(log(r))^2+(2\pi)^2]\xrightarrow{r\to 0} 0
\end{equation}
Prendendo il limite per R$\to\infty$ si trova che:
\begin{align}
    & \lim_{r\to \infty}\lim_{r\to 0}\oint_\Gamma G(z)dz= \\
    &=\lim_{r\to \infty}\lim_{r\to 0}\left\{ \int_{I_+}+\int_{I_-} \right\}G(z)dz = \\
    &= \int_0^{+\infty}f(x)(logx)^2dx-\int_0^{\infty}f(x)(logx+i2\pi)^2 dx=\\
    &= \int_0^\infty f(x)[(logx)^2-(logx)^2-4\pi i logx + 4\pi^2]dx= \\
    &=4\pi^2\int_0^\infty f(x)dx-4\pi i \int_0^\infty f(x)logx dx
\end{align}
Che per il Th interno dei residui (\ref{11 interno}) è uguale a
\[
2\pi i \sum_{k=1}^N Res[f(z)(logz)^2,z_k]
\]
Prendendo ed eguagliando le parti reali e immaginarie della relazione trovata si ha:


\begin{equation}
\begin{split}
    \int_0^\infty f(x)dx=Re\left\{\frac{i}{2\pi}\sum_1^NRes[f(z)(log(z))^2,z_k]\right\} \\ \int_0^\infty f(x)log(x)dx=Im\left\{-\frac{i}{2}\sum_1^NRes[f(z)(log(z))^2,z_k]\right\}
\end{split}\end{equation}
\newpage

\section{Relazione tra funzioni analitiche e armoniche}
Se $f=u+iv$ è una funzione analitica in un certo dominio $G$, allora $u(x,y), v(x,y)$ sono \textit{funzioni armoniche piane} nello stesso dominio.
\\
Ossia, $\forall (x,y) \in G$:
\begin{equation}
    \begin{split}
        \Delta_2 u\equiv \left( \frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2} \right) u=0 \\
        \Delta_2 v\equiv \left( \frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2} \right) v =0
    \end{split}
\end{equation}

\begin{proof}
Derivando le Condizioni di Cauchy-Riemann (\ref{CR}), $f_x+if_y=0$ rispetto a $x$ e a $y$ si trova (essendo analitica, $f$ è infinitamente differenziabile):

\begin{equation}
\begin{split}
     \left \{ \begin{array}{lr}
         f_{xx}+if_{yx}=0 \ \Rightarrow \ f_{xx}=-if_{yx}=-if_{xy}  \\
         f_{xy}+if_{yy}=0 \ \Rightarrow \ f_{yy}=if_{xy} 
    \end{array}
    \right. \\
    \Rightarrow \ \Delta_2 f \equiv f_{xx}+f_{yy}=-if_{xy}+if_{xy}=0 \ \ \iff \ \ \Delta_2 u = \Delta_2 v =0
\end{split}
\end{equation}

\end{proof}

Le funzioni $u(x,y), v(x,y)$ si dicono anche \textit{armoniche coniugate}, poichè soddisfano l'equazione di Laplace e valgono per esse le condizioni (\ref{CR}):
\begin{equation}
    \left \{ \begin{array}{lr}
         u_x=v_y \\
         u_y=-v_x
    \end{array}
    \right.
\end{equation}

\textbf{Osservazione:} Le \textit{curve di livello} $u(x,y)=cte$ sono ortogonali alle \textit{curve di livello} $v(x,y)=cte$.
\\
\begin{proof}
Per definizione $\nabla u=(u_x,u_y)$ è ortogonale alle curve di livello di $u$ e analogamente per $\nabla v$.
\\
Si osserva che in base alle condizioni (\ref{CR}) vale:
\begin{equation}
   \nabla u \cdot \nabla v =u_x v_x + u_y v_y =0
\end{equation}
\end{proof}

\subsection{Relazione inversa}
Data un funzione armonica $u(x,y)$ in un dominio semplicemente connesso $G$, si può trovare una funzione armonica coniugata $v(x,y)$ tale che $f=u+iv$ sia una funzione analitica in $G$.

\begin{proof}
Si consideri la forma differenziale 
\begin{equation}
    \omega \equiv A(x,y)dx+B(x,y)dy \ \ \ \ \text{con} \ \ \ A\equiv -u_y \ , \ B\equiv u_x
\end{equation}
Osservando che $A_y=-u_{yy}=u_{xx}=B_x$, poichè sono armoniche per ipotesi, si vede che $\omega$ è esatta in $G$.
\\
(una forma differenziale si dice \textit{esatta} se esiste una funzione $f$ differenziabile tale che il suo differenziale coincida con $\omega$, ossia $df=\omega$; \textit{ndr})
\\
Ossia:
\begin{equation}
    \exists v \ \ : \ \ \omega \equiv -u_y dx + u_x dy = dv = v_x dx + v_y dy \ \ \ \Rightarrow \ \ \left \{ \begin{array}{lr}
         u_x=v_y  \\
         u_y=-v_x 
    \end{array}
    \right.
\end{equation}
che sono le condizioni (\ref{CR}) per la funzione $f=u+iv$, che quindi è analitica in $G$.
\\
(Si noti che la $v$ è definita a meno di una costante)

\end{proof}

Questo legame tra funzioni analitiche e armoniche fa in modo che molte proprietà siano a comune tra le due:

\subsection{Formula del Valor Medio}
Data $u(x,y)$ armonica in $G$, allora $\forall (x_0,y_0) \in G$ e $\forall R$ tc la circonferenza $C_R$ sia contenuta in $G$, si ha:
\begin{equation}
    u(x_0,y_0)=\frac{1}{2\pi}\int_{0}^{2\pi}u(x_0 + Rcos\theta , y_0 + Rsin\theta) d\theta
\end{equation}

\begin{proof}
Segue dal fatto che 
\begin{equation}
    \exists f \ \ \text{analitica in $G$ tale che} \ \ u=Re(f)
\end{equation}
Basta applicare la formula del valor medio per $f$:
\begin{equation}
    f(z_0)=\frac{1}{2\pi}\int_0 ^{2\pi} f(z_0+Re^{i\theta})d\theta
\end{equation}
e prendere la parte reali di entrambi i membri.

\end{proof}

\subsection{Il principio del Massimo/Minimo}

Data $u(x,y)$ armonica in $G$ semplicemente connesso e limitato e continua in $\bar{G}$, essa non può avere punti di Max o Min in $G$, a meno che non sia costante su tutto il dominio, ma solo sulla frontiera $\partial G$:
\begin{equation}
    \min_{(x,y)\in \partial G} u(x,y)\le u(x,y) \le \max_{(x,y)\in \partial G} u(x,y) \ \ , \ \ \ \ \forall (x,y) \in G
\end{equation}

\begin{proof}
Segue dal fatto che
\begin{equation}
    \exists f \ \ \text{analitica in $G$ tale che} \ \ u=Re(f)
\end{equation}
e si applica il principio del Max/Min modulo alla funzione analitica 
\begin{equation}
g(z)\equiv e^{f(z)}=e^{u+iv} \ \ \Rightarrow \ \ |g(z)|=e^u
\end{equation}

\end{proof}

\subsection{Le Trasformazioni Conformi}

Data una funzione analitica $f(z)$ in un dominio $G$ con la proprietà $f'(z)\ne 0 \ \ \forall z \in G$, l'applicazione $z\to z'=f(z)$ si dice \textit{Trasformazione Conforme} del dominio $G$ nel dominio $G'=f(G)$.

\begin{figure}[h]
\centering
\includegraphics[scale=0.25]{conforme.png}
\label{fig:conforme}
\caption{Trasformazione conforme}
\end{figure}

\subsubsection{Proprietà geometriche}
Una trasformazione conforme possiede nell'intorno di ogni punto $z_0 \in G$ le proprietà:
\begin{enumerate}
    \item conservazione degli angoli.
    \item costanza delle dilatazioni.
\end{enumerate}
Ossia, l'applicazione $z\to z'=f(z)$ trasforma triangoli infinitamente piccoli con vertice in $z_0$ in triangoli infinitamente piccoli con vertice in $z_0 ' = f(z_0)$.

\begin{proof}
Si consideri la Figura (\ref{fig:conforme}).
\\
I punti $z_1,z_2$, infinitamente vicini a $z_0$ vengono mappati in $z_1'=f(z_1)$ e $z_2'=f(z_2)$ infinitamente vicini a $z_0'=f(z_0)$.
\\
Per definizione di derivata complessa:
\begin{equation}
    f'(z_0)=\frac{\Delta z_1 '}{\Delta z_1}=\frac{\Delta z_2 '}{\Delta z_2}
\end{equation}
Da cui, ponendo
\begin{equation}
    f'(z_0)\equiv k e^{i\alpha} \ \ \ \ ; \ \ \ \ k\equiv |f'(z_0)| \ \ , \ \ \alpha\equiv Arg(f'(z_0))
\end{equation}
si trova:
\begin{equation}
    ke^{i\alpha}=\frac{|\Delta z_1'|}{|\Delta z_1|}e^{i(Arg(\Delta z_1 ')-Arg(\Delta z_1))}=\frac{|\Delta z_2'|}{|\Delta z_2|}e^{i(Arg(\Delta z_2 ')-Arg(\Delta z_2))}
\end{equation}
Da cui si trova:
\begin{equation}
    \frac{|\Delta z_1'|}{|\Delta z_1|}=\frac{|\Delta z_2'|}{|\Delta z_2|}=k
\end{equation}
che è la proprietà di costanza delle dilatazioni. \\
e anche
\begin{equation}
   Arg(\Delta z_1 ')-Arg(\Delta z_1)=Arg(\Delta z_2 ')-Arg(\Delta z_2)=\alpha
\end{equation}
da cui 
\begin{equation}
    Arg(\Delta z_2 ')-Arg(\Delta z_1')=Arg(\Delta z_2)-Arg(\Delta z_1)
\end{equation}
che è la proprietà di conservazione degli angoli.

\end{proof}

\subsection{Trasformazione di M\" \oe bius}

Un esempio di trasformazione conforme è:
\begin{equation}\label{moebius}
    f(z)=\frac{az+b}{cz+d} \ \ \ \ \ \ \ a\ne 0 \ , \ c \ne 0
\end{equation}
$f(z)$ è analitica $\forall z \ne - \frac{d}{c}$. Inoltre:
\begin{equation}
    f'(z)=\frac{a}{cz+d}-\frac{(az+b)c}{(cz+d)^2}=\frac{a(cz+d)-c(az+b)}{(cz+d)^2}=\frac{ad-bc}{(cz+d)^2}
\end{equation}
Da cui si trova la condizione
\begin{equation}
    f'(z)\ne 0 \ \iff \ ad-bc\ne 0
\end{equation}
Da cui si vede che la funzione (\ref{moebius}) con la condizione $ad-bc\ne 0$ è una trasformazione conforme definita nel dominio $G=\mathds{C}/\{ z=-\frac{d}{c}\}$.

\subsection{Th. di Riemann}
\begin{theorem}[\textbf{Th. di Riemann}]\label{Riemann}
$\forall G$ dominio semplicemente connesso del piano complesso $z$, $\exists \ z\to z'=f(z)$ trasformazione conforme che applica $G$ all'interno del cerchio unitario $|z'|<1$.
\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{riemann.png}
\label{fig:riemann}
\end{figure}
\end{theorem}
Tale trasformazione non è univocamente determinata ($g(z)=e^{i\alpha}f(z)$ è la stessa applicazione), ma risulta definita in modo univoco con le condizioni:
\begin{itemize}
    \item $f(z_0)=0$ con $z_0 \in G$.
    \item $arg(f'(z_0))=\alpha_0$ con $\alpha_0 \in \mathds{R}$ assegnato.
\end{itemize}
























\newpage

\section{Funzione di Green per sistemi lineari ed indipendenti dal tempo}
\subsection{Sistemi lineari e funzione di Green}
Si considera un segnale in ingresso $a(t)$, con $t\in\mathds{R}$ variabile tempo, detto segnale di INPUT. Tale segnale interagisce con un sistema fisico, causando un segnale in uscita $b(t)=L[a(t)]$.\\
\begin{definition}
La proprietà di linearità del sistema implica che per 2 segnali di INPUT e OUTPUT,  $b_1(t)=L[a_1(t)],\ b_2(t)=L[a_2(t)]$, si abbia
\begin{equation}
    L[\alpha a_1(t)+\beta a_2(t)]=\alpha L[a_1(t)]+\beta L[a_2(t)]=\alpha b_1(t)+\beta b_2(t) \qquad \forall \alpha,\beta \in \mathds{C}
\end{equation}
\end{definition}
In questo caso si può scrivere che:
\begin{equation} \label{15 Green}
    b(t)=\int_{-\infty}^{+\infty}G(t,t')a(t')dt'
\end{equation}
Dove $G(t,t')$ è detta \textbf{Funzione di Green} del sistema.
\subsection{Indipendenza dal tempo}
Si può richiedere che il sistema sia invariante per traslazioni nella variabile $t$.\\
Questo equivale a chiedere che se l'input è sostituito da $a_\delta(t')\equiv a(t'-\delta)$, allora l'output sarà $b_\delta(t)\equiv b(t-\delta)$, ovvero:
\begin{equation}
    b_\delta(t)=\int_{-\infty}^\infty G(t,t')a_\delta(t')dt'=b(t-\delta)
\end{equation}
Sostituendo $t$ con $t-\delta$ nella (\ref{15 Green}):
\begin{equation}
    b(t-\delta)=\int_{-\infty}^\infty G(t-\delta,\tau)a(\tau)d\tau=\int_{-\infty}^\infty G(t-\delta,t'-\delta)a(t'-\delta)dt'
\end{equation}
Dove si è posto $\tau=t'-\delta$.\\
Comparando le 2 espressioni:
\begin{equation}
    G(t-\delta,t'-\delta)=G(t,t') \forall \delta \in \mathds{R}
\end{equation}
Ponendo $\delta=t'$, si ottiene:
\begin{equation}
    G(t,t')=G(t-t',0)\equiv G(t-t')
\end{equation}
Di conseguenza :
\begin{equation}
    b(t)=\int_{\infty}^\infty G(t-t')a(t')dt'
\end{equation}
Per cui per \textit{sistemi lineari e indipendenti dal tempo} la relazione fra INPUT ed OUTPUT è del tipo:
\begin{equation}\label{15 conv}
    b(t)\equiv (G*a)(t)\equiv \int_{-\infty}^\infty G(t-t')a(t')dt'=\int_{-\infty}^\infty G(\tau)a(t-\tau)d\tau
\end{equation}
Definito come \textbf{Prodotto di convoluzione}.
\subsection{Funzione di Green e trasformata di Fourier}
Si esegue ora l'analisi in frequenza del sistema attraverso la trasformata di Fourier di ambo i membri dell' eq (\ref{15 conv}), si ottiene:
\begin{equation}\label{15 trasf}
    \Tilde{b}(\omega)=\Tilde{G}(\omega)\Tilde{a}(\omega)
\end{equation}
In particolare la legge che esprime la dipendenza di G dalla variabile $\omega$ è detta \textit{legge di dispersione}.
\subsubsection{Delta di Dirac}
Dalla (\ref{15 trasf}) si deduce che, prendendo come INPUT un segnale la cui trasformata di Fourier sia uguale ad 1, si avrebbe un OUTPUT uguale alla funzione di Green del sistema:
\begin{equation}
    \Tilde{a}(\omega)=1 \Longrightarrow \Tilde{b}(\omega)=\Tilde{G}(\omega)\Longrightarrow b(t)=G(t)
\end{equation}
Tuttavia non esiste nessuna funzione, o almeno propriamente detta, la cui trasformata di Fourier sia uguale ad 1.\\
Quello che si può fare è trovare una successione di funzioni le cui trasformate tendano ad 1. Ad esempio:
\begin{equation}\label{15 tau}
    a_\tau(t)=\begin{cases}
    \frac{1}{2\tau} & |t|\le \tau\\
    0 & |t|>\tau
\end{cases}
\end{equation}
Da cui:
\begin{equation}
    \Tilde{a}_\tau(\omega)=\int_{-\infty}^\infty a_\tau(t)e^{i\omega t}dt=\int_{-\tau}^\tau \frac{1}{2\tau}e^{i\omega t}dt=\frac{1}{2\tau}\left.\frac{e^{i\omega t}}{i\omega}\right|_{-\tau}^\tau=\frac{sen(\omega\tau)}{\omega\tau}
\end{equation}
\begin{equation}1
    \Longrightarrow \delta\equiv\lim_{\tau\to 0^+}\Tilde{a}_\tau=1
\end{equation}
Si definisce in questo modo (in maniera euristica) la "funzione" \textit{Delta di Dirac}: non si tratta di una vera funzione poichè:
\begin{equation}
    \delta(t)=\begin{cases}
    0 &  t \ne 0 \\
    \infty & t=0
    \end{cases} \qquad \int_{-\infty}^\infty\delta(t)dt=\lim_{\tau\to 0^+}\int_{-\infty}^\infty a_\tau(t)dt=1
\end{equation}
Inoltre data una funzione $f(x)$ continua nell'intorno del punto $t=0$, si ha:
\begin{equation}
    \int_{-\infty}^\infty\delta(t)f(t)dt=\lim_{\tau\to 0^+}\int_{-\infty}^\infty a_\tau(t)f(t)dt=\lim_{\tau\to 0^+}\frac{1}{2\tau}\int_{-\tau}^\tau f(t)dt=\lim_{\tau\to 0^+}f(\epsilon)=f(0) \quad \epsilon\in[-\tau,\tau]
\end{equation}
La $\delta(t)$ è in realtà una distribuzione come si vedrà più avanti.\\
Dalla relazione:
\begin{equation}
    F(\delta(t))=\lim_{\tau\to 0^+}F(a_\tau(t))=1
\end{equation}
E' possibile quindi interpretare la funzione di Green $G(t)$ di un dato sistema come la risposta, OUTPUT, del sistema ad un INPUT pari alla $\delta(t)$.
\subsection{Appendix: proprietà trasformata di Fourier}
\begin{itemize}
    \item \textbf{Teoremi di traslazione:}
    \begin{equation}
        \mathcal{F}(f(t-a))=e^{i\omega a}\mathcal{F} \qquad \mathcal{F}(e^{-it}f(t))=\Tilde{f}(\omega-a)
    \end{equation}
    \item \textbf{Teoremi di derivazione:}
    \begin{equation}
        \mathcal{F}\left(\frac{d^kf(t)}{dt^k}\right)=(-i\omega)^k\mathcal{F}(f(t)) \qquad \mathcal{F}((it)^kf(t))=\frac{d^k}{d\omega^k}\Tilde{f}(\omega)
    \end{equation}
    \item \textbf{Lemma di Riemann-Lebesgue:}
    \begin{equation}
        \lim_{\omega\to\pm\infty}\Tilde{f}(\omega)=0
    \end{equation}
    \item \textbf{Teorema di convoluzione:}
    \begin{equation}
        \mathcal{F}(f*g)=\Tilde{f}(\omega)\Tilde{g}(\omega)
    \end{equation}
\end{itemize}






\begin{comment}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
buonasera\\
sto cercando supporto morale\\
vedo che hai degli errori con hyperref\\
poi te li sistemo\\
<3\\
TUtto quello che ho fatto stasera è la lezione 11 e riscrivere 6 volte le stesse 2 frasi di Lab\\
tutto quello che ho fatto io è stato aspettare che finiscano le acquisizioni big mood\\
Comunque stiamo costruendo una sedia di quelle ergonomiche\\
?\\
che vuol dire ergonomiche?\\
Quelle con il poggiaginocchia e senza schienale, in modo da stare con la schiena dritta\\
che scomode oddio le avevo provate all'ikea\\
c'è da dire che si fanno bene però ti ci devi abituare e all'inizio a me ha dato noia\\
Eh lo so, ma se no divento il gobbo di notre dame\\
Buonanotte giuliè\\
vado anche io\\
buonanotte\\
\end{comment}
\newpage

\section{Proprietà della Funzione di Green per sistemi lineari causali}

Se con $t$ si indica la variabile temporale, si dice che un sistema lineare, descritto dalla \textit{funzione di Green} $G(t,t')$ è \textit{causale} se il segnale di uscita $b(t)$ non è influenzato dal segnale di ingresso $a(t')$ per $t'>t$, ma dipende da $a(t')$ solo per $t'<t$.
Ossia:
\begin{equation}\label{causa}
    G(t,t')=0 \ \ \ \text{per} \ \ t'>t
\end{equation}
da cui
\begin{equation}
    b(t)=\int_{-\infty}^t G(t,t')a(t')dt'
\end{equation}
E se il sistema è anche indipendente dal tempo, la condizione di causalità (\ref{causa}) diventa:
\begin{equation}
    G(t-t')=0 \ \ \text{per} \ \ t'>t \ \ \ \iff \ \ \ G(\tau)=0 \ \ \text{per} \ \ \tau<0
\end{equation}
e la relazione tra input e output diventa:
\begin{equation}
    b(t)=\int_{-\infty}^t G(t-t')a(t')dt'=\int_0 ^{\infty}G(\tau)a(t-\tau)d\tau
\end{equation}

\begin{theorem}
Sia $G(t)$ una \textit{funzione di Green} causale e a quadrato sommabile $(G(t)\in \mathds{L}^2(0,\infty))$.
\\
Allora la sua trasformata di Fourier:
\begin{equation}
    \chi(\omega)\equiv \Tilde{G}(\omega)=\int_0^{\infty} e^{i\omega t}G(t)dt
\end{equation}
intesa come funzione della variabile complessa $\omega$ è una funzione analitica nel semipiano $Im(\omega)>0$.
\end{theorem}

\begin{proof}
Si considera il rapporto incrementale
\begin{equation}
    \frac{\Delta \chi}{\Delta \omega}=\frac{\chi(\omega + \Delta \omega)-\chi(\omega)}{\Delta \omega}
\end{equation}
ponendo $\varepsilon\equiv \Delta \omega$ e $\omega=\omega' + i \omega''$.
\begin{equation}
    \frac{\chi(\omega+\varepsilon)-\chi(\omega)}{\varepsilon}=\int_0^\infty\frac{e^{i\varepsilon t}-1}{\varepsilon}e^{i\omega t}G(t)dt=\int_0^\infty\left( \frac{e^{i\varepsilon t}-1}{i\varepsilon t} \right)ite^{i\omega' t}e^{-\omega'' t}G(t)dt \equiv \int_0^\infty f_\varepsilon(t)dt
\end{equation}
dove si è posto
\begin{equation}
    f_\varepsilon(t)\equiv \left( \frac{e^{i\varepsilon t}-1}{i\varepsilon t} \right)ite^{i\omega' t}e^{-\omega'' t}G(t)
\end{equation}
Si consideri per un dato $t>0$ la funzione della variabile complessa $\varepsilon$
\begin{equation}
    g(\varepsilon)\equiv \frac{e^{i\varepsilon t}-1}{i\varepsilon t}
\end{equation}

$g(\varepsilon)$ è una funzione intera (ha una singolarità rimovibile in $\varepsilon=0$).
\\
Si considera nel piano complesso $\varepsilon$ il cerchio $|\varepsilon|\le \rho$ in Figura (\ref{cerc}).
\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{fourier.JPG}
\label{cerc}
\end{figure}

Per il principio del massimo modulo (\ref{massimo modulo}) risulta
\begin{equation}
    |g(\varepsilon)|\le \max_{|\varepsilon|=\rho}|g(\varepsilon)| \ \ \ \ \ \ \forall \ \varepsilon \ : \ |\varepsilon|\le \rho
\end{equation}
Considerando perciò la circonferenza $|\varepsilon|=\rho$, ossia parametrizzando come
\begin{equation}
    \varepsilon=\rho e^{i\theta} \ \ \ \ \ \ \ \ \theta \in [0,2\pi]
\end{equation}
si trova
\begin{equation}
    e^{i\varepsilon t}=e^{i\rho t(cos\theta + i sin \theta)}=e^{-\rho t sin \theta}e^{i\rho t cos \theta}
\end{equation}
Da cui è possibile maggiorare il modulo di $g(\varepsilon)$
\begin{equation}
    |g(\rho e^{i\theta})|=\frac{|e^{i\varepsilon t}-1|}{|\varepsilon|t}\le \frac{|e^{i\varepsilon t}|+1}{|\varepsilon|t}=\frac{e^{-\rho t sin \theta}+1}{\rho t}\le \frac{e^{\rho t}+1}{\rho t}
\end{equation}
A questo punto si può maggiorare anche il modulo di $f_\varepsilon(t)$ per $|\varepsilon|\le \rho$, trovando:
\begin{equation*}
    |f_\varepsilon(t)|=|g(\varepsilon)|t e^{-\omega''t}|G(t)|\le \frac{e^{\rho t}+1}{\rho t}t e^{-\omega'' t}|G(t)|=\frac{1}{\rho}e^{-(\omega'' -\rho)t}|G(t)|+\frac{1}{\rho}e^{-\omega'' t}|G(t)|\equiv F(t)
\end{equation*}
Perciò se $\omega''\equiv Im(\omega)>0$, prendendo $\rho < \omega''$ (ad esempio $\rho=\omega''/2$), si trova
\begin{equation}
    \frac{1}{\rho}e^{-\frac{\omega''}{2}t} \ \ , \ \ \ \ \frac{1}{\rho}e^{-\omega'' t} \ \ , \ \ \ \ |G(t)| \ \ \ \ \in \mathds{L}^2(0,+\infty)
\end{equation}
Da cui
\begin{equation}
     \frac{1}{\rho}e^{-\frac{\omega''}{2}t}|G(t)| \ \ , \ \ \ \ \frac{1}{\rho}e^{-\omega'' t}|G(t)| \ \  \in \mathds{L}^1(0,+\infty)
\end{equation}
Perciò
\begin{equation}
    F(t)\equiv \frac{1}{\rho}e^{-(\omega'' -\rho)t}|G(t)|+\frac{1}{\rho}e^{-\omega'' t}|G(t)| \ \ \in \ \mathds{L}^1(0,+\infty)
\end{equation}
A questo punto si applica il Th. della convergenza dominata (di Lebesgue), in base al quale
\begin{equation}
    \exists \ \lim_{\varepsilon\to 0}\int_0^\infty f_\varepsilon(t)\ dt =\int_0^\infty f(t) \ dt
\end{equation}
con 
\begin{equation}
    f(t)=\lim_{\varepsilon\to 0}f_\varepsilon(t)=ite^{i\omega't}e^{-\omega'' t}G(t) \ \ \ (\in \ \mathds{L}^1(0,+\infty))
\end{equation}
In conclusione, se $\omega''\equiv Im(\omega)>0$, allora
\begin{equation*}
    \exists \ \lim_{\varepsilon\to 0}\frac{\chi(\omega+\varepsilon)-\chi (\omega)}{\varepsilon}\equiv \chi'(\omega)
\end{equation*}
Ossia, la funzione $\chi(\omega)$ è analitica nel semipiano complesso susperiore, $Im(\omega)>0$.

\end{proof}


Con un procedimento analogo si può dimostrare il 
\begin{theorem}
Se una funzione $G(t)$ è \textit{a supporto compatto} allora la sua trasformata di Fourier
\begin{equation}
    \chi(\omega)\equiv \Tilde{G}(\omega)=\int_{-\infty}^{\infty} e^{i\omega t}G(t) dt =\int_I e^{i\omega t}G(t)dt
\end{equation}
dove $I$ è il supporto compatto di $G(t)$, come funzione della variabile complessa $\omega$ è una funzione intera.
\end{theorem}

\subsection{Trasformata di Hilbert}
Per un sistema lineare, indipendente dal tempo e causale, la funzione $\chi(\omega)\equiv \Tilde{G}(\omega)$ per $\omega \in \mathds{R}$ si ottiene come \textit{valore al contorno} per $\omega''\equiv Im(\omega)\to 0^+$ di una funzione analitica nel semipiano complesso superiore.
\\
Integrando allora la funzione
\begin{equation}
    \frac{\chi(z)}{z-\omega}
\end{equation}
nella variabile $z$ lungo il $\Gamma$ in Figura (\ref{Gamma}):


\begin{center}
    \begin{tikzpicture} \label{Gamma}
    \draw[thick,->] (-5.5,0) -- (5.5,0) node[anchor=north west] {$Re(z)$};
\draw[thick,->] (0,-1) -- (0,5.5) node[anchor=south east] {$Im(z)$};
    \draw[thick,->] (-1.5,0)--(-1,0);
    \draw[thick,->] (1,0)--(1.5,0);
    \draw (5,0) arc (0:180:5cm);
    \draw[thick,->] (0.1,5)--(-0.3,5);
    \draw (4,0) arc (0:180:1cm);
    \draw[thick,->] (2.9,1)--(3.1,1);
    \filldraw[black] (-5,0)  circle  (1pt);
    \filldraw[black] (-5.25,-0.25) circle (0pt)node[anchor=west] {$-R$};
      \filldraw[black] (5,0)  circle  (1pt);
    \filldraw[black] (4.75,-0.25) circle (0pt)node[anchor=west] {$R$};
    \filldraw[black] (0,0)  circle  (1pt);
     \filldraw[black] (3,0)  circle  (1pt);
    \filldraw[black] (2.75,-0.25) circle (0pt)node[anchor=west] {$\omega$};
    \filldraw[black] (1.7,-0.25) circle (0pt)node[anchor=west] {$\omega-\varepsilon$};
    \filldraw[black] (3.7,-0.25) circle (0pt)node[anchor=west] {$\omega+\varepsilon$};
     \filldraw[black] (-5.5,5.5) circle (0pt)node[anchor=west] {$\Gamma$:};
    \filldraw[black] (3,1.25) circle (0pt)node[anchor=west] {$C_{\varepsilon} ^{'-}$};
    \filldraw[black] (5,1.25) circle (0pt)node[anchor=west] {$C_{R} ^{'+}$};
    \end{tikzpicture}
\end{center}
Si trova applicando il \textit{Th. di Cauchy} (\ref{Cauchy}):
\begin{equation}
    0=\oint_{\Gamma}\frac{\chi(z)}{z-\omega}dz= \left\{ \int_{-R}^{\omega - \varepsilon} + \int_{\omega+\varepsilon}^R \right\} \frac{\chi(\nu)}{\nu - \omega}+\int_{C_{\varepsilon}^{'-}} \frac{\chi(z)}{z-\omega}dz+\int_{C_R^{'+}}\frac{\chi(z)}{z-\omega}dz
\end{equation}
Supponendo che $\chi(z)$ abbia un \textit{buon comportamento all'infinito}, ossia 
\begin{equation}
    \lim_{R\to \infty}\int_{C_R '}\frac{\chi(z)}{z-\omega}dz=0
\end{equation}
si ricava:
\begin{equation} \begin{split}
    \lim_{R\to \infty}\lim_{\varepsilon \to 0^+} \left\{ \int_{-R}^{\omega - \varepsilon} + \int_{\omega + \varepsilon}^R \right\} \frac{\chi(\nu)}{\nu - \omega}d\nu \equiv \mathscr{P}\int_{-\infty}^{\infty} \frac{\chi(\nu)}{\nu-\omega}d\nu=\lim_{\varepsilon\to 0^+}\int_{C_{\varepsilon}^{'+}}\frac{\chi(z)}{z-\omega}dz= \\
    =i\pi Res\left[ \frac{\chi(z)}{z-\omega},z=\omega \right]=i\pi \lim_{z\to \omega}(z-\omega) \frac{\chi(z)}{z-\omega}=i\pi \chi(\omega)
\end{split} \end{equation}
Ossia:
\begin{equation} \label{14.1.5}
    \mathscr{P}\int_{-\infty}^{\infty}\frac{\chi'(\nu)+i\chi''(\nu)}{\nu -\omega}d\nu=i\pi [\chi'(\omega)+i\chi''(\omega)]
\end{equation}
Uguagliando parte reale e immaginaria in (\ref{14.1.5}) si trovano le \textit{relazioni di dispersione}:
\begin{equation}\label{hilbert}
    \begin{array}{lr}
         \chi'(\omega)=\frac{1}{\pi}\mathscr{P}\int_{-\infty}^{\infty}\frac{\chi''(\nu)}{\nu -\omega}d\nu  \\
         & \\
         \chi''(\omega)=-\frac{1}{\pi}\mathscr{P}\int_{-\infty}^{\infty}\frac{\chi'(\nu)}{\nu -\omega}d\nu
    \end{array}
\end{equation}
In matematica si dice che le funzioni in (\ref{hilbert}) sono l'una la \textit{Trasformata di Hilbert} dell'altra.

\subsection{Th. di Titchmarsh}
Un teorema che viene enunciato e non dimostrato è il seguente:
\begin{theorem}[\textbf{Th. di Titchmarsh}]
Dato un sistema lineare e indipendente dal tempo, con funzione di Green $G(t)$, le seguenti proprietà risultano equivalenti:
\begin{itemize}
    \item $G(t)$ è causale e a quadrato sommabile, per cui ammette la trasformata di Fourier $\chi(\omega)=\Tilde{G}(\omega) \in \mathds{L}^2(\mathds{R})$.
    \item $\chi(\omega')\equiv \Tilde{G}(\omega')$ con $\omega \in \mathds{R}$ è a quadrato sommabile ed è il limite per $\omega''\equiv Im(\omega)\to 0^+$ di una funzione $\chi(\omega=\omega'+i\omega'')$ analitica nel semipiano complesso superiore e tale per cui esiste finito
    \begin{equation}
        \sup_{\omega''\to 0}\int_{-\infty}^{\infty}|\chi(\omega'+i\omega'')|^2d\omega' < +\infty
    \end{equation}
    \item Le funzioni $\chi'(\omega)\equiv Re(\chi(\omega))$ e $\chi''(\omega)\equiv Im(\chi(\omega))$, con $\omega \in \mathds{R}$, sono le \textit{Trasformate di Hilbert} l'una dell'altra e sono a quadrato sommabile.
\end{itemize}
\end{theorem}

\textbf{Nota Bene:} La sola analiticità nel semipiano complesso superiore non basta, è necessario il buon andamento all'infinito.

\subsection{Relazioni di Kramers-Kr\"onig}
Nel caso in cui a(t)=E(t), campo elettrico, e b(t)=P(t) polarizzazione di un dielettrico, si ha:
\begin{equation}
    P(t)=(G*E)(t) \qquad G(t),P(t),E(t)\in \mathds{R}
\end{equation}
Di conseguenza:
\begin{equation}
    \Tilde{P}(\omega)=\Tilde{G}(\omega)\Tilde{E}(\omega)\equiv \chi(\omega)\Tilde{E}(\omega) \qquad \chi(\omega)=\int_0^\infty G(t)e^{i\omega t}dt
\end{equation}
Prendendo il complesso coniugato si ottiene:
\begin{equation}
    \chi^*(\omega)=\int_0^\infty G(t)e^{-i\omega t}dt=\chi(-\omega)
\end{equation}
\begin{equation}
     \chi^*(\omega)=\chi'(\omega)-i\chi''(\omega)=\chi'(-\omega)+i\chi''(-\omega) \Longrightarrow \begin{cases}
     \chi'(-\omega)=\chi'(\omega)\\
     \chi''(-\omega)=-\chi''(\omega)\\
     \end{cases}
\end{equation}
Grazie a tali relazioni le \textit{Relazioni di Dispersione} (\ref{hilbert}) possono essere riscritte in una maniera equivalente sotto il nome di \textit{Relazioni di Kramers-Kr\"onig}, ossia:
\begin{equation}
    \left\{ \begin{array}{lr}
         \chi'(\omega)=\frac{2}{\pi}\mathscr{P}\int_0^\infty \frac{\nu}{\nu^2 - \omega}\chi''(\nu)d\nu \\
         & \\
         \chi''(\omega)=-\frac{2}{\pi}\mathscr{P}\int_0^\infty \frac{\omega}{\nu^2 - \omega^2}\chi'(\nu)d\nu
    \end{array} \right.
\end{equation}
\begin{proof}
\begin{align}
    \chi'(\omega)&=\frac{1}{\pi}\mathscr{P}\int_{-\infty}^{\infty}\frac{\chi''(\nu)}{\nu -\omega}d\nu=\frac{1}{\pi}\mathscr{P}\biggl\{\int_{-\infty}^{0}\frac{\chi''(\nu)}{\nu -\omega}d\nu+\int_{0}^{\infty}\frac{\chi''(\nu)}{\nu -\omega}d\nu\biggr\}=\\
    &=\frac{1}{\pi}\mathscr{P}\biggl\{\int_{0}^{\infty}\frac{\chi''(\nu)}{\nu -\omega}d\nu+\int_{0}^{\infty}\frac{\chi''(-\nu')}{-\nu' -\omega}d\nu'\biggr\}=\frac{1}{\pi}\mathscr{P}\biggl\{\int_{0}^{\infty}\frac{\chi''(\nu)}{\nu -\omega}d\nu+\int_{0}^{\infty}\frac{\chi''(\nu')}{\nu'+\omega}d\nu'\biggr\}\\
    &=\frac{2}{\pi}\mathscr{P}\int_0^\infty \frac{\nu}{\nu^2 - \omega}\chi''(\nu)d\nu 
\end{align}
Ed in modo analogo per l'altra relazione.
\end{proof}



\newpage
\section{Distribuzioni}
\begin{definition}
Una distribuzione $T$ è un funzionale lineare continuo che applica uno spazio vettoriale $\mathds{F}$ di funzioni test in $\mathds{C}$:
\begin{equation}
    T:\mathds{F}\to \mathds{C} \qquad T[\phi] \text{ oppure } <T,\phi> \quad \phi \in \mathds{F}
\end{equation}
Tale che:
\begin{equation}
    <T,\alpha\phi_1+\beta\phi_2>=\alpha<T,\phi_1>+\beta<T,\phi_2>
\end{equation}
\end{definition}
Per continuità di intende quella derivata dalla nozione di "convergenza" nello spazio $\mathds{F}$.\\
Ovvero $T$ è continua se:
\begin{equation}
    \phi_n\xrightarrow{\mathds{F}} \ \phi \ \Longrightarrow \ <T,\phi_n> \ \to \ <T,\phi>
\end{equation}
\begin{definition}
L'insieme delle distribuzioni così definita viene indicata con $\mathds{F}'$ ed è detta spazio duale
\end{definition}
Si distinguono 3 classi principali di distribuzioni:
\begin{itemize}
    \item \textbf{Distribuzioni su funzioni infinitamente derivabili (o a supporto compatto)}:\\
    L'insieme delle funzioni test è
    \begin{equation}
        F=C^\infty\equiv\mathcal{E}
    \end{equation}
    La nozione di convergenza significa che:
    \begin{equation}
        \phi_n \xrightarrow{\mathcal{E}} 0 \Longrightarrow
        \frac{d^k\phi_n}{dx^k} \xrightarrow{n\to\infty} 0 \qquad \forall k\in\mathds{N}
    \end{equation}
    uniformemente su ogni $\mathds{K}$ compatto $\subset\mathds{R}$.\\
    L'insieme delle distribuzioni $\epsilon$ si indica con $\mathcal{E}'$.
    \item \textbf{Distribuzioni temperate}:\\
    Insieme delle funzioni test è:
    \begin{equation}
        \mathds{F}=\left\{\phi:\phi\in C^{\infty}, \sup_{x\in\mathds{R}}\left|x^h\frac{d^k\phi}{dx^k}\right|<+\infty, \forall h,k,\in \mathds{N}\right\}\equiv S
    \end{equation}
    Queste funzioni di test si dicono funzioni $C^\infty$ a decrescenza rapida.\\
    Con la nozione di convergenza:
   \begin{equation}
       \phi_n\xrightarrow{S} 0 \Longrightarrow \forall h,k\in\mathds{N}:\ x^h\frac{d^k\phi_n}{dx^k} \xrightarrow{n\to\infty} 0 \text{ uniformemente in }\mathds{R}
   \end{equation}
   L'insieme delle distribuzioni $S$ si indica con $S'$.
   \item \textbf{Distribuzioni di Schwartz:}\\
    Insieme delle funzioni test è:
    \begin{equation}
        \mathds{F}=C_0^\infty=\{\phi:\phi\in C^{\infty} \text{ e a supporto compatto }\}\equiv D
    \end{equation}
   Con la nozione di convergenza si intende che:
    \begin{equation}\begin{split}
       \phi_n \xrightarrow{D} 0 \Longrightarrow \exists \ K \text{ compatto tale che } K_n\equiv supp(\phi_n) \ \subset \mathds{K} \ \forall n \\ \text{ tale che }\forall k\in \mathds{N} \ \  \frac{d^k\phi_n}{dx^k} \xrightarrow{n\to\infty} 0 \text{ uniformemente in }\mathds{K}
   \end{split}\end{equation}
   Dove con \textit{supp} si indica il supporto della funzione. \\
L'insieme delle distribuzioni $D$ si indica con $D'$.
\end{itemize}
Dalle definizioni segue che
\begin{equation}
    D\subset S\subset \mathcal{E}
\end{equation}
e anche:
\begin{equation}
    \phi_n\xrightarrow{D}0\Longrightarrow\phi_n\xrightarrow{S}0\Longrightarrow\phi_n\xrightarrow{\mathcal{E}}0 \qquad \Longrightarrow \mathcal{E}'\subset S'\subset D'
\end{equation}
\subsection{Esempi}
\subsubsection{Distribuzione \texorpdfstring{$T_U$}{Lg}}
La distribuzione associata alla funzione $u(x)$ viene definita come:
\begin{equation}
    \bra{T_u}\ket{\phi}\equiv\int_{-\infty}^\infty u(x)\phi(x)dx
\end{equation}
Dato uno spazio di funzioni test $\phi \in F$ è necessario che $u(x)$ soddisfi certi requisiti affinchè $T_U$ sia ben definita come distribuzione appartenente allo spazio duale $F'$.
\begin{itemize}
    \item ad ogni $u(x)$ che sia localmente sommabile ($u(x)\in \ L^1_{loc}$) è associata una distribuzione di Schwartz $T_u\in D'$, definita come:
    \begin{equation}
        \bra{T_u}\ket{\phi}\equiv\int_{supp(\phi)} u(x)\phi(x)dx
    \end{equation}
    Essendo $supp(\phi)$ il supporto di $\phi(x)\in D$.\\
    L'integrale risulta quindi ben definito e la linearità è ovvia.\\
    Per dimostrare la continuità, si considera una successione $\phi_n\xrightarrow{D}0$ e detto $K$ un insieme compatto tale che $supp(\phi_n)\subset K$ si ha che:
    \begin{equation}
        \left|\bra{T_u}\ket{\phi_n}\right|\equiv\left|\int_{K} u(x)\phi_n(x)dx\right|\le \int_{K} |u(x)||\phi_n(x)|dx\le \max_{x\in K}|\phi_n(x)|\int_k|u(x)|dx\to 0
    \end{equation}
    Tuttavia se $u(x)\in L^1_{loc}$ non è detto che $T_U\in S'$, ad esempio con $u(x)=e^x$ l'integrale non risulta ben definito con funzioni a decrescenza rapida.
    \item per ogni funzione $u(x)$ limitata ($\sup_{x\in\mathds{R}}<\infty$) è associata una distribuzione temperata $T_u\in S'$. Difatti l'integrale nella definizione è ben definito $\forall \phi\in S$ e quindi rappresenta un funzionale lineare e continuo in $S$. Difatti:
    \begin{equation}
        \left|\int_{-\infty}^\infty u(x)\phi(x)dx\right|\le \int_{-\infty}^\infty|u(x)|\phi(x)|dx\le M\int_{-\infty}^\infty|\phi(x)|dx
    \end{equation}
    Con $M=\sup_{x\in\mathds{R}}<\infty$.\\
    Ma:
    \begin{equation}
        \phi(x)\in S\Longrightarrow |\phi(x)|<A, \ x^2|\phi(x)|\le B, \ \forall x\in \mathds{R},\ A>0,B>0
    \end{equation}
    Sommando le disguaglianze si trova che:
    \begin{equation}
        |\phi(x)|\le \frac{C}{1+x^2}\in L^1(\mathds{R})
    \end{equation}
    Per una successione $\phi_n\xrightarrow{S}0$, dato $\epsilon>0$:
    \begin{equation}
        \exists N_\epsilon : |\phi_n(x)|<\epsilon\ \forall n\ge N_\epsilon, \forall x\in\mathds{R} \qquad \exists N'_\epsilon : x^2|\phi_n(x)|<\epsilon\ \forall n\ge N'_\epsilon, \forall x\in\mathds{R}
    \end{equation}
    Per cui
    \begin{equation}
        (1+x^2)|\phi_n(x)|<2\epsilon\ \forall n\ge N''_\epsilon=\max\{N_\epsilon,N'_\epsilon\}, \forall x\in \mathds{R} \Longrightarrow |\phi_n(x)|<\frac{2\epsilon}{1+x^2}\in L^1(\mathds{R})
    \end{equation}
    Si può ottenere
    \begin{equation}
        \left|\bra{T_u}\ket{\phi_n}\right|\le M\int_{-\infty}^\infty|\phi_n(x)|dx=2\pi M\epsilon \to 0
    \end{equation}
    \item Prendendo $u(x)=cte$, oppure $u(x)=sen(x)$, $u(x)=cos(x)$, o ancora $u(x)=\Theta(x)$, si ha $T_u\in S'$.
    \item Si dimostra che in generale che se $u(x) \in L^2(\mathds{R}),$ o $\in L^2(\mathds{R})$ oppure $u(x)=P(x)$ polinomio di $x$ allora $T_U\in S'$
\end{itemize}

\vspace{0.5 cm}

\begin{definition}
Si dice che "$T=0$ in $\Omega$ (aperto) $\subset \mathds{R}$" se $<T,\phi>=0 \ \forall \phi \in \mathcal{F}$ con $supp(\phi) \subset \Omega$.
\\
Detto $\Omega_0=sup(\Omega)$ il più grande di tali inisemi, il suo complementare $\Omega_0 ^c \equiv \mathds{R}/\Omega_0$ viene detto "supporto della distribuzione $T$" e si indica con $Supp(T)\equiv \Omega_0 ^c$.
\\
In particolare
\begin{equation}
    T=T_u \ \Rightarrow \ Supp(T_u)=supp(u)
\end{equation}
\end{definition}

\textbf{Osservazione:} Si dimostra che le distribuzioni $T \in \mathcal{E}'$ sono tutte e sole le Distribuzioni a supporto compatto.
\\
Infatti 
\begin{equation}
    T \in \mathcal{E}' \ \iff \ Supp(T) \text{ è compatto}
\end{equation}
Ma allora in base agli esempi sopra, se $u(x)$ è una costante, una funzione trigonometrica o la $\Theta(x)$, allora $T_u \in S'$, ma $T_u \notin \mathcal{E}'$ (poichè $Supp(T_u)=supp(u)$ non è compatto).

\subsubsection{Distribuzioni non associate a funzioni}
Non tutte le distribuzioni sono associate a una $u(x)$. Per esempio la \textit{distribuzione singolare} Delta (di Dirac).

\begin{definition}
La distribuzione "Delta di Dirac" (con centro in $x_0$), che si indica con $\delta_{x_{0}}$ o $\delta(x-x_0)$, è definita come:
\begin{equation}
    <\delta_{x_{0}},\phi>\equiv \phi(x_{0}) \ \ \ \ \forall \phi \in \mathcal{F}
\end{equation}
\end{definition}
Questo è un funzionale lineare e continuo in $\mathcal{E}'$ (e quindi anche in $S'$ e $D'$).\\
Spesso la $\delta$ viene scritta come:
\begin{equation}
    \int_{-\infty}^{\infty} \delta(x-x_0)\phi(x) dx = \phi(x_0)
\end{equation}
\textbf{Nota Bene} $Supp(\delta_{x_{0}})=\{x_0\}$, è possibile dimostrare che la $\delta_{x_{0}}$ e le sue derivate sono le uniche distribuzioni a supporto puntiforme. 
\subsection{Appendix}
\begin{theorem}
u(x)$\in L^1(\mathds{R})\Longrightarrow T_U$ è una distribuzione temperata.
\end{theorem}
\begin{proof}
Per definizione:
\begin{equation}
    \bra{T_u}\ket{\phi}\equiv\int_{-\infty}^\infty u(x)\phi(x)dx \qquad \forall \phi\in S
\end{equation}
L'integrale esiste poichè $\phi\in$ S e quindi $\sup_{x\in\mathds{R}}|\phi(x)|<\infty$, per cui:
\begin{equation}
    \left|\int_{-\infty}^\infty u(x)\phi(x)dx\right|\le \int_{-\infty}^\infty |u(x)||\phi(x)|dx\le \sup_{x\in\mathds{R}}|\phi(x)|\int_{-\infty}^\infty|u(x)|dx<\infty
\end{equation}
$T_u$ è un funzionale lineare di S in $\mathds{C}$, si dimostra la continuità:
\begin{equation}
    \left|\bra{T_u}\ket{\phi_n}-\bra{T_u}\ket{\phi}\right|=\left|\int_{-\infty}^\infty u(x)(\phi_n(x)-\phi(x))dx\right|\to 0 \quad n\to\infty
\end{equation}
Poichè $\phi_n-\phi\to 0, n\to\infty$ uniformemente in $\mathds{R}$:
\begin{equation}
    \forall \epsilon>0,\ \exists N_\epsilon:\ |\phi_n(x)-\phi(x)| \ \forall n>N_\epsilon,\forall x\in \mathds{R}
\end{equation}
Da cui:
\begin{equation}
    \left|\int_{-\infty}^\infty u(x)(\phi_n(x)-\phi(x))dx\right|\le \int_{-\infty}^\infty|u(x)|dx\equiv \epsilon' \qquad \forall n\ge N_\epsilon
\end{equation}
Per cui $\bra{T_u}\ket{\phi_n}\to\bra{T_u}\ket{\phi}$.
\end{proof}
\vspace{0.8cm}
\begin{theorem}
u(x)$\in L^2(\mathds{R})\Longrightarrow T_U$ è una distribuzione temperata.
\end{theorem}
\begin{proof}
Si ha:
\begin{equation}
        \bra{T_u}\ket{\phi}\equiv\int_{-\infty}^\infty u(x)\phi(x)dx=(u*,\phi)_{L^2}<\infty \qquad \forall \phi\in S
\end{equation}
Poiche $\phi\in S\Longrightarrow\phi \in L^2(\mathds{R})$ ed usando la disuguaglianza di Schwarz $|(u*,\phi)_{L^2}|\le||u||_{L^2}||\phi||_{L^2}<\infty$.\\
Di conseguenza:
\begin{equation}
    \left|\bra{T_u}\ket{\phi_n}-\bra{T_u}\ket{\phi}\right|=\left|\bra{T_u}\ket{\phi_n-\phi}\right|=|(u*,\phi_n-\phi)_{L^2}\le||u||_{L^2}||\phi_n-\phi||_{L^2}\to 0
\end{equation}
Poichè le funzioni $|\phi_n-\phi|^2$ possono essere maggiorate da una funzione sommabile grazie alla decrescenza rapida, quindi applicare il teorema della convergenza dominata di Lebesgue e concludere che:
\begin{equation}
    \phi_n\xrightarrow{S} \phi \Longrightarrow\int_{-\infty}^\infty|\phi_n-\phi|^2dx\to 0
\end{equation}
In altre parole le funzioni $\phi_n(x)$ risultano convergere a $\phi(x)$ anche in senso $L^2(\mathds{R})$
\end{proof}

\newpage

\section{Sulla convergenza debole tra distribuzioni}
Detta $T_n$ una successone di distribuzioni di $F'$, si dice che \textit{$T_n$ converge a $T\in F$ per $n\to \infty$} se:
\begin{equation}
    <T_n,\phi> \to <T,\phi> \ \ \ \ \forall \phi \in F
\end{equation}
Si considerano alcuni casi particolari:
\begin{enumerate}
    \item 
    \rule{\textwidth}{0.7pt}
    Se $u_n(x)$ è una successione di funzioni in $\mathds{L}^2$ convergente a $u(x)$ nel senso della norma $\mathds{L}^2$ o nel senso della convergenza debole in $\mathds{L}^2$, si verifica che
    \begin{equation}
        T_{u_n} \xrightarrow{n \to \infty} T_u \ \ \ \text{in $S'$}
    \end{equation}
    \begin{proof}
    $\phi \in S \ \Rightarrow \ \phi \in \mathds{L}^2$. Allora:
    \begin{equation}
        <T_{u_{n}},\phi>=\int_{-\infty}^{\infty}u_n(x)\phi(x) dx=(u_n ^*,\phi)_{\mathds{L}^2}\xrightarrow{n\to \infty}(u ^*,\phi)_{\mathds{L}^2}=<T_u,\phi> \ \ \forall \phi \in S
    \end{equation}
    Avendo usato la convergenza debole in $\mathds{L}^2$.\\
    Volendo essere più pedanti si può usare la convergenza in norma $\mathds{L}^2$ per mostrarlo:
    \begin{equation}\begin{split}
        |<T_{u_{n}},\phi>-<T_u,\phi>|=|<T_{u_{n}}-T_u,\phi>|=\left|\int_{-\infty}^{\infty} (u_n(x)-u(x))\phi(x) dx \right|= \\
        =|(u_n ^* - u^*,\phi)|_{\mathds{L}^2}\ \le \ || u_n ^* - u^*||_{\mathds{L}^2} ||\phi||_{\mathds{L}^2} \xrightarrow{n\to \infty} 0 \ \ \forall \phi \in S
   \end{split} \end{equation}
   Dove si è fatto uso della disuguaglianza di Schwartz.\\
    \end{proof}
    \item
     \rule{\textwidth}{0.7pt}
     Se $u_n(x)$ è una successione di funzioni in $\mathds{L}^1$ e $u_n(x)\xrightarrow{n\to \infty}u(x)$ puntualmente quasi ovunque ed è soddisfatta la \textit{condizione di convergenza dominata} di Lebesgue:
     \begin{equation}
         |u_n(x)|\le F(x) \ \in \mathds{L}^1 \ \ \forall n
     \end{equation}
    allora si ha:
    \begin{equation}
        T_{u_{n}} \xrightarrow{n\to \infty} T_u \ \ \text{in} \ S'
    \end{equation}
     \begin{proof}
     Si ha:
     \begin{equation}
         <T_{u_{n}},\phi>=\int_{-\infty}^{\infty}u_n(x)\phi(x) dx =\int_{-\infty}^{\infty}f_n(x) dx 
     \end{equation}
     dove 
     \begin{equation}
         f_n(x)=u_n(x)\phi(x)\ (\in \mathds{L}^1) \ \xrightarrow{n\to \infty} \ f(x)=u(x)\phi(x) \ \ [q.o.]
     \end{equation}
     e inoltre risulta:
     \begin{equation}
         |f_n(x)|=|u_n(x)||\phi(x)| \ \le \ \sup_{x\in\mathds{R}}|\phi(x)|F(x) \ \in \mathds{L}^1
     \end{equation}
     Da cui è possibile applicare il teorema di Lebesgue:
     \begin{equation}
         \begin{split}
             \lim_{n\to \infty} <T_{u_{n}},\phi> =\lim_{n\to \infty}\int_{-\infty}^{\infty}f_n(x)dx=\int_{-\infty}^{\infty}\lim_{n\to \infty}f_n(x) dx= \\
             =\int_{-\infty}^{\infty}f(x)dx=\int_{-\infty}^{\infty}u(x)\phi(x)dx=<T_u,\phi> \ \ \ \forall \phi \in S
         \end{split}
     \end{equation}
     
     \end{proof}
     
     \item
      \rule{\textwidth}{0.7pt}
     Se $u_n(x)$ è una successione di funzioni limitate ($|u_n(x)|\le M$) che convergono puntualmente a $u(x)$, allora si ha:
     \begin{equation}
         T_{u_n}\xrightarrow{n \to \infty} T_u \ \ \text{in} \ S'
     \end{equation}
     \begin{proof}
     Infatti
     \begin{equation}
         <T_{u_{n}},\phi>=\int_{-\infty}^{\infty}u_n(x)\phi(x)dx=\int_{-\infty}^{\infty} f_n(x)dx
     \end{equation}
     con
     \begin{equation}
         f_n(x)=u_n(x)\phi(x) \in \mathds{L}^1 \ \ \ ; \ \ \ |f_n(x)|\le M |\phi(x)| \equiv F(x) \in \mathds{L}^1
     \end{equation}
     da cui, applicando il Th. di Lebesgue:
     \begin{equation}
         \lim_{n\to \infty}<T_{u_{n}},\phi>=\int_{-\infty}^{\infty} u(x)\phi(x)dx=<T_u,\phi> \ \ \ \forall \phi \in S
     \end{equation}
     
     \end{proof}
     
     \item
      \rule{\textwidth}{0.7pt}
     In tutti gli esempi precedenti si è considerato successioni di distribuzioni associate a funzioni $u_n$ che convergessero debolmente a distribuzioni associate alla funzione $u$.
     \\
     Si considera ora il caso di una successione di distribuzioni $T_{u_{n}}$ che converge ad una distribuzione $T$ non associata ad una funzione.
     \\
     Si verifica ad esempio che 
     \begin{equation}
         T_{f_{\tau,a}}\xrightarrow{\mathcal{E}'}\delta_a
     \end{equation}
     dove $f_{\tau,a}$ è la funzione a gradino:
     \begin{equation}
         f_{\tau,a}\equiv \left\{ \begin{array}{lr}
              1/2\tau \ \ \text{per} \ |x-a|\le \tau  \\
              0 \ \ \text{per} \ |x-a|>\tau
         \end{array}
         \right.
     \end{equation}
     (si noti che $Supp(T_{f_{\tau,a}})=Supp(f_{\tau,a})=[-\tau,\tau]$
     \\
     Allora si ha:
     \begin{equation}\begin{split}
         <T_{f_{\tau,a}},\phi>=\int_{-\infty}^{\infty} f_{\tau,a}(x)\phi(x)dx =\frac{1}{2\tau}\int_{a-\tau}^{a+\tau}\phi(x)dx= \\ =\frac{1}{2\tau}2\tau \phi(\overline{x}_{\tau}\in [a-\tau,a+\tau]) \xrightarrow{\tau \to 0^+}\phi(a)=<\delta_a,\phi> \ \ \ \forall \phi \in \mathcal{E}\equiv C^{\infty}
    \end{split} \end{equation}
     Ossia 
     \begin{equation}
         T_{f_{\tau,a}}\xrightarrow{\mathcal{E}'}\delta_a
     \end{equation}
     Altri esempi di successioni di distribuzioni che tendono alla distribuzione $\delta$ sono ad esempio le $T_{u_k}$ con u(x):
     \begin{equation}
         u_n(x)=\frac{1}{\pi}\frac{n}{1+n^2x^2} \quad \quad u_n(x)=\frac{n}{\sqrt{\pi}}e^{-n^2x^2} \quad 
         u_n(x)=\frac{sen(nx)}{\pi x} \quad n\to\infty
     \end{equation}
     Oppure equivalentemente:
     \begin{equation}
         u_\epsilon(x)=\frac{1}{\pi}\frac{\epsilon}{x^2+\epsilon^2} \qquad \qquad u_\epsilon(x)=\frac{1}{\epsilon\sqrt{\pi}}e^{-\frac{x^2}{\epsilon^2}} \quad \epsilon\to 0^+
     \end{equation}
\end{enumerate}

Si verifica infatti
\begin{itemize}
    \item Per
    \begin{equation}
        u_n(x)=\frac{1}{\pi}\frac{n}{1+n^2x^2}
    \end{equation}
    risulta
    \begin{equation}
        <T_{u_n},\phi>=\frac{1}{\pi}\int_{-\infty}^\infty \frac{n}{1+n^2x^2}\phi(x)dx=\frac{1}{\pi}\int_{-\infty}^\infty \frac{1}{1+y^2}\phi\left(\frac{y}{n}\right)dy
    \end{equation}
    A questo punto si vede che
    \begin{equation*}
        \lim_{n\to \infty}\frac{1}{1+y^2}\phi\left(\frac{y}{n}\right)=\frac{1}{1+y^2}\phi(0) 
    \end{equation*}
    Ed inoltre
    \begin{equation}
        \left| \frac{1}{1+y^2}\phi\left( \frac{y}{n}\right) \right|=\frac{1}{1+y^2}\left| \phi\left(\frac{y}{n} \right) \right|\le \sup_{x\in \mathds{R}}|\phi(x)|\frac{1}{1+y^2}\equiv F(y)
    \end{equation}
    E $F(y)\in \mathds{L}^1(\mathds{R})$.
    \\
    Perciò si può applicare il Th. di Lebesgue:
   \begin{align}
            \lim_{n\to \infty}<T_{u_n},\phi>&=\lim_{n\to \infty}\frac{1}{\pi}\int_{-\infty}^\infty\frac{1}{1+y^2}\phi\left( \frac{y}{n}\right)dy=   \frac{1}{\pi}\int_{-\infty}^\infty \lim_{n\to\infty} \frac{1}{1+y^2}\phi\left(\frac{y}{n}\right)dy\\&=\frac{\phi(0)}{\pi}\int_{-\infty}^\infty \frac{dy}{1+y^2}=\frac{\phi(0)}{\pi}\pi=\phi(0)=<\delta_0,\phi>
    \end{align}
    Da cui, in conclusione:
    \begin{equation}
     \lim_{n\to\infty}T_{u_n}=\delta_0   
    \end{equation}
    Passaggi analoghi portano a dimostrare la versione con $\varepsilon \in \mathds{R}$, con $\varepsilon\to0^+$.
    
    \item Per 
    \begin{equation}
        u_n(x)=\frac{n}{\sqrt{\pi}}e^{-n^2x^2}
    \end{equation}
    si procede come prima.
    \begin{equation}
        <T_{u_n},\phi>=\frac{n}{\sqrt{\pi}}\int_{-\infty}^\infty e^{-n^2x^2}\phi(x)dx=\frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty e^{-y^2}\phi\left( \frac{y}{n} \right)dy
    \end{equation}
    Da cui
    \begin{equation}
        \left| e^{-y^2}\phi\left(\frac{y}{n}\right) \right|\le \left|\phi\left(\frac{y}{n}\right)\right|\le \sup_{x\in\mathds{R}}|\phi(x)|\in \mathds{L}^1(\mathds{R})
    \end{equation}
    Per cui è possibile applicare la convergenza dominata e trovare
    \begin{equation*}
        \lim_{n\to\infty}\frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty e^{-y^2}\phi\left( \frac{y}{n} \right)dy=\frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty \lim_{n\to \infty} e^{-y^2}\phi\left( \frac{y}{n} \right)dy=\frac{\phi(0)}{\sqrt{\pi}}\int_{-\infty}^\infty e^{-y^2}dy=\phi(0)
    \end{equation*}
    Da cui
    \begin{equation}
        \lim_{n\to \infty}T_{u_n}=\delta_0
    \end{equation}
    
    
    
    
    
\end{itemize}

\subsection{Derivata delle distribuzioni}
Per definire la derivata ($DT$) di una distribuzione $T$ si parte dalla richiesta che se $T_u$ è una distribuzione associata alla funzione $u(x)$ derivabile, allora (ponendo $DT_u\equiv T_u')$
\begin{equation*}
    <DT_u,\phi>\equiv <T_u',\phi>=\int_{-\infty}^{\infty}u'(x)\phi(x)dx=u(x)\phi(x)\left. \right|_{-\infty}^{\infty}-\int_{\infty}^{\infty}u(x)\phi'(x)dx=-<T_u,\phi'> \ \ \forall \phi \in \mathcal{F}
\end{equation*}
Avendo usato che 
\begin{equation}
    \lim_{x\to \pm \infty}u(x)\phi(x)=0
\end{equation}
come segue dalla richiesta che $T_u$ sia ben definita.
\\
In generale:
\begin{definition}
si definisce la \textit{Derivata di una distribuzione} come
\begin{equation}\label{derivabilità}
    <DT,\phi>\equiv - <T,\phi'> \ \ \ \ \forall \phi \in \mathcal{F}
\end{equation}
\end{definition}
Ne segue che ogni distribuzione è infitamente derivabile:
\begin{equation}
    <D^k T,\phi>\equiv (-1)^k <T,D^k \phi> \ \ \ \ \forall \phi \in \mathcal{F}
\end{equation}
In quanto le funzioni di test sono $C^\infty$.

\subsubsection{Derivata di \texorpdfstring{$\Theta(x)$}{Lg}}
La funzione a scalino ($\Theta(x)$) non è derivabile in $x=0$, ma la distribuzione associata $T_{\Theta}\in S'$ è derivabile e usando la \ref{derivabilità}:
\begin{align}
    <DT_{\Theta},\phi>&=-<T_{\Theta},\phi'>\equiv - \int_{-\infty}^{\infty}\Theta(x)\phi'(x)dx=-\int_0^{\infty}\phi'(x)dx=\\&=-[\phi(\infty)-\phi(0)]=\phi(0)=<\delta_0,\phi> \ \ \ \forall \phi \in S
\end{align}
Questo implica:
\begin{equation}
    DT_{\Theta}=\delta_0
\end{equation}

\subsubsection{Derivate della \texorpdfstring{$\delta$}{Lg}}
Anche la $\delta_{x_{0}}$ è derivabile e dalla definizione segue:
\begin{equation}
    <D^k \delta_{x_{0}},\phi>\equiv (-1)^k <\delta_{x_{0}},\phi^{(k)}>=(-1)^k\phi^{(k)}(x_0) \ \ \ \ \forall \phi \in \mathcal{E}
\end{equation}

\subsubsection{Esempio sulle derivate di distribuzioni}
Si consideri $T_u$ con $u$ derivabile $\forall x$ tranne che in $x_0$, dove
\begin{equation*}
    \exists\ \sigma=\lim_{x\to x_0^+}u(x)-\lim_{x\to x_0^-}u(x) \ \ \ , \ \ |\sigma|<+\infty
\end{equation*}
Ossia $u(x)$ ha in $x_0$ una discontinuità finita.
\\
Risulta allora
\begin{align}
        <DT_u,\phi>&=-\int_{-\infty}^\infty u(x)\phi'(x)dx
        =-\int_{-\infty}^{x_0}u(x)\phi'(x)dx-\int_{x_0}^\infty u(x)\phi'(x)dx  =\\    &=-\lim_{\varepsilon\to0^+}\lim_{R\to\infty} \int_{-R}^{x_0-\varepsilon}u(x)\phi'(x)dx-\lim_{\varepsilon'\to0^+}\lim_{R'\to\infty}\int_{x_0+\varepsilon'}^{R'}u(x)\phi'(x)dx=\\
        &=-\lim_{\varepsilon\to0^+}\lim_{R\to\infty} \left[ u(x)\phi(x)\left. \right|_{-R}^{x_0-\varepsilon}-\int_{-R}^{x_0-\varepsilon}u'(x)\phi(x)dx \right] -\\& \ \ \  -\lim_{\varepsilon'\to0^+}\lim_{R'\to\infty} \left[ u(x)\phi(x)\left. \right|_{x_0+\varepsilon'}^{R'}-\int_{x_0+\varepsilon'}^{R'}u'(x)\phi(x)dx \right]=\\
        &=(u(x_0^+)-u(x_0^-))\phi(x_0)+\lim_{\varepsilon'\to0^+}\lim_{\varepsilon\to0^-}\left\{\int_{-\infty}^{x_0-\varepsilon} +\int_{x_0+\varepsilon'}^{\infty}\right\}u'(x)\phi(x)dx=\\
        &=\sigma\phi(x_0)+<T_{\{u'\}},\phi>=\sigma<\delta_{x_0},\phi>+<T_{\{u\}},\phi>=<\sigma \delta_{x_0}+T_{\{u'\}},\phi>
\end{align}
Da cui perciò
\begin{equation}
    DT_u=\sigma \delta_{x_0}+T_{\{ u'\}}
\end{equation}

\subsubsection{Altro esempio sulle derivate di distribuzioni}
Si consideri la successione di distribuzioni associate alle funzioni
\begin{equation}
    g_n(x)\equiv \frac{\int_{-\infty}^{nx}h(t')dt'}{\int_{-\infty}^{\infty}h(t)dt}=\frac{n\int_{-\infty}^{x}h(nt)dt}{\int_{-\infty}^{\infty}h(t)dt}
\end{equation}
con $h(x)$ funzione continua e integrabile, con 
\begin{equation}
    \int_{-\infty}^{\infty}h(x)dx \ne 0
\end{equation}

Si verifica che $g_n(x) \xrightarrow{n\to \infty}\theta(x)$ o, nel senso delle distribuzioni:
\begin{equation}\label{theta}
    T_{g_{n}}\xrightarrow{n\to \infty}T_{\theta}
\end{equation}

E si verifica anche che l'operatore di derivazione $D$ sulle distribuzioni è un operatore continuo. Ossia vale il seguente:

\begin{theorem}[\textbf{Di continuità dell'operatore $D$}]\label{continuità derivata}
\begin{equation}
    T_n\to T\Longrightarrow  D^k T_n \to D^k T
\end{equation}
\end{theorem}

\begin{proof}
Si ha infatti:
\begin{equation}
    <DT_n,\phi>\equiv -<T_n,\phi'> \xrightarrow{n\to \infty}-<T,\phi'> \equiv <DT,\phi> \ \ \ \forall \phi \in \mathcal{F} \ \ \Rightarrow \ \ DT_n \xrightarrow{\mathcal{F}'}DT
\end{equation}

\end{proof}

Si può a questo punto riconsiderare la (\ref{theta}) e applicare il (\ref{continuità derivata}), trovando:
\begin{equation}
    DT_{g_{n}}\to DT_{\theta}=\delta_0
\end{equation}
E si vede che, essendo $h(x)$ continua:
\begin{equation}
    g_n '(x)=\frac{nh(nx)}{\int_{-\infty}^{\infty}h(t)dt}\equiv u_n(x) \ \Rightarrow \ DT_{g_{n}} \equiv T_{g_{n}'}=T_{u_{n}} \xrightarrow{n \to \infty} \delta_0
\end{equation}

\newpage
\section{Trasformata di Fourier delle distribuzioni temperate}

Analogamente alla costruzione fatta per definire la derivata di una distribuzione, si prova a definire la \textit{trasformata di Fourier $\mathcal{F}(t)$ di una distribuzione $T$}, partendo dalla richiesta che se $u(x)$ è Fourier-trasformabile, allora $\mathcal{F}(T_u)\equiv T_{\mathcal{F}(u)}$. Ossia:
\begin{equation}\label{Fourier}
    \begin{split}
        <\mathcal{F}(T_u),\phi>\equiv <T_{\mathcal{F}(u)},\phi>=\int_{-\infty}^{\infty} \Tilde{u}(\alpha)\phi(\alpha)d\alpha=\int_{-\infty}^{\infty}d\alpha \phi(\alpha)\left( \int_{-\infty} ^{\infty} u(x)e^{i\alpha x} dx \right)= \\
        = \int_{-\infty}^{\infty}dx u(x)\left( \int_{-\infty}^{\infty} d\alpha \phi(\alpha)e^{i\alpha x} \right)=\int_{-\infty}^{\infty}dx u(x) \Tilde{\phi}(x)=<T_u, \mathcal{F}(\phi)> \ \ \ \forall \phi
    \end{split}
\end{equation}

Ma perchè questa definizione sia valida $\mathcal{F}(\phi)$ deve appartenere allo stesso spazio di funzioni test a cui appartiene $\phi$.
\\
Questo non è generalmente verificato per le distribuzioni di Schwartz $D'$. Infatti dal momento che $\phi \in D$ ha supporto compatto, $\mathcal{F}(\phi)(\omega)$ è una funzione intera in $\omega$, quindi ha al più degli zeri isolati e non può avere quindi un supporto compatto.
\\
Si può invece definire la trasformata di Fourier di una distribuzione temperata $T\in S'$, dal momento che vale il:
\begin{lemma}
$\mathcal{F}$ e $\mathcal{F}^{-1}$ sono operatori lineari che mappano lo spazio delle funzioni test temperate $S$ in se stesso.
\end{lemma}
Inoltre sono operatori continui rispetto alla convergenza introdotta in S.\\
%Se u$\in L^1(\mathds{R})$, quindi $T_U\in S$ allora $\mathcal{F}$(u) è limitata , per cui $T_{\mathcal{F}(u)}\in S'$
Da cui, generalizzando la (\ref{Fourier}) si trova:
\begin{definition}
    \begin{equation}
        <\mathcal{F}(T),\phi>\equiv <T,\mathcal{F}(\phi)> \ \ \ \forall \phi \in S
    \end{equation}
    \begin{equation}
        <\mathcal{F}^{-1}(T),\phi>\equiv <T,\mathcal{F}^{-1}(\phi)> \ \ \ \forall \phi \in S
    \end{equation}

\end{definition}

Segue immediatamente che
\begin{equation}
    \mathcal{F}(\delta_{x_{0}})=T_{e^{i\omega x_0}}
\end{equation}
\subsection{Esempi}


Si dimostra che 
\begin{equation}
    \mathcal{F}(e^{-iax})=2\pi \delta(\omega -a)
\end{equation}
Ossia dal punto di vista delle distribuzioni
\begin{equation}
    \mathcal{F}(T_{e^{-iax}})=2\pi \delta_a
\end{equation}

Infatti risulta:
\begin{equation}\begin{split}
    <\mathcal{F}(T_{e^{-iax}}),\phi>=<T_{e^{-iax}},\mathcal{F}(\phi)>= \\
    =\int_{-\infty}^{\infty}dx e^{-iax}\Tilde{\phi}(x)=2\pi \phi(a)=2\pi <\delta_a,\phi> \ \ \ \forall \phi \in S \\
    \Rightarrow \ \ \mathcal{F}(T_{e^{-iax}})=2\pi \delta_a
\end{split}\end{equation}
In cui si è utilizzata la \textit{rappresentazione di Fourier della $\delta$}:
\begin{equation}
    \delta(t)= \frac{1}{2\pi} \int_{-\infty}^\infty e^{-i\omega t}d\omega
\end{equation}

Si dimostra che 
\begin{equation}
    \mathcal{F}^{-1}(e^{ib\omega})=\delta(x-b)
\end{equation}
Ossia dal punto di vista delle distribuzioni
\begin{equation}
    \mathcal{F}^{-1}(T_{e^{ib\omega}})=\delta_b
\end{equation}
Infatti risulta:
\begin{equation}
    \begin{split}
        <\mathcal{F}^{-1}(T_{e^{ib\omega}}),\phi>=<T_{e^{ib\omega}},\mathcal{F}^{-1}(\phi)>= \\
        =\int_{-\infty}^{\infty}dx e^{ibx}\mathcal{F}^{-1}(\phi)(x)=\phi(b)=<\delta_b,\phi> \ \ \ \forall \phi \in S \\
        \Rightarrow \ \ \mathcal{F}^{-1}(T_{e^{ib\omega}})=\delta_b
    \end{split}
\end{equation}
\subsection{Continuità degli operatori}
\begin{theorem}
$\mathcal{F}$ e $\mathcal{F}^{-1}$ sono operatori continui in $S'$, cioè:
\begin{equation}
    T_n \xrightarrow{S'}T \ \Rightarrow \ \mathcal{F}(T_n) \xrightarrow{S'}\mathcal{F}(T) \ \ \ \text{e} \ \ \ \mathcal{F}^{-1}(T_n) \xrightarrow{S'}\mathcal{F}^{-1}(T)
\end{equation}
\end{theorem}

\begin{proof}
Segue dalla definizione di convergenza debole e di trasformata di una distribuzione.
\begin{equation}
    T_n \xrightarrow{S'}T \ \iff \ <T_n,\phi> \to <T,\phi> \ \ \forall \phi \in S
\end{equation}
Per cui è 
\begin{equation}
   <\mathcal{F}(T_n),\phi>\equiv <T_n,\mathcal{F}(\phi)> \to <T,\mathcal{F}(\phi)>\equiv <\mathcal{F}(T),\phi> \ \ \ \forall \phi \in S
\end{equation}
Ossia
\begin{equation}
    \mathcal{F}(T_n) \xrightarrow{S'}\mathcal{F}(T)
\end{equation}
E stesso procedimento per l'antitrasformata.

\end{proof}

\textbf{Esempio Importante:}
Si è visto che $\mathcal{F}(\delta_{x_0})=T_{e^{i\omega x_0}}$ e in particolare che $\mathcal{F}(\delta(x))=1$.
\\
Un altro modo per ricavare questo risultato è considerare le distribuzioni $T_{f_{\tau}}$ associate alle funzioni a gradino (\ref{15 tau}), ricordando che 
\begin{equation}
    \mathcal{F}(T_{f_{\tau}})\equiv T_{\Tilde{f}_{\tau}} \xrightarrow[\mathcal{E}']{\tau \to 0}\mathcal{F}(\delta_0)
\end{equation}
Ma risulta che
\begin{equation}
    \Tilde{f}_{\tau}(\omega)=\frac{sin(\omega \tau)}{\omega \tau} \xrightarrow{\tau \to 0^+} 1 \ \Rightarrow \ \mathcal{F}(\delta_0)=\lim_{\tau \to 0^+}T_{\Tilde{f}_{\tau}}=T_1
\end{equation}

\subsection{La distribuzione "Parte Principale"}
La funzione $u(x)=1/x$ non ammette una distribuzione associata ben definita.
\\
\'E invece ben definita come \textit{distribuzione temperata} ($S$'), la seguente distribuzione, nota come \textit{parte principale}:
\begin{equation}\label{P}
    <\mathscr{P}\frac{1}{x},\phi>\equiv \mathscr{P}\int_{-\infty}^{\infty}\frac{\phi(x)}{x}dx \equiv \lim_{R\to \infty} \lim_{\epsilon \to 0^+}\left\{ \int_{-R}^{\epsilon} + \int_{\epsilon}^{R} \right\} \frac{\phi(x)}{x}dx \ \ \ \forall \phi \in S
\end{equation}

Si può verificare che questa espressione è ben definita.
\\
Per $a$ fissato e arbitrario $\epsilon<a<R$ si trova:
\begin{equation}
    \begin{split}
        \mathscr{P}\int_{-\infty}^{\infty} \frac{\phi(x)}{x}dx \equiv \lim_{R\to \infty} \lim_{\epsilon \to 0^+}\left\{ \int_{-R}^{-\epsilon} + \int_{\epsilon}^{R} \right\}\frac{\phi(x)}{x}dx= \\
        = \lim_{R\to \infty} \lim_{\epsilon \to 0^+}\left\{ \int_{-R}^{-a} + \int_{-a}^{-\epsilon} + \int_{\epsilon}^a +\int_a ^R \right\}\frac{\phi(x)}{x}dx = \\
        = \lim_{R\to \infty}\left\{ \int_{-R}^{-a} + \int_a ^R \right\}\frac{\phi(x)}{x}dx + \lim_{\epsilon \to 0^+}\left\{ \int_{-a}^{-\epsilon} + \int_{\epsilon}^a \right\}\frac{\phi(x)}{x}dx
    \end{split}
\end{equation}
Il limite a infinito esiste sicuramente per la proprietà di decrescenza rapida della $\phi$.
\\
Nel secondo invece si opera come segue:
\begin{equation}
    \psi(x) \equiv \frac{\phi(x)-\phi(0)}{x} \ \ \ \Rightarrow \ \ \ \exists \ \lim_{x\to 0}\psi(x)=\phi ' (0)
\end{equation}
Da cui si ricava che $\psi(x)$ è continua e si può allora riscrivere:
\begin{equation}
   \begin{split}
    \lim_{\epsilon \to 0^+}\left\{ \int_{-a}^{-\epsilon} + \int_{\epsilon}^a \right\}\frac{\phi(x)}{x}dx=\lim_{\epsilon \to 0^+}\left\{ \int_{-a}^{-\epsilon} + \int_{\epsilon}^a \right\}\frac{\phi(0)+x\psi(x)}{x}dx=\\
    =\lim_{\epsilon \to 0^+}\left\{ \int_{-a}^{-\epsilon} + \int_{\epsilon}^a \right \}\frac{\phi(0)}{x}dx + \lim_{\epsilon \to 0^+}\left\{ \int_{-a}^{-\epsilon} + \int_{\epsilon}^a \right\} \psi(x)dx=\int_{-\infty}^{\infty}\psi(x)dx < \infty
    \end{split}
\end{equation}
Dove si è usato il fatto che l'integrale contenente $\phi(0)$ è un integrale dispari su un dominio pari.


\textbf{Nota:} La (\ref{P}) può essere riscritta:
\begin{equation}\label{P2}
    <\mathscr{P}\frac{1}{x},\phi>\equiv \lim_{R\to\infty}\lim_{\epsilon \to 0^+}<T_{u_{\epsilon,R}},\phi> \ \ \ \forall \phi \in S
\end{equation}
Dove $T_{u_{\epsilon,R}}$ è la distribuzione associata alla funzione:
\begin{equation}
    u_{\epsilon,R}(x)\equiv
    \left\{ \begin{array}{lr}
         0 \ \ \text{per} \ |x|<\epsilon \ |x|>R  \\
        \frac{1}{x} \ \ \text{per} \ \epsilon<|x|<R
    \end{array}
    \right.
\end{equation}
$u_{\epsilon,R} \in \mathds{L}^1$ per cui è Fourier-trasformabile e la trasformata appartiene a $S'$.
\\
Dal momento che il doppio limite in (\ref{P2}) esiste finito, si trova che la successione $T_{u_{\epsilon,R}} \in S'$ è debolmente convergente in $S'$. Dal momento che $S'$ è completo, ne risulta che la distribuzione parte principale è temperata.
\\
Se ne può allora calcolare la Trasformata di Fourier 
\begin{equation}
    \mathcal{F}\left(\mathscr{P}\frac{1}{x}\right)=\lim_{R\to\infty}\lim_{\epsilon \to 0^+}\mathcal{F}\left(T_{u_{\epsilon,R}}\right)=\lim_{R\to\infty}\lim_{\epsilon \to 0^+}T_{\mathcal{F}(u_{\epsilon,R})}
\end{equation}
Per calcolare la trasformata si applica il Lemma di Jordan (\ref{Air Jordan}) calcolando l'integrale sul contorno in Figura (\ref{segno}):
\begin{equation}\begin{split}
    \lim_{R\to\infty}\lim_{\epsilon \to 0^+}\mathcal{F}(u_{\epsilon,R})=\lim_{R\to\infty}\lim_{\epsilon \to 0^+}\left\{ \int_{-R}^{-\epsilon} + \int_{\epsilon}^R \right\}\frac{e^{i\omega x}}{x}dx = \\
    = \left\{ \begin{array}{lr}
         i\pi Res\left[\frac{e^{i\omega z}}{z},z=0 \right]=i\pi \ \ \text{per} \ \omega >0  \\
          -i\pi Res\left[\frac{e^{i\omega z}}{z},z=0 \right]=-i\pi \ \ \text{per} \ \omega <0
    \end{array} \right.
\end{split}\end{equation}
\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{segno.JPG}
\label{segno}
\end{figure}
Da cui riassumendo:
\begin{equation}
    \lim_{R\to \infty}\mathcal{F}(u_{\epsilon,R})=i\pi \varepsilon(\omega)
\end{equation}
dove $\varepsilon(\omega)$ è la funzione segno
\begin{equation}
    \varepsilon(\omega)\equiv \left\{ \begin{array}{lr}
         +1 \ \ \text{per} \ \omega>0  \\
         -1 \ \ \text{per} \ \omega<0  
    \end{array} \right.
\end{equation}
Da cui in ultima istanza si può scrivere quanto trovato come:
\begin{equation}\label{19 P}
    \mathcal{F}\left( \mathscr{P}\frac{1}{x} \right)=T_{i\pi \varepsilon(\omega)} \ \ \ \ \iff \ \ \ \ \mathcal{F}\left( \mathscr{P}\frac{1}{x} \right)=i\pi \varepsilon(\omega)
\end{equation}
\subsection{Esempi}
Si consideri la funzione $u_n(x)\equiv\frac{sen(nx)}{\pi x}$.\\
Utilizzando la (\ref{19 P}) si può dimostrare che:
\begin{equation}
    u_n(x)\equiv\frac{sen(nx)}{\pi x} \Longrightarrow \mathcal{F}(u_n)=\Theta(\omega+n)-\Theta(\omega-n)=\begin{cases}
    1 & |\omega|\le n\\
    0 & |\omega|>n
    \end{cases}
\end{equation}
Per cui esiste il limite:
\begin{equation}
    \lim_{n\to\infty}\mathcal{F}(u_n)=1=\mathcal{F}(\delta_0)
\end{equation}
Per la continuità degli operatori, questo implica che $T_{u_n}\xrightarrow{S'}\delta_0$.\\
Per dimostrarlo, basta scrivere il seno in notazione complessa:
\begin{equation}\begin{split}
    \mathcal{F}(u_n)=\int_{-\infty}^\infty \frac{sin(nx)}{\pi x}e^{i\omega x}dx=\mathscr{P}\int_{-\infty}^\infty \frac{sin(nx)}{\pi x}e^{i\omega x}dx=\\
    =\frac{1}{2\pi i}\left\{ \mathscr{P}\int_{-\infty}^\infty \frac{e^{i(\omega+n)x}}{x}dx-\mathscr{P}\int_{-\infty}^\infty \frac{e^{i(\omega-n)x}}{x}dx  \right\}=\\
    =\frac{1}{2\pi i}\left\{ \mathcal{F}\left(\mathscr{P}\frac{1}{x} \right)(\omega +n)-\mathcal{F}\left(\mathscr{P}\frac{1}{x} \right)(\omega -n) \right\}=\\
    =\frac{1}{2\pi i}\left\{ i\pi \varepsilon(\omega +n)-i \pi \varepsilon(\omega-n) \right\}=\frac{1}{2}\left\{ \varepsilon(\omega+n)-\varepsilon(\omega-n) \right\}=\\
    =\theta(\omega+n)-\theta(\omega-n)=\left\{ \begin{array}{cc}
         1 \ \ \ \ \ \text{per} \ \ \ |\omega|<n  \\
         &  \\
         0 \ \ \ \ \ \text{per} \ \ \ |\omega|>n
    \end{array}\right.
\end{split}\end{equation}
Avendo usato la relazione:
\begin{equation}
    \varepsilon(x)=2\theta(x)-1
\end{equation}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Proprietà e due esempi importanti}
Si elencano due proprietà:
    \begin{equation}
        \mathcal{F}(D^kT)=(-i\omega)^k \mathcal{F}(T)
        \end{equation}
        \begin{equation}\label{18.0.2}
          D^k(\mathcal{F}(T))=\mathcal{F}((ix)^kT)
        \end{equation}
Le dimostrazioni, lasciate al lettore, sfruttano il fatto che, detto P$(x)$ un polinomio in $x$:
\begin{equation}
    <P(x)T,\phi>=<T,P(x)\phi> \qquad \forall T\in S', \forall \phi\in S
\end{equation}
Tali proprietà permettono di ottenere 2 esempi importanti:
\begin{itemize}
    \item 
    \begin{equation}
        \mathcal{F}(\delta^{(k)}(x))=(-i\omega)^k
    \end{equation}
    Si ha infatti 
    \begin{equation}
        \mathcal{F}(\delta_0 ^{(k)})=\mathcal{F}(D^k \delta_0)=(-i\omega)^k \mathcal{F}(\delta_0)=(-i\omega)^k
    \end{equation}
    \item
    \begin{equation}
        \mathcal{F}(x^k)=(-i)^k2\pi \delta^{(k)}(\omega)
    \end{equation}
    Infatti
    \begin{equation}
        \mathcal{F}(e^{-iax})=2\pi \delta(\omega -a)
    \end{equation}
     e prendendo $a=0$ si trova
     \begin{equation}
         \mathcal{F}(1)=2\pi \delta(\omega) \ \ \ \iff \ \ \ \mathcal{F}(T_1)=2\pi \delta_0
     \end{equation}
     Ma per le proprietà sopra:
     \begin{equation}
         \mathcal{F}((ix)^kT)=D^k \mathcal{F}(T) \ \ \iff \ \ \mathcal{F}(x^kT)=(-i)^kD^k\mathcal{F}(T)
     \end{equation}
     Da cui, prendendo $T=1$
     \begin{equation}
         \mathcal{F}(x^k)=\mathcal{F}(x^kT_1)=(-i)^kD^k\mathcal{F}(T_1)=(-i)^k2\pi D^k \delta_0
     \end{equation}
     Ossia
     \begin{equation}
         \mathcal{F}(x^k)=(-i)^k2\pi \delta^{(k)}(\omega)
     \end{equation}
\end{itemize}

Facendo l'antitrasformata dei risultati appena trovati si ottiene:
\begin{itemize}
    \item 
    \begin{equation}
        \mathcal{F}^{-1}(\omega^k)=i^k \delta^{(k)}(x)
    \end{equation}
    \item
    \begin{equation}
        \mathcal{F}^{-1}(\delta^{(k)}(\omega))=\frac{1}{2\pi}(ix)^k
    \end{equation}
\end{itemize}

\subsection{Esercizi}
\begin{enumerate}
    \item 
    \rule{\textwidth}{0.7pt}
    Si verifica la relazione:
    \begin{equation}
        x\delta'(x)=-\delta(x)
    \end{equation}    
    \begin{proof}
    Utilizzando che per ogni polinomio e $\forall \ \phi \ \in \mathcal{E}\equiv C^{\infty}$ vale:
    \begin{equation}
        <P(x)T,\phi>\equiv <T,P(x)\phi>
    \end{equation}
    e che:
    \begin{equation}
        <D^k\delta_{x_0},\phi>=(-1)^k \phi^k(x_0)
    \end{equation}
    Si ha:
    \begin{equation}
        <x\delta'_0,\phi>=<\delta'_0,x\phi>=-D(x\phi)\left. \right|_{x=0}=[-x\phi'-\phi]\left. \right|_{x=0}=-\phi_0=-<\delta_0,\phi>
    \end{equation}
    Ossia:
    \begin{equation}
        x\delta'_0=-\delta_0
    \end{equation}
    
    \end{proof}
    
    \item
    \rule{\textwidth}{0.7pt}
    
    Si verifica che vale in generale
    \begin{equation}
        x^cD^k \delta_0=0 \ \ \ \forall c > k \ \ (c,k \in \mathds{N})
    \end{equation}
    
    \begin{proof}
    Infatti
    \begin{equation}
        <x^cD^k\delta_0,\phi>=<D^k \delta_0,x^c\phi>=<D^k\delta_0,x^c\phi>=(-1)^kD^k(x^c\phi)\left. \right|_{x=0}=0 \ \ \ \ \forall c>k
    \end{equation}
    In particolare prendendo $c=1$ e $k=0$ si trova:
    \begin{equation}
        x\delta_0(x)=0
    \end{equation}
    
    \end{proof}
    
    Dal momento che le uniche distribuzioni a supporto puntiforme sono la delta e le sue derivate, si trova che la soluzione più generale dell'equazione
    \begin{equation}
        xT=0 \ \ \Rightarrow \ \ T=c\delta(x) \ \ \ \ c \in \mathds{C}
    \end{equation}
    E allo stesso modo si trova
    \begin{equation}
        x^2T=0 \ \ \Rightarrow \ \ T=c_1 \delta(x) + c_2 \delta'(x) \ \ \ \ c_1,c_2 \in \mathds{C}
    \end{equation}
    E in generale
    \begin{equation}
        x^cT=0 \ \ \Rightarrow \ \ T=\sum_{k=0}^{c-1}b_kD^k\delta_0 \ \ \ \ c\ge 1 \ , \ b_k \in \mathds{C}
    \end{equation}
    
    \item
    \rule{\textwidth}{0.7pt}
    Si trovi la soluzione più generale dell'equazione 
    \begin{equation}\label{noice}
        xT=1
    \end{equation}
    
    \begin{proof}
    Si verifica che 
    \begin{equation}
        T_p = \mathcal{P}\frac{1}{x}
    \end{equation}
    è una soluzione particolare. Infatti:
    \begin{equation}
        \begin{split}
            <x\mathcal{P}\frac{1}{x},\phi>=<\mathcal{P}\frac{1}{x},x\phi>= \lim_{R\to \infty}\lim_{\varepsilon\to 0^+}\left\{ \int_{-R}^{-\varepsilon}+\int_{\varepsilon}^{R} \right\} \frac{1}{x}x\phi(x) \ dx = \\
            =\lim_{R\to \infty}\lim_{\varepsilon\to 0^+} \left\{ \int_{-R}^{-\varepsilon}+\int_{\varepsilon}^{R} \right\} \phi(x) \ dx= \int_{-\infty}^{\infty}\phi(x) \ dx = \\
            = \int_{-\infty}^{\infty}1 \phi(x) \ dx = <T_1,\phi> \ \ \ \ \ \ \forall \phi \in S
        \end{split}
    \end{equation}
    Ovvero con notazione \textit{lasca}:
    \begin{equation}
        x\mathcal{P}\frac{1}{x}=1
    \end{equation}
    Per trovare la soluzione più generale si somma ora la soluzione dell'omogenea associata
    \begin{equation}
        xT_0=0 \ \ \Rightarrow \ \ T_0=c\delta(x)
    \end{equation}
    Perciò la soluzione più generale della (\ref{noice}) è:
    \begin{equation}
        T=T_p + T_0=\mathcal{P}\frac{1}{x}+c\delta(x)
    \end{equation}
    
    \end{proof}
    
    \item
    \rule{\textwidth}{0.7pt}
    Si trovi la soluzione più generale dell'equazione
    \begin{equation}
        xT=aT \ \ \ \ \ a \in \mathds{R}
    \end{equation}
    
    \begin{proof}
    Scrivendo
    \begin{equation}
        (x-a)T=0
    \end{equation}
    Si trova che $T$ deve avere supporto puntiforme in $a$, da cui la soluzione più generale è 
    \begin{equation}
        T=c\delta(x-a) \ \ \ \ c \in \mathds{C}
    \end{equation}
    
    \end{proof}
    
\end{enumerate}

\subsection{Esercizi sulle distribuzioni}

Si risolvono in trasformata di Fourier le seguenti equazioni con distribuzioni:

\begin{enumerate}
    \item 
    \rule{\textwidth}{0.7 pt}
    \begin{equation}
        xT=0
    \end{equation}
    In cui $T$ è l'incognita. Prendendo la trasformata e sfruttando la (\ref{18.0.2}) si trova:
    \begin{equation}
        \mathcal{F}(xT)=-i\mathcal{F}(ixT)=-iD\mathcal{F}(T)=0
    \end{equation}
    Ossia
    \begin{equation}
        D\mathcal{F}(T)=0 \ \ \Rightarrow \ \ \mathcal{F}(T)=c \ \ \Rightarrow \ \ T=\mathcal{F}^{-1}(c)=c\mathcal{F}^{-1}(1)=c\delta(x)
    \end{equation}
    
    \item
    \rule{\textwidth}{.7 pt}
    \begin{equation}
        xT=aT \ \ \iff \ \ (x-a)T=0
    \end{equation}
    con $a \in \mathds{R}$.
    \\
    Trasformando:
    \begin{equation}
        \mathcal{F}(xT)=-iD\mathcal{F}(T) \ \ \ \ \mathcal{F}(aT)=a\mathcal{F}(T)
    \end{equation}
    Perciò
    \begin{equation}
        -iD\mathcal{F}(T)=a\mathcal{F}(T) \ \ \iff \ \ D\mathcal{F}=ia\mathcal{F}(T)
    \end{equation}
    Da cui in sintesi
    \begin{equation}
        \mathcal{F}(T)=ce^{ia\omega} \ \ \Rightarrow \ \ T=\mathcal{F}^{-1}(ce^{ia\omega})=c\mathcal{F}^{-1}(e^{ia\omega})=c\delta(x-a)
    \end{equation}
    \item
    \rule{\textwidth}{.7 pt}
    \begin{equation}
        x^2T=1
    \end{equation}
    Se si osserva che 
    \begin{equation}\label{shrek}
        x^2D\left( \mathscr{P}\frac{1}{x} \right)=-1
    \end{equation}
    si può scrivere la soluzione più generale nella forma
    \begin{equation}
        T=-D\left( \mathscr{P}\frac{1}{x} \right)+c_1\delta(x)+c_2\delta'(x)
    \end{equation}
    La (\ref{shrek}) fornisce una soluzione particolare, ora si dimostra che per l'omogenea vale:
    \begin{equation}
        x^2T_0=0 \ \ \ \Rightarrow \ \ \ T_0=c_1\delta(x)+c_2\delta'(x)
    \end{equation}
    Se si fa la trasformata infatti:
    \begin{equation}
        \mathcal{F}(x^2T_0)=-\mathcal{F}((ix)^2T_0)=-D^2\mathcal{F}(T_0)=0
    \end{equation}
    Da cui
    \begin{equation}
        D\mathcal{F}(T_0)=c \ \ \Rightarrow \ \ \mathcal{F}(T_0)=c\omega + c_1
    \end{equation}
    e antitrasformando
    \begin{equation}
        T_0=\mathcal{F}^{-1}(c\omega + c_1)=c_1 \delta(x) + c \delta'(x)
    \end{equation}
    
    
    
\end{enumerate}








\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Le distribuzioni \texorpdfstring{$\delta_+$}{Lg} e \texorpdfstring{$\delta_-$}{Lg}}

Si usano comunemente in fisica le distribuzioni:
\begin{equation}
    \delta_{\pm}\equiv \frac{1}{2}\delta(x) \pm \frac{1}{2\pi i}\mathcal{P}\frac{1}{x}
\end{equation}
La cui trasformata è:
\begin{equation}
    \mathcal{F}(\delta_{\pm}(x))=\frac{1}{2}(1\pm \varepsilon(\omega))=\theta(\pm \omega)
\end{equation}
Avendo usato le relazioni:
\begin{equation}
    \theta(\omega)+\theta(-\omega)=1 \ \ \ \ \ \ \ \theta(\omega)-\theta(-\omega)=\varepsilon(\omega)
\end{equation}
Sfruttando la relazione $\mathcal{F}^{-1}=\frac{1}{2\pi}\hat{P}\mathcal{F}$ con $\hat{P}$ operatore di Parità spaziale.\\
Si possono ricavare anche le seguenti:
\begin{equation}
    \mathcal{F}^{-1}\left( \mathcal{P}\frac{1}{\omega} \right)=\frac{1}{2\pi}i \pi \varepsilon(-x)=\frac{1}{2i}\varepsilon(x) \ \ \Rightarrow \ \ \mathcal{F}(\varepsilon(x))=2i \mathcal{P}\frac{1}{\omega}
\end{equation}
Da cui si ricava ancora:
\begin{equation}
    \mathcal{F}(\theta(\pm x))=\pm i \mathcal{P}\frac{1}{\omega}+\pi \delta (\omega)\equiv 2\pi \delta_{\mp} (\omega)
\end{equation}

\subsection{Sulla trasformata di Fourier della \texorpdfstring{$\theta$}{Lg}}

Si vogliono dimostrare le seguenti relazioni (per $a \in \mathds{R}$):
\begin{itemize}
    \item 
    \begin{equation}
    \mathcal{F}(\theta(x)e^{-iax})=i\mathcal{P}\frac{1}{\omega -a}+\pi \delta (\omega -a)
    \end{equation}
    \item
    \begin{equation}
        \mathcal{F}(\theta(x-a))=e^{i\omega a}\mathcal{F}(\theta(x))=e^{i\omega a}\left( i\mathcal{P}\frac{1}{\omega}+\pi \delta(\omega) \right)
    \end{equation}
\end{itemize}

Per dimostrarle si pensi alla $\theta$ come al limite di una successione di funzioni $u_n \in \mathds{L}^1$ a cui sono associate le distribuzioni $T_{u_{n}}$:
\begin{equation}
    T_{\theta}=\lim_{n\to \infty}T_{u_{n}} \ \ \ \text{con} \ \ u_n(x)= \left\{ \begin{array}{lr}
         1 \ \ \text{per} \ x \in (0,n)  \\
         0 \ \ \text{per} \ x<0 \ , \ x>n
    \end{array}\right.
\end{equation}
Risulta infatti:
\begin{equation}
    <T_{u_{n}},\phi>=\int_{-\infty}^{\infty}u_n(x)\phi(x)dx=\int_{0}^{n}\phi(x)dx \xrightarrow{n \to \infty}\int_0 ^{\infty}\phi(x)dx=<T_{\theta},\phi> \ \ \forall \phi \in S
\end{equation}
Da cui 
\begin{equation}
    \lim_{n\to \infty}T_{u_{n}}=T_{\theta}
\end{equation}

Conseguentemente si ha:
\begin{equation}
    \mathcal{F}(T_{\theta})=\lim_{n\to \infty}\mathcal{F}(T_{u_{n}})=\lim_{n\to \infty}T_{\mathcal{F}(u_{n})}
\end{equation}

Per cui si può scrivere:
\begin{equation}
    T_{\theta(x)e^{-iax}}=\lim_{n\to \infty}T_{u_n(x)e^{-iax}}
\end{equation}
Perciò
\begin{equation}
    \mathcal{F}(T_{\theta(x)e^{-iax}})=\lim_{n\to \infty}\mathcal{F}(T_{u_n(x)e^{-iax}})=\lim_{n\to \infty}T_{\mathcal{F}(u_n(x)e^{-iax})}
\end{equation}
Ma $u_n(x) \in \mathds{L}^1$ da cui
\begin{equation}
    \mathcal{F}(u_n(x)e^{-iax})=\Tilde{u}_n(\omega-a)
\end{equation}
Da cui si ottiene:
\begin{equation}\begin{split}
 \mathcal{F}(T_{\theta(x)e^{-iax}})(\omega)=\lim_{n\to \infty}\mathcal{F}(T_{u_n(x)e^{-iax}})(\omega)=\lim_{n\to \infty}T_{\mathcal{F}(u_n(x)e^{-iax})(\omega)}= \\
 = \lim_{n\to \infty}T_{\mathcal{F}(u_n(x))(\omega-a)}=\mathcal{F}(T_{\theta})(\omega -a)
 =i\mathcal{P}\frac{1}{\omega -a}+\pi \delta(\omega -a)\equiv 2\pi \delta_- (\omega- a)
\end{split}\end{equation}

Analogamente per la seconda relazione si può usare la successione di funzioni:
\begin{equation}
    v_n(x)=u_n(x-a)=\left\{ \begin{array}{lr}
         1 \ \ \text{per} \ x \in (a,a+n)  \\
         0 \ \ \text{per} \ x<a \ , \ x>a+n
    \end{array}\right.
\end{equation}

Che per $n\to \infty$ riproduce la $\theta(x-a)$. Allora si ha:
\begin{equation}
    \begin{split}
        \mathcal{F}(T_{\theta(x-a)})=\lim_{n\to \infty} \mathcal{F}(T_{v_{n}(x)})=\lim_{n\to \infty}T_{\mathcal{F}(v_n(x))}= \\
        = \lim_{n\to \infty}T_{e^{i\omega a}\mathcal{F}(u_n(x))}=\lim_{n\to \infty} e^{i\omega a} T_{\mathcal{F}(u_n(x))}=e^{i\omega a} \mathcal{F}(T_{\theta})
    \end{split}
\end{equation}

Dove si è usato:
\begin{equation}\begin{split}
    <T_{e^{i\omega a}\mathcal{F}(u_n(x))},\phi(\omega)>=\int_{-\infty}^{\infty}e^{i\omega a}\Tilde{u}_n(\omega) \phi(\omega) d\omega= \int_{-\infty}^{\infty}\Tilde{u}_n(\omega)[e^{i\omega a}\phi(\omega)]d\omega =\\
    =<T_{\Tilde{u}_n},e^{i\omega a}\phi(\omega)> \ \ \xrightarrow{n \to \infty} \ \ <\mathcal{F}(T_{\theta}),e^{i\omega a}\phi(\omega)>=<e^{i\omega a}\mathcal{F}(T_{\theta}),\phi(\omega)> \\
    \forall \phi \in S \ \ \ \Rightarrow \ \lim_{n\to \infty}T_{e^{i\omega a}\mathcal{F}(u_n(x))}=e^{i\omega a}\mathcal{F}(T_{\theta})
\end{split}\end{equation}

\subsection{Su un limite notevole}
Si ha:
\begin{equation}
    \lim_{\epsilon\to 0^+}\frac{1}{x\pm i\epsilon}=\mathcal{P}\frac{1}{x}\mp i\pi \delta(x)
\end{equation}

Si studiano separatamente i due casi.
\\
Si ha:
\begin{equation}
    \frac{1}{x+i\epsilon}=\mathcal{F}^{-1}(v_{\epsilon}(\omega)) \ \ \ \text{con} \ \ v_{\epsilon}(\omega)=-2\pi i \theta(-\omega)e^{\epsilon \omega} \ , \ \epsilon >0
\end{equation}

\begin{proof}
\begin{equation}\begin{split}
\mathcal{F}^{-1}(v_{\epsilon}(\omega))=\frac{1}{2\pi}\int_{-\infty}^{\infty}v_{\epsilon}(\omega)e^{-i\omega x}d\omega=\frac{1}{2\pi}(-2\pi i)\int_{-\infty}^{\infty}\theta(-\omega)e^{\epsilon \omega}e^{-i\omega x}d\omega= \\
=-i \int_{-\infty}^0 e^{(\epsilon-ix)\omega}d\omega=-i \frac{e^{(\epsilon-ix)\omega}}{\epsilon-ix}\left. \right|_{-\infty}^0 = \frac{-i}{\epsilon-ix}=\frac{1}{x+i\epsilon}
\end{split}\end{equation}
Perciò nel limite $\epsilon \to 0^+$ si trova:
\begin{equation}
    \begin{split}
        \lim_{\epsilon\to 0^+}\frac{1}{x+i\epsilon}=\lim_{\epsilon\to 0^+}\mathcal{F}^{-1}(v_{\epsilon}(\omega))=-2\pi i \mathcal{F}^{-1}(\theta (-\omega))= \\
        = -2\pi i \frac{1}{2\pi}\left[i\mathcal{P}\frac{1}{x}+\pi \delta(x) \right]=\mathcal{P}\frac{1}{x}-i\pi \delta(x)
        \end{split}
\end{equation}
E si procede analogamente per $u_{\epsilon}(\omega)$ tale che $\mathcal{F}^{-1}(u_{\epsilon}(\omega))=\frac{1}{x-i\epsilon}$.
\\
Sommando e sottraendo le due relazioni trovate, è possibile trovare un'espressione per $\mathcal{P}\frac{1}{x}$ e per $\delta(x)$ come limiti di successioni:
\begin{itemize}
    \item 
    \begin{equation}
    \mathcal{P}\frac{1}{x}=\lim_{\epsilon\to 0^+}\frac{x}{x^2+\epsilon^2}
    \end{equation}
    \item
    \begin{equation}\label{delta}
        \delta(x)=\lim_{\epsilon\to 0^+}\frac{1}{\pi}\frac{\epsilon}{x^2+\epsilon^2}
    \end{equation}
\end{itemize}

\end{proof}

\subsection{Sul prodotto e la convoluzione tra distribuzioni}
Nel caso in cui una distribuzione sia associata a una funzione $u(x)$ si definisce il prodotto come segue:
\begin{equation}
    <T_uT,\phi>\equiv <T,u\phi> \ \ \ \forall \phi \in S
\end{equation}

Se $u\phi \in S$ (ossia è ancora una funzione test).
\\
Questo è verificato se $u(x)$ è un polinomio o un esponenziale, ma non nel caso della $\theta$.
\\
Per esempio se $T=\delta_{x_0}$ si trova:
\begin{equation}
    <T_u \delta_{x_0},\phi>=<\delta_{x_0},u\phi>=u(x_0)\phi(x_0)=u(x_0)<\delta_{x_0},\phi> \ \ \Rightarrow \ T_u \delta_{x_0}=u(x_0)\delta_{x_0}
\end{equation}

Mentre per le derivate della $\delta$ si trova, $\forall \phi \in S$
\begin{equation}
\begin{split}
     <T_u\delta'_{x_0},\phi >=<\delta'_{x_0},u\phi>=(-1)(u\phi)'(x_0)=(-1)[u'(x_0)\phi(x_0)+u(x_0)\phi'(x_0)]=\\
     =<-u(x_0\delta_{x_0}+u(x_0)\delta'_{x_0},\phi> \Longrightarrow T_u\delta'_{x_0}=-u'(x_0)\delta(x-x_0)+u(x_0)\delta'(x-x_0)
\end{split}
\end{equation}
E analogamente:
\begin{equation}
    u(x)\delta''(x-x_0)=u''(x_0)\delta(x-x_0)-2u'(x_0)\delta'(x-x_0)+u(x_0)\delta''(x-x_0)
\end{equation}
Richiedendo che $u(x)$ sia derivabile un numero di volte pari al gradi di derivazione della $\delta$.
\subsubsection{Prodotto di convoluzione}
Se $u,v$ sono due funzioni in $\mathds{L}^1(\mathds{R})$, allora si definisce:
\begin{equation}
    T_u * T_v \equiv T_{u*v}
\end{equation}
Ossia:
\begin{equation}
    \begin{split}
        <T_u * T_v,\phi>=<T_{u*v},\phi>=\int_{-\infty}^{\infty}dx \phi(x) (u*v)(x)=
        \int_{-\infty}^{\infty}dx \phi(x)\int_{-\infty}^{\infty}dy \ u(x-y)v(y)= \\
        =\int_{-\infty}^{\infty}dy \ v(y)\int_{-\infty}^{\infty} dx \ u(x-y) \phi(x)= 
        \int_{-\infty}^{\infty}dy \ v(y) \int_{-\infty}^{\infty}dx \ u(-(y-x))\phi(x)=\\
        =\int_{-\infty}^{\infty}dy \ v(y)\int_{-\infty}^{\infty}dx \ u_- (y-x)\phi(x)
        =\int_{-\infty}^{\infty}dy \ v(y) (u_- * \phi) (y)=<T_v,u_-*\phi> 
    \end{split}
\end{equation}
Con $u_-(t)\equiv u(-t)$.
\\
Ed è possibile estendere la definizione nei casi $T_u * T$:
\begin{equation}
    <T_u*T,\phi>\equiv <T,u_-*\phi> \ \ \forall \phi \in S
\end{equation}
A condizione che $u_-*\phi \in S$.
\\
Ad esempio è possibile definire $T_u * \delta_0$:
\begin{equation}\begin{split}
    <T_u*\delta_0,\phi>\equiv <\delta_0,u_-*\phi>=(u_-*\phi)(0)=\\
    =\int_{-\infty}^{\infty}dt \ u_-(-t)\phi(t)=\int_{-\infty}^{\infty}dt \ u(t)\phi(t)= \\
<T_u,\phi> \ \ \forall \phi \in S \ \ \Rightarrow \ T_u*\delta_0=T_u
\end{split}\end{equation}
che a volte viene scritto:
\begin{equation}
    \int_{-\infty}^{\infty}u(x')\delta(x-x')dx'=u(x)
\end{equation}

Ogni volta che il prodotto di convoluzione ben definito valgono:
\begin{itemize}
    \item 
    \begin{equation}
        D(T_1*T_2)=(DT_1)*T_2=T_1*(DT_2)
    \end{equation}
    \item
    \begin{equation}
        \mathcal{F}(T_1*T_2)=\mathcal{F}(T_1)\mathcal{F}(T_2)
    \end{equation}
    \item
    \begin{equation}
        \mathcal{F}^{-1}(\Tilde{T}_1 * \Tilde{T}_2)=2\pi T_1 T_2
    \end{equation}
\end{itemize}

\subsection{Cambiamento di variabili nelle distribuzioni}

Si vuole definire $\delta(f(x))$ nel caso $f(x)$ sia una funzione almeno $C^1$ con solo zeri semplici.
\\
Dal momento che la $\delta$ si può definire come il limite di una successione di distribuzioni associate a funzioni come in (\ref{delta}), si estende la definizione a $\delta(f(x))$:
\begin{equation}
    \delta(f(x))=\lim_{\epsilon\to 0^+}\delta_{\epsilon\to 0^+}f(x)=\lim_{\epsilon\to 0^+}\frac{1}{\pi}\frac{\epsilon}{[f(x)]^2+\epsilon^2}
\end{equation}
Ossia in maniera estesa:
\begin{equation}
<\delta(f),\phi>=\lim_{\epsilon\to 0^+}<\delta_{\epsilon}(f),\phi>=\lim_{\epsilon\to 0^+} \int_{-\infty}^{\infty}\frac{1}{\pi}\frac{\epsilon}{[f(x)]^2+\epsilon^2}\phi(x) dx
\end{equation}
Si distinguono i contributi all'integrale dovuti a diversi tratti I dell'asse reale.\\
Sia I un tratto chiuso in cui f(x)$\ne$0, si ha allora $0<m^2\le[f(x)]^2\le M^2$ per x$\in I$, da cui:
\begin{equation}
    \frac{\epsilon}{\pi(M^2+\epsilon^2)}\le \frac{\epsilon}{\pi([f(x)]^2+\epsilon^2)}\le \frac{\epsilon}{\pi(m^2+\epsilon^2)}<\frac{\epsilon}{\pi m^2}
\end{equation}
Se ne deduce:
\begin{equation}
    \lim_{\epsilon\to 0}\int_I\frac{\epsilon}{\pi([f(x)]^2+\epsilon^2)}\phi(x) dx=0
\end{equation}
Siano $I_i$ tratti chiusi, sufficentemente piccoli da contenere il solo zero $x_i$, con f($x_i$)=0, e tale che f(x) sia monotona (quindi invertibile) in $I_i$, in accordo con l'ipotesi di zeri semplici.\\
In questo caso si può fare il cambio di variabile $x\to y=f(x)$:
\begin{equation}
\int_{I_i}\frac{\epsilon}{\pi([f(x)]^2+\epsilon^2)} \phi(x)dx=\int_{-\alpha}^\beta \frac{\epsilon}{\pi (y^2+\epsilon^2)}\phi(f_i^{-1}(y))\frac{dy}{|f'(f_i^{-1}(y))|}
\end{equation}
Con $\alpha,\beta>0$. Ponendo $g(y)\equiv \frac{\phi(f_i^{-1}(y))}{f'(f_i^{-1}(y))}$ funzione continua, e con l'ulteriore cambio di variabili y=$\epsilon t$ si trova:
\begin{equation}
    \int_{I_i}\frac{\epsilon}{\pi([f(x)]^2+\epsilon^2)}
    \phi(x)dx=\int_{-\alpha/\epsilon}^{\beta/\epsilon}\frac{g(\epsilon t)}{\pi (1+t^2)}dt=\int_\infty^\infty\frac{g(\epsilon t)}{\pi (1+t^2)}\chi_{[-\frac{\alpha}{\epsilon},\frac{\beta}{\epsilon}]}(t)dt
\end{equation}
Con $\chi_{[a,b]}$ funzione caratteristica del tratto [a,b].\\
Il modulo dell'integrando è maggiorabile con una funzione $L^1(\mathbb{R})$ (basta prendere il massimo di g), per cui si può applicare il teorema della convergenza dominata e passare al limite sotto il segno di integrale:
\begin{equation}
    \lim_{\epsilon\to 0^+}\int_{-\infty}^{\infty}\delta_{\epsilon}(f(x))\phi(x)dx= g(0)\frac{1}{\pi}\int_\infty^\infty\frac{dt}{1+t^2}=g(0)=\frac{\phi(x_i)}{|f'(x_i)}=\left<  \frac{\delta_{x_i}}{|f'(x_i)|},\phi \right>
\end{equation}
Sommando su tutti gli $I_i$
\begin{equation}
    \delta(f(x))=\sum_i \frac{\delta(x-x_i)}{|f'(x_i)|}
\end{equation}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Esercizi sulle funzioni di Green}
\subsection{Primo esempio}
Consideriamo il sistema lineare indipendente dal tempo descritto da:
\begin{equation}
    y'(t)=f(t)
\end{equation}
In cui $f(t)\equiv INPUT$, $y(t)\equiv OUTPUT$.
Per determinare la funzione di Green $G(t)$ di tale sistema si pone come $f(t)=\delta(t)$, da cui $y(t)=G(t)$:
\begin{equation}
    G'(t)=\delta(t)
\end{equation}
Si passa in trasformata di Fourier:
\begin{equation}
    \mathcal{F}(G'(t))=(-i\omega)\Tilde{G}(\omega)=\mathcal{F}(\delta(t))=1 \Longrightarrow \omega\Tilde{G}(\omega)=i
\end{equation}
Usando come fatto noto che $\omega P \frac{1}{\omega}$, si ha come soluzione particolare:
\begin{equation}
    \Tilde{G}_P(\omega)=iP\frac{1}{\omega}
\end{equation}
Mentre per la soluzione dell'omogenea:
\begin{equation}
    \omega \Tilde{G}_O(\omega)=0 \Longrightarrow \Tilde{G}_O(\omega)=\Tilde{c}\delta(\omega) \qquad \Tilde{c}\in \mathbb{C}
\end{equation}
Per cui si ottiene la soluzione generale:
\begin{equation}
    \Tilde{G}(\omega)=\Tilde{G}_P(\omega)+\Tilde{G}_O(\omega)=iP\frac{1}{\omega}+\Tilde{c}\delta(\omega)
\end{equation}
Per cui antitrasformando e ricordando che $\mathcal{F}^{-1}(P\frac{1}{\omega}=\frac{1}{2i}\epsilon(t)$ e $\mathcal{F}^{-1}(\delta(\omega))=\frac{1}{2\pi}$, si trova l'espressione:
\begin{equation}
    G(t)=\frac{\epsilon(t)}{2}+\frac{\Tilde{c}}{2\pi}=\Theta(t)+c
\end{equation}
Con $c\equiv \frac{\Tilde{c}}{2\pi}-\frac{1}{2}$.
Quanto ottenuto risulta coerente con il fatto che $D\Theta(t)=\delta(t)$.
\subsection{Secondo esempio:}
Considero il sistema descritto dall'equazione differenziale:
\begin{equation}
    y'(t)+ay(t)=f(t) \qquad a\in\mathds{R}
\end{equation}
Si ottiene la funzione di Green del sistema:
\begin{equation}
    G'(t)+aG(t)=\delta(t)\quad \Longrightarrow\quad (a-i\omega)\Tilde{G}(\omega)=1 \quad \Longrightarrow\quad \Tilde{G}(\omega)=\frac{1}{a-i\omega}
\end{equation}
Antitrasformando troviamo $G(t)$:
\begin{equation}
    G(t)=\frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{-i\omega t}}{a-i\omega}d\omega
\end{equation}
Tale integrale si può calcolare con il lemma di Jordan (\ref{Air Jordan}). La funzione $g(z)=\frac{1}{-i(z+ia)}$ ha difatti un polo in $z=-ia$ e risulta $|g(z)|=\frac{1}{|z+ia|}\le\frac{1}{|R-|a||}\xrightarrow{R\to\infty} 0$.
Occore tuttavia distinguere 2 casi in funzione del segno di $a$:
\begin{itemize}
    \item \textbf{$a>0$:} Il polo risulta sul semiasse immaginario negativo, per cui dal lemma di Jordan:
    \begin{equation}
       G_p(t)= \begin{cases}
            0 & t<0\\
            \frac{i}{2\pi}(-2\pi i) Res\left[\frac{e^{-izt}}{z+ia},z=-ia\right] & t>0
        \end{cases} \Longrightarrow
        G_p(t)=\Theta(t)e^{-at}
    \end{equation}
Tuttavia questa è solo una soluzione particolare dell'equazione differenziale di partenza. Occorre aggiungere una soluzione dell'equazione omogenea:
\begin{equation}
    G_O'(t)+aG_O(t)=0 \quad \Longrightarrow\quad G_O(t)=ce^{-at} \qquad c\in \mathds{C}
\end{equation}
Questa soluzione non è fourier-trasformabile, nemmeno nel senso delle distribuizioni (T$_{e^{-at}}\in D'$ ma non $\in S$), per questo motivo non era stata trovata in trasformata.\\
Per cui la soluzione generale:
\begin{equation}
    G(t)=(\Theta(t)+c)e^{-at}
\end{equation}
Se $c=0$ la soluzione è causale.
\item \textbf{$a<0$:} Il polo risulta sul semiasse immaginario positivo, da cui 
\begin{equation}
        G_p(t)=\begin{cases}
            \frac{i}{2\pi}(2\pi i) Res\left[\frac{e^{-izt}}{z+ia},z=-ia\right] & t<0\\
            0 & t<0\\
        \end{cases} \Longrightarrow
        G_p(t)=-\Theta(-t)e^{-at}
    \end{equation}
Analogamente a prima si deve trovare anche una soluzione omogenea (identica a prima), per cui la soluzione generale risulta:
\begin{equation}
    G(t)=(-\Theta(-t)+c)e^{-at}
\end{equation}
Che risulta causale solo per $c=1$.
\end{itemize}
Le 2 equazioni trovate rapprensentano la soluzione più generale dell'equazione di partenza. \\
Inoltre le soluzioni particolari sono tali indipendentemente dal segno di $a$, come si può verificare
Tuttavia l'equazione di partenza poteva essere risolta direttamente senza ricorrere alle trasformate di Fourier:
\begin{equation}
    G'(t)+aG(t)=0 \text{ se $t<0$ o $t>0$ } \Longrightarrow
    G(t)\begin{cases}
    c_1e^{-at} & t<0\\
    c_2e^{-at} & t>0
    \end{cases}
\end{equation}
Ricordando che se $u(x)$ è derivabile ovunque tranne che in $x_0$, dove presenta una discontinuità di prima specie pari a $\sigma\equiv \lim_{x\to x_0^+}u(x)-\lim_{x\to x_0^-}u(x)$, si ha $\sigma DT_u=\delta_{x_0}+T_{\{u'\}}$.\\
Nel caso in esame $DT_G+aT_G=\delta_0$, per cui $G(t)$ deve avere una discontinuità finita in $t=0$ pari a 1, per cui definitiva:
\begin{equation}
    G(t)=e^{-at}(\Theta(t)+c)
\end{equation}

\subsection{Terzo esempio}
Si consideri il sistema descritto da:
\begin{equation}
    y'(t)+iby(t)=f(t) \ \ \ \ b \in \mathds{R}
\end{equation}
L'equazione differenziale per la funzione di Green diventa:
\begin{equation}
    G'(t)+ibG(t)=\delta(t) \ \ \ \Rightarrow \ \ \ -i(\omega - b)\Tilde{G}(\omega)=1 \ \ \ \Rightarrow \ \ \ (\omega-b)\Tilde{G}(\omega)=i
\end{equation}
\begin{itemize}
    \item \textbf{Omogenea :}
    \begin{equation}
        (\omega-b)\Tilde{G}(\omega)=0 \ \ \ \Rightarrow \ \ \ \Tilde{G}_o(\omega)=\Tilde{c}\ \delta(\omega -b)
    \end{equation}
    \item\textbf{Particolare :}
    \begin{equation}
        (\omega-b)\Tilde{G}(\omega)=i \ \ \ \Rightarrow \ \ \ \Tilde{G}_p(\omega)=\mathcal{P}\frac{i}{\omega - b}
    \end{equation}
\end{itemize}
Da cui:
\begin{equation}
    \Tilde{G}(\omega)=\Tilde{G}_o(\omega) + \Tilde{G}_p(\omega)=\Tilde{c}\ \delta(\omega -b) + \mathcal{P}\frac{i}{\omega - b}
\end{equation}
E antitrasformando:
\begin{equation}
    G(t)=\left[ \frac{1}{2}(2\theta(t)-1)+\frac{\Tilde{c}}{2\pi} \right]e^{-ibt}=[\theta(t)+c]e^{-ibt}
\end{equation}
Si sarebbe potuto risolvere in maniera analoga all'esempio precedente senza passare in trasformata di Fourier.

\newpage
\section{La funzione di Green per l'equazione di Poisson}
Si consideri l'equazione di Poisson
\begin{equation}\label{Poisson}
    \Delta \Phi \equiv \frac{\partial^2 \Phi}{\partial x^2}+\frac{\partial^2 \Phi}{\partial y^2}+\frac{\partial^2 \Phi}{\partial z^2}=-4\pi \rho
\end{equation}

Dove $\Delta$ è il solito Laplaciano.
\\
Si può considerare la (\ref{Poisson}) come un sistema lineare e invariante per traslazioni in cui $\rho(\vec{x})$ è l'INPUT e $\Phi(\vec{x})$ è l'OUTPUT.
\\
La soluzione è nota ed è:
\begin{equation}\label{23 sol}
    \Phi(\Vec{x})=\iiint_{\mathds{R}^3}\frac{\rho(\Vec{x})}{|\Vec{x}-\vec{x}'|}\ d^3\Vec{x}'=\frac{1}{|\Vec{x}|}*\rho
\end{equation}
Da cui si verifica che $G_o(\Vec{x})\equiv\frac{1}{|\Vec{x}|}$ è la funzione di Green del problema.\\
Difatti dovendo essere soluzione dell'eq (\ref{Poisson}) con $\rho(\vec{x})=\delta^{(3)}(\vec{x})$, si ha:
\begin{equation}
    \Delta G_0(\Vec{x})=-4\pi \delta^{(3)}(\vec{x})
\end{equation}
Risulta essere i potenziale generato da una carica puntiforme posta in $\Vec{x}=0$.\\
E' possibile dimostrarlo anche direttamente usando il seguente:
\begin{theorem}[\textbf{di Green}]\label{green}
Dato un volume (aperto e connesso) limitato dalla superficie $S=\partial V$ e due funzioni $\psi(\Vec{x})$ e $\phi(\Vec{x})$ regolari in $V$ si ha:
\begin{equation}
    \int_V(\psi \Delta \phi - \phi \Delta \psi) \ d^3 \Vec{x}=\int_{S=\partial V}\left( \psi \frac{\partial \phi}{\partial n}-\phi \frac{\partial \psi}{\partial n} \right) \ dS
\end{equation}
con $\partial/ \partial n \equiv \Vec{n}\cdot \nabla $ la derivata lungo la direzione del versore normale $\Vec{n}$ orientato verso l'esterno del volume $V$.
\end{theorem}

\begin{proof}
Si parte dal \textbf{Th. della divergenza}, per cui, dato un campo vettoriale $\Vec{A}$ racchiuso da una superficie $S\equiv \partial V$ si ha:
\begin{equation}\label{Div}
    \int_V \nabla \cdot \Vec{A} \ d^3 \Vec{x}=\int_{S=\partial V}\Vec{A}\cdot d\Vec{S}=\int_{S=\partial V}\Vec{A}\cdot \Vec{n} \ dS
\end{equation}
Prendendo $\Vec{A}=\psi \nabla \phi$ risulta
\begin{equation}
    \nabla \cdot \Vec{A}=\nabla \cdot (\psi \nabla \phi)=\nabla \psi \cdot \nabla \phi + \psi \Delta\phi \ \ \ \ \ \ \ \ \Vec{A}\cdot \Vec{n}=\psi \frac{\partial \phi}{\partial n}
\end{equation}
Da cui sostituendo nella (\ref{Div}) si trova:
\begin{equation}
    \int_V (\psi \Delta \phi + \nabla \psi \cdot \nabla \phi ) d^3 \Vec{x}=\int_S \psi \frac{\partial \phi}{\partial n}ds
\end{equation}
Nota come \textit{Prima identità di Green}.
\\
Se si considera la stessa identità ma scambiando tra loro $\phi$ e $\psi$ poi le si sottraggono membro a membro si trova la tesi, nota come \textit{Seconda identità di Green}.

\end{proof}


Si utilizza ora il Th. per dimostrare che 
\begin{equation}
    \Delta \frac{1}{|\Vec{x}|}=-4\pi \delta^{(3)}(\Vec{x})
\end{equation}
Nel senso delle distribuzioni si ha 
\begin{equation}
    \Delta T_{1/|\Vec{x}|}=-4\pi \delta^{(3)}_{\Vec{0}}
\end{equation}
Lo si può fare prendendo il limite di una distribuzione adoperando le funzioni a scalino:
\begin{equation}
    T_{1/|\Vec{x}|}=\lim_{R\to \infty} \lim_{\varepsilon \to 0^+}T_{u_{\varepsilon,R}(\Vec{x})} \ \ \ \ \ \ \ \ u_{\varepsilon,R}(\Vec{x})\equiv \left\{ \begin{array}{lr}
         \frac{1}{|\Vec{x}|} \ \ \ \ \ \ \varepsilon\le |\Vec{x}|\le R  \\
         0 \ \ \ \ \ \ |\Vec{x}|<\varepsilon \ \ \ |\Vec{x}|>R
    \end{array}\right.
\end{equation}
Notare che, non essendo $1/|\Vec{x}|$ derivabile in $\Vec{x}=\Vec{0}$ non si può dire che $\Delta T_{1/|\Vec{x}|}=T_{\Delta u_{\varepsilon, R}}$.
\\
Usando le proprietà di derivazione delle distribuzioni si trova:
\begin{align}
    <\Delta T_{1/|\vec{x}|},\phi>&=\lim_{R\to \infty}\lim_{\varepsilon \to 0^+}<\Delta T_{u_{\varepsilon,R}},\phi>=\lim_{R\to \infty}\lim_{\varepsilon \to 0^+}<T_{u_{\varepsilon,R}},\Delta \phi>\\&=\lim_{R\to \infty}\lim_{\varepsilon \to 0^+}\iiint_{\varepsilon\le |\Vec{x}|\le R}\frac{1}{|\Vec{x}|}\Delta \phi \ d^3\Vec{x}
\end{align}
Detto $V_{\varepsilon,R}$ il guscio sferico su cui avviene l'integrazione, si può usare il (\ref{green}) con $\psi(\Vec{x})=1/|\Vec{x}|$.
\\
Con questa scelta risulta $\hat{n}=\hat{u}_r$, con $\hat{u}_r$ versore radiale uscente, per il guscio sferico $S_R$, mentre $\hat{n}=-\hat{u}_r$, versore radiale uscente dal guscio interno, per il guscio sferico $S_\varepsilon$.
\\
Per cui
\begin{equation*}
    \frac{\partial}{\partial n}=\hat{n}\cdot \nabla=\hat{u}_r\cdot \nabla=\frac{\partial}{\partial r}
\end{equation*}
per $S_R$, mentre
\begin{equation*}
    \frac{\partial}{\partial n}=\hat{n}\cdot \nabla=-\hat{u}_r\cdot \nabla=-\frac{\partial}{\partial r}
\end{equation*}
per $S_\varepsilon$. \\
E si trova:
\begin{align}
    \int_{V_{\varepsilon,R}}\frac{1}{|\Vec{x}|}\Delta \phi d^3 \Vec{x}
    =\int_{S_R}\left( \frac{1}{r}\frac{\partial \phi}{\partial r}+\frac{\phi}{r^2} \right)ds - \int_{S_{\varepsilon}}\left( \frac{1}{r}\frac{\partial \phi}{\partial r}+\frac{\phi}{r^2} \right)ds
\end{align}
Avendo sfruttato che $\Delta\frac{1}{|\vec{x}|}=0$ $\forall \Vec{x}\ne 0$.\\
Grazie al buon andamento a infinito delle funzioni test $\phi \in S$ si ha (basta passare in coordinate sferiche con $dr=R^2 d\Omega$):
\begin{equation}
    \lim_{R\to \infty}\int_{S_R}\left( \frac{1}{r}\frac{\partial \phi}{\partial r}+\frac{\phi}{r^2} \right)ds=0
\end{equation}

Da cui
\begin{equation}\begin{split}
   \lim_{R\to \infty} \lim_{\varepsilon \to 0^+} \int_{V_{\varepsilon,R}}1/|\Vec{x}|\Delta \phi d^3 \Vec{x}= - \lim_{\varepsilon \to 0^+} \int_{S_{\varepsilon}}\left( \frac{1}{r}\frac{\partial \phi}{\partial r}+\frac{\phi}{r^2} \right)ds=\\
   =-\lim_{\varepsilon \to 0^+}\int \left( \frac{1}{\varepsilon}\frac{d\phi}{dr}+\frac{1}{\varepsilon^2}\phi \right)\varepsilon^2 d\Omega=-\lim_{\varepsilon \to 0^+}\int \phi \ d\Omega=-\phi(\vec{0})\int d\Omega = -4\pi \phi(\Vec{0})
\end{split}\end{equation}

Da cui si trova
\begin{equation}
    <\Delta T_{1/|\Vec{x}|},\phi>=-4\pi <\delta^{(3)}_{\Vec{0}},\phi> \ \ \ \ \ \ \forall \phi \in S
\end{equation} 



\newpage
\section{Funzioni di Green per sistemi con condizioni al contorno assegnate}
In un generico sistema lineare
\begin{equation}
    \text{INPUT } \ a(x) \ \ \rightarrow \ \ b(x) \ \text{OUTPUT}
\end{equation}
con condizioni al contorno assegnate per $b(x)$ in punti fissati, la funzione di Green del sistema dipende separatamente da $x$ e $x'$, anzichè solo dalla loro differenza $x-x'$ (le condizioni al contorno rompono l'invarianza per traslazioni).\\
Ad esempio si consideri un sistema del tipo:
\begin{equation}\label{24 es}
    L_x[b(x)]=a(x)
\end{equation}
Sia $L_x$ operatore differenziale lineare e si abbiano condizioni al contorno assegnate $b(\alpha)=b(\beta)=0$.\\
La funzione di Green $G(x,x')$ del sistema sarà la soluzione dell'equazione (\ref{24 es}) con $a(x)\to\delta(x-x')$ e con le dovute condizioni al contorno:
\begin{equation}
    L_x[G(x,x')]=\delta(x-x') \qquad G(\alpha,x')=G(\beta,x')=0\ \forall x'
\end{equation}
Si ha in tale caso:
\begin{equation*}
    b(x)=\int G(x,x')a(x')dx' \Longrightarrow L_x[b(x)]=\int L[G(x,x')]a(x')dx'=\int\delta(x-x')a(x')dx'=a(x)
\end{equation*}
\subsection{Esempio}
Si consideri il sistema:
\begin{equation}
    \frac{d^2 b}{dx^2}=a(x) \qquad b(0)=b(1)=0
\end{equation}
Si determina la funzione di Green del sistema:
\begin{equation}
    \frac{d^2}{dx^2}G(x,x')=\delta(x-x') \qquad G(0,x')=G(1,x')=0
\end{equation}
Si ottiene:
\begin{equation}
    G(x,x')=\begin{cases}
    Ax+B & 0\le x<x'\le 1\\
    Cx+D & 0\le x'<x\le 1
    \end{cases}
\end{equation}
Affinchè sia soluzione si deve avere:
\begin{equation}
    \lim_{x\to x'-}G(x,x')=\lim_{x\to x'+}G(x,x')\Longrightarrow Ax'+B=Cx'+D
\end{equation}
\begin{equation}
    \lim_{x\to x'+}\frac{d}{dx}G(x,x')-\lim_{x\to x'-}\frac{d}{dx}G(x,x')\Longrightarrow C-A=1
\end{equation}
Si osservi che $A,B,C,D$ sono costanti rispetto ad $x$, ma sono in generale funzioni di $x': A=A(x')$.\\
Si impongono anche le condizioni al contorno per G:
\begin{equation}
    G(0,x')=B(x')=0 \qquad G(1,x')=C(x')+D(x')=0 \qquad \forall x'
\end{equation}
Si ricava dunque:
\begin{equation}
    \begin{cases}
    A(x')=C(x')-1=-D(x')-1\\
    B(x')=0\\
    C(x')=-D(x')\\
    \end{cases}\Longrightarrow G(x,x')=\begin{cases}
    (-D(x')-1)x &  0\le x<x'\le 1\\
    D(x')(1-x) & 0\le x'<x\le 1
    \end{cases}
\end{equation}
Ma dalla condizione di continuità risulta che $D(x')=-x'$, per cui:
\begin{equation}
    G(x,x')=\begin{cases}
    (x'-1)x &  0\le x<x'\le 1\\
    x'(x-1) & 0\le x'<x\le 1
    \end{cases}
\end{equation}
Ovvero risulta simmetrica rispetto a $x\to x'$
\subsection{Soluzione formale del problema elettrostatico dei valori al contorno mediante la funzione di Green}
Si vuole ottenere la soluzione dell'equazione dell'equazione di Poisson:
\begin{equation}
    \Delta \Phi=-4\pi\rho(\Vec{x})
\end{equation}
All'interno di un volume $V$, con condizioni al contorno sulla superfice $S=\partial V$.\\
Si è gia visto che $G_0(\vec{x})\equiv\frac{1}{|\vec{x}|}$ è una funzione di Green (ovvero $\Delta \frac{1}{|\vec{x}|}=-4\pi\delta^{(3)}(\Vec{x})$).\\
Di conseguenza detto $\vec{x}_0$ un punto qualsiasi del volume $V$, si ha che:
\begin{equation}
    \Delta G_0(\vec{x}-\vec{x}_0)=\Delta\frac{1}{|\vec{x}-\vec{x}_0|}=-4\pi\delta^{(3)}(\Vec{x}-\vec{x}_0)
\end{equation}
Più in generale una qualsiasi funizone del tipo:
\begin{equation}\label{24 G G}
    G(\vec{x}_0,\vec{x})=G_0(\vec{x}-\vec{x}_0)+h(\vec{x}_0,\vec{x})=\frac{1}{|\vec{x}-\vec{x}_0|}+h(\vec{x}_0,\vec{x})
\end{equation}
Con $h(\vec{x}_0,\vec{x})$ funzione armonica $\forall \vec{x}\in V$.\\
Anche $G(\vec{x}_0,\vec{x})$ è per cui una funzione di Green del problema. Data l'arbitrarietà della funzione $h(\vec{x}_0,\vec{x}$), posso effettuare tale scelta in modo da soddisfare una determinata condizione al contorno su $S\equiv\partial V$.\\
La soluzione dell'equazione di Poisson (\ref{Poisson}) può allora essere ottenuta tramite il teorema di Green. Prendendo $\phi(\vec{x})=\Phi(\vec{x})$ e $\psi(\vec{x})=G(\vec{x}_0,\vec{x})$ e scegliendo per essa una funzione di Green che soddisfa condizioni al contorno che non dipendono in modo dettagliato dalle condizioni al contorno soddisfatte da $\Phi$ su $S$.\\
Utilizzando l'equazione (\ref{24 G G}) e prendendo un volume $V_\epsilon\equiv V/C_\epsilon$ con $C_\epsilon=\{x:|x|\le\epsilon\}$ sfera di raggio $\epsilon$, racchiusa dalla superfice sferica  $S_\epsilon$ e facendo tendere $\epsilon\to 0$ si trova, riordinando i termini e dividendo per $4\pi$:
\begin{equation}\label{24 19}
    \Phi(\vec{x}_0)=\int_VG(\vec{x}_0,\vec{x})\frac{}{}\rho(\vec{x})d^3\vec{x}+\frac{1}{4\pi}\int_S\biggl[G(\vec{x}_0,\vec{x})\frac{\partial \Phi(\Vec{x})}{\partial n}-\Phi(\Vec{x})\frac{\partial G(\vec{x}_0,\vec{x})}{\partial n}\biggr]dS
\end{equation}
Per cui la soluzione dell'equazione (\ref{Poisson}) in un volume $V$ è definita univocamente, a meno di una costante additiva, assegnando i valori di $\Phi|_s$, sulla superficie $S\equiv \partial V$ (detta condizione al contorno di Dirichlet), oppure assegnando i valori della derivata normale $\frac{\partial \Phi(\Vec{x})}{\partial n}\bigg|_S$ sulla superficie (condizione di Neumann).\\
Difatti date 2 soluzioni della (\ref{Poisson}) che soddisfano le medesime condizioni al contorno su $S$, si ha, utilizzando la prima identità di Green:
\begin{equation}
    \int_V(\psi\Delta\phi+\nabla\psi\cdot\nabla\phi)d^3\vec{x}=\int_S\psi\frac{\partial\phi}{\partial n}dS
\end{equation}
Con $\psi=\phi=U\equiv\Phi_2-\Phi_1$:
\begin{equation}
    \int_V(U\Delta U+\nabla U\cdot\nabla U) d^3\vec{x} = \int_S U\frac{\partial U}{\partial n}dS
\end{equation}
Essendo $\Delta U=\Delta \Phi_2-\Delta\Phi_1=0$ e $U|_S=0$ per le condizioni di Dirichlet, o $\frac{\partial U}{\partial n}|_S=0$ per le condizioni di Neumann.\\
In ogni caso si ha $\biggl[U\frac{\partial U}{\partial n}\biggr]_S=0$, per cui:
\begin{equation}
    \int_V|\nabla U\nabla U|^2 d^3\vec{x} = 0 \Longrightarrow \nabla U=0
\end{equation}
Il che implica $U$ costante, ovvero $\Phi_2=\Phi_1+cost$.\\
Nel caso di condizione al contorno di Dirichlet si ha che la costante vale 0, mentre le caso delle condizioni di Neumann, la soluzione è unica a meno di una costante inessenziale.\\
Per cui in generale non esiste una soluzione per cui sia $\Phi$ che $\frac{\partial \Phi}{\partial n}$ abbiamo entrambe valori prefissati su $S$ (condizioni di Cauchy), poichè il problema risulterebbe sovramisurato.\\
Tornando all'equazione (\ref{24 19}), data l'arbitrarietà di $h$, armonica in $V$, in $G=G_0+h$ posso scegliere $G$ in modo che l'integrale di superfice dipenda solo dalle condizioni al contorno scelte per $\Phi$:
\begin{itemize}
    \item Per condizioni di Dirichlet si impone che:
    \begin{equation}
        G_D(\Vec{x}_0,\Vec{x})=0 \quad\forall \Vec{x}\in S \Longrightarrow h(\Vec{x}_0,\Vec{x})=-\frac{1}{|\Vec{x}-\Vec{x}_0|} \forall \Vec{x}\in S
    \end{equation}
    Per cui l'equazione prende la forma:
    \begin{equation}
    \Phi(\vec{x}_0)=\int_VG(\vec{x}_0,\vec{x})\frac{}{}\rho(\vec{x})d^3\vec{x}-\frac{1}{4\pi}\int_S\Phi(\Vec{x})\frac{\partial G(\vec{x}_0,\vec{x})}{\partial n} dS
\end{equation}
\item Per condizioni di Neumann non è possibile imporre semplicemente: $\frac{\partial G_n}{\partial_n}(\vec{x}_0,\vec{x})=0 \ \forall\vec{x}\in S$ poichè sarebbe in contrasto con il teorema di Gauss:
\begin{equation}
    \int_s\frac{\partial G_n}{\partial n} dS=\int_S\nabla G_n\cdot \vec{n}dS=\int_S\nabla G_n\cdot \vec{dS}=\int_V\nabla\cdot\nabla G_nd^3\Vec{x}=\int_V\Delta G_nd^3\Vec{x}=-4\pi
\end{equation}
La condizione al contorno più semplice possibile per $G_n$ è invece:
\begin{equation}
    \frac{\partial G_n}{\partial n}(\Vec{x}_0,\Vec{x})=-\frac{4\pi}{A}
\end{equation}
Con $A$ area totale della superficie.\\
L'integrale in tale caso prende la forma seguente:
\begin{equation}
    \Phi(\vec{x}_0)=\int_VG(\vec{x}_0,\vec{x})\frac{}{}\rho(\vec{x})d^3\vec{x}+\frac{1}{4\pi}\int_S\biggl[G(\vec{x}_0,\vec{x})\frac{\partial \Phi(\Vec{x})}{\partial n}+<\Phi>_S\biggr]dS
\end{equation}
Con $<\Phi>\equiv \frac{1}{A}\int_S\Phi(\vec{x})dS$ valore medio del potenziale sulla superfice.\\
\item Usando il teorema di Green con $\Phi(\vec{y})\equiv G(\vec{x}_0,\vec{y})$ e $\psi(\vec{y})\equiv G(\vec{x},\vec{y})$ con $\vec{y}$ variabile di integrazione, è possibile dimostrare la proprietà di simmetria per la funzione di Green con le condizioni al contorno di Dirichlet:
\begin{equation}
    G_D(\vec{x}_0,\vec{x})=G_D(\vec{x},\vec{x}_0)
\end{equation}
Ovvero l'interscambialità fisica fra sorgente e punto di osservazione.\\
Per la funzione di Green con condizioni di Neumann la proprietà di Dirichlet non è automaticamente soddisfatta, ma può essere imposta come condizione aggiuntiva.\\
\end{itemize}

\subsection{Esempio in 2 dimensioni}
Sia $D\subset\mathds{R}^2$ domino semplicemente connesso e $z_0$ punto di $D$. Per il teorema di Riemann è possibile trovare una trasformazione conforme $z\to z'=f(z;z_0)$ che mappa $D$ nel cerchio unitario $\{z':|z'|\le 1\}$ (e la sua frontiera su $\{z':|z'|= 1\}$) e il punto $z_0$ nell'origine.\\
Si cerca dunque la funzione di Green per l'equazione di Poisson 2D:
\begin{equation}
    \Delta_2G_D(\vec{r}_0,\vec{r})=-4\pi\delta^{(2)}(\vec{r}-\vec{r}_0)\qquad \vec{r}=(x,y), \vec{r}_0=(x_0,y_0)
\end{equation}
Con condizioni al contorno di Dirichlet:
\begin{equation}
    G_D(\vec{r}_0,\vec{r})=0 \quad\forall \vec{r}\in \partial D
\end{equation}
E' data da:
\begin{equation}
    G_D(\vec{r}_0,\vec{r})=-2log|f(z,z_0)|
\end{equation}
Difatti $f(z;z_0)$ è analitica in $D$ con $f'(z;z_0)\ne0$, per cui $z_0$ zero di ordine 1 di $f$, inoltre non ci sono altri zeri di $f$, per cui è invertibile.\\
Di conseguenza definendo:
\begin{equation}
    \phi(z;z_0)\equiv \frac{f(z;z_0)}{z-z_0}
\end{equation}
Tale funzione è analitica in $D$, avendo in $z_0$:
\begin{equation}
    \phi(z_0;z_0)=\lim_{z\to z_0)}\frac{f(z;z_0)}{z-z_0}=f'(z_0;z_0)\ne 0
\end{equation}
Ed inoltre è non nulla in $D$.\\
Scrivendo $f(z;z_0)=(z-z_0)\phi(z;z_0)$ si vede che:
\begin{equation}
    log|f(z;z_0)|=log|z;z_0|+log|\phi(z;z_0)| \Longrightarrow -2log|f(z;z_0)|=G_0(\vec{r}-\vec{r}_0)-2log|\phi(z;z_0)|
\end{equation}
Essendo $G_D(\vec{r}-\vec{r}_0)\equiv -2log(|\vec{r}-\vec{r}_=)|=-2log|z-z_0|$ una funzione di Green per l'eq di Poisson in 2D.\\
Invece $h(\vec{r}_0,\vec{r})\equiv-2log|\phi(z;z_0)$ funzione armonica in $D$, essendo la parte reale della funzione analitica $-2log(\phi(z;z_0))$.\\
Per cui la combinazione:
\begin{equation}
    -2log|f(z;z_0)|=G_0(\vec{r}-\vec{r}_0)+h(\vec{r}_0,\vec{r})
\end{equation}
Rappresenta una funzione di Green per l'eq di Poisson in 2D.\\
Essendo $|f(z;z_0)|=1 \forall z\in\partial D$ si ha che tale funzione di Green soddisfa le condizioni al contorno di Dirichlet.\\
\subsubsection{Sottoesempio}
La funzione di Green per l'equazione di Poisson nel semipiano $y=Im(z)>0$, con condizioni al contorno:
\begin{equation}
    G_d(\vec{r}_0,\vec{r})=0 \quad \text{per} \quad y=0
\end{equation}
è data da:
\begin{equation*}
    G_D(\vec{r}_0,\vec{r})=-2log|f(z,z_0)|=-2log\biggl|\frac{z-z_0}{z-z_0^*}\biggr|=-2log|z-z_0|+2 loog|z-z_0^*|=-2log|\vec{r}-\vec{r}_0|+2log|\vec{r}-\vec{r}_I|
\end{equation*}
Con $\vec{r}_I$ posizione della carica immagine.



\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%\begin{center}
%\begin{tikzpicture}

%\draw (0,2) circle (2cm);
%\draw (0,-2) circle (2cm);
%\draw (2,-2)--(10,-2);
%\draw (2,2)--(10,2);
%\draw (10,2.5)--(10,-2.5);
%\draw (12.5,0) arc (0:90:2.5cm);
%\draw (12.5,0) arc (0:-90:2.5cm);
%\draw (11,0)--(12.5,0);
%\fill[pink!40!white] (0,-2) rectangle (10,2);
%\filldraw[fill=pink!60!white, draw=black] (0,-2) circle (2cm);
%\filldraw[fill=pink!60!white, draw=black] (0,2) circle (2cm);

%\end{tikzpicture}
%\end{center}




\newpage

\section{Conclusione}
Gli autori si augurano di aver creato una dispensa che sia stata di utilità a qualche lettore e che chiunque ne abbia fruito abbia sostenuto con successo l'esame.
\vfill
%\epigraph{Spero solo che la mia morte abbia più senso della mia vita.}
\epigraph{Sentiamo dentro di noi la perpetua chiamata: "Lì c'è il problema, cerca la soluzione".}{\textit{David Hilbert} }


\end{document}
